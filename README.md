# FG2P â€” ConversÃ£o Grafema-para-Fonema para PortuguÃªs Brasileiro

Modelo neural BiLSTM Encoder-Decoder + AtenÃ§Ã£o Bahdanau para converter texto PT-BR em transcriÃ§Ã£o fonÃ©tica IPA, com Distance-Aware Loss customizada.

**ğŸ† SOTA PER: 0.49%** (Exp104b, 9.7M params, 28.782 palavras de teste)
**ğŸ† SOTA WER: 4.96%** (Exp9, sem separadores silÃ¡bicos)
**Teste**: 57Ã— maior que LatPhon (0.86%) com mais confianÃ§a estatÃ­stica

---

## ğŸš€ Quick Start

```bash
# Setup
python -m venv .venv && .venv\Scripts\activate
pip install -r requirements.txt

# Usar modelo SOTA (Exp104b, index=18)
python src/inference_light.py --index 18 --word computador
# â†’ k Ãµ p u t a Ëˆ d o x .

# Modo interativo
python src/inference_light.py --index 18 --interactive

# Avaliar em banco de generalizaÃ§Ã£o
python src/inference_light.py --index 18 --neologisms docs/generalization_test.tsv

# RelatÃ³rio HTML completo
python src/reporting/report_generator.py

# Gerar apresentaÃ§Ã£o PPTX
python src/reporting/presentation_generator.py --mode full      # 31 slides
python src/reporting/presentation_generator.py --mode compact   # 20 slides (10 min)
```

---

## ğŸ“Š Resultados Principais (Phase 6C Completa)

| Exp | Params | TÃ©cnica | PERâ†“ | WERâ†“ | Uso recomendado |
|-----|--------|---------|------|------|-----------------|
| **Exp104b** | 9.7M | DA Loss + dist custom | **0.49%** | 5.43% | **SOTA PER â€” TTS, alinhamento** |
| **Exp9** | 9.7M | DA Loss Î»=0.2 | 0.58% | **4.96%** | **SOTA WER â€” NLP, busca** |
| Exp106 | 9.7M | DA + sem hÃ­fen | 0.58% | 6.12% | **Velocidade: 30.2 w/s âš¡ (2.58Ã—)** |
| Exp105 | 9.7M | DA + 50% dados | 0.54% | 5.87% | Deploy com menos dados |
| Exp102 | 9.7M | CE + separadores | 0.52% | 5.79% | ReferÃªncia |
| Exp5 | 9.7M | CrossEntropy | 0.63% | 5.38% | Baseline |

**Descobertas-chave**:
- Split 60/10/30 supera 70/10/20 em **âˆ’41% PER**
- Distance-Aware Loss: pesa erros por distÃ¢ncia articulatÃ³ria (eâ†’É› â‰  eâ†’k)
- Separadores silÃ¡bicos criam trade-off Pareto irredutÃ­vel (PERâ†“, WERâ†‘)
- 50% dados â†’ apenas +0.05% PER â€” modelo robusto
- Sem hÃ­fen â†’ 2.58Ã— velocidade, apenas +0.04% PER

---

## ğŸ“š DocumentaÃ§Ã£o

```
docs/
â”œâ”€â”€ 01_OVERVIEW.md            â† IntroduÃ§Ã£o, dataset, resultados completos
â”œâ”€â”€ 02_ARCHITECTURE.md        â† BiLSTM + AtenÃ§Ã£o Bahdanau
â”œâ”€â”€ 03_METRICS.md             â† PER, WER, mÃ©tricas fonolÃ³gicas
â”œâ”€â”€ 04_EXPERIMENTS.md         â† Exp0-106, design e resultados
â”œâ”€â”€ 05_THEORY.md              â† G2P, Loss functions, features articulatÃ³rias
â”œâ”€â”€ 06_PREPROCESSING.md       â† NormalizaÃ§Ã£o, charset, filtros
â”œâ”€â”€ 07_STRUCTURAL_ANALYSIS.md â† Problema d(.,Ëˆ)=0 e soluÃ§Ã£o (Exp104b)
â”œâ”€â”€ 09_CONTINUOUS_PHONETIC_SPACE.md â† EspaÃ§o fonÃ©tico 7D (Phase 7 â€” futuro)
â”œâ”€â”€ 11_CORPUS_AUDIT.md        â† Auditoria corpus: regra É£/x, NFD/NFC
â”œâ”€â”€ 16_SCIENTIFIC_ARTICLE.md  â† Artigo acadÃªmico completo
â””â”€â”€ 17_APRESENTACAO_MERGED.md â† ApresentaÃ§Ã£o PPTX [modes: full, compact]
```

**Leitura recomendada**: [docs/01_OVERVIEW.md](docs/01_OVERVIEW.md)

---

## ğŸ—ï¸ Arquitetura Resumida

```
"c a s a" â†’ [Embedding 192D] â†’ [BiLSTM Encoder 2Ã—384D] â†’ [AtenÃ§Ã£o Bahdanau]
                                                              â†“
                                          [LSTM Decoder 2Ã—384D] â†’ k a z a
```

**Loss**: `L = L_CE + Î» Â· d(Å·, y) Â· p(Å·)` â€” CrossEntropy + penalidade articulatÃ³ria
**Dataset**: 95.937 palavras PT-BR (dicts/pt-br.tsv) | Split: 60/10/30

---

## ğŸ”§ Comandos Ãšteis

```bash
# Treinar experimento
python src/train.py --config conf/config_exp104b_intermediate_sep_da_custom_dist.json

# AvaliaÃ§Ã£o completa (WER/PER no test set)
python src/inference.py

# Listar modelos treinados
python src/manage_experiments.py --list

# Benchmark de velocidade
python src/benchmark_inference.py
```

---

**Status**: Phase 6C Completa âœ… | Phase 7 Planejada (espaÃ§o fonÃ©tico 7D contÃ­nuo)
**DocumentaÃ§Ã£o**: [docs/](docs/) | **Roadmap**: [TODO.md](TODO.md) | **Status**: [STATUS.md](STATUS.md)
