# Gloss√°rio Unificado ‚Äî Fon√©tica, Algoritmos, e Projeto FG2P

**Prop√≥sito**: Centralizar todas as defini√ß√µes pedag√≥gicas para a apresenta√ß√£o FG2P em um √∫nico arquivo.

---

## üéØ PROJETO FG2P

### **G2P (Grapheme-to-Phoneme)**
Sistema que converte **grafemas** (letras escritas) em **fonemas** (sons).

```
Entrada:  "gato"  (grafemas: g-a-t-o)
‚Üì
[G2P Model]
‚Üì
Sa√≠da:    /…° a t u/  (fonemas: oclusiva-velar-vozeada, vogal-baixa, ...)
```

**Aplica√ß√µes**:
- **TTS (Text-to-Speech)**: Ler documentos em voz
- **Busca fon√©tica**: Encontrar "gato" mesmo escrito "gatt"
- **An√°lise lingu√≠stica**: Entender padr√µes sonoros

---

### **LSTM (Long Short-Term Memory)**
Tipo avan√ßado de rede neural para **processar sequ√™ncias**.

**Por qu√™ LSTM?**
- Problema: RNNs simples "esquecem" informa√ß√µes antigas
- Solu√ß√£o: LSTM tem "mem√≥ria" de longo prazo + curto prazo
- Resultado: Acorda o stress/contexto mesmo em palavras longas

```
Palavra: "c-o-m-p-u-t-a-d-o-r"
         ‚Üì
    [LSTM Encoder] ‚Üê lembra de tudo
         ‚Üì
    [LSTM Decoder] ‚Üê gera fonemas sabendo o contexto todo
```

---

### **PT-BR (Portugu√™s Brasileiro)**
Variante do portugu√™s com caracter√≠sticas fonol√≥gicas distintas.

**Diferen√ßas vs. Portugu√™s Europeu**:
- `/t É/` em "tia" (portugu√™s BR) vs `/ti/` (portugu√™s EU)
- Redu√ß√£o voc√°lica diferente em √°tona
- Rhotacism: /r/ em coda tem dois alofones

---

## üìç FON√âTICA PT-BR ‚Äî Articula√ß√µes e Dimens√µes Voc√°licas

### **Dimens√µes Articulat√≥rias ‚Äî Como Funciona na Boca**

#### **Ponto de Articula√ß√£o** (Onde na boca soa)

Imagine a cavidade oral como um mapa de zonas. Cada consoante √© produzida tocando/aproximando elementos da boca em posi√ß√µes espec√≠ficas:

```
         palato duro (c√©u da boca)
              ‚Üì
labial ‚îÄ alveolar ‚îÄ palatal ‚îÄ velar
  ‚Üë        ‚Üë         ‚Üë        ‚Üë
l√°bios   dentes   c√©u da boca  garganta
```

| Termo | Onde | Exemplos PT-BR | Como Soa |
|-------|------|-----------------|----------|
| **Labial** | L√°bios (superior/inferior) | /p/, /b/, /m/ | "**p**√£o", "**b**ola", "**m**√£o" |
| **Alveolar** | Atr√°s dos dentes superiores (crista alveolar) | /t/, /d/, /n/, /s/, /z/, /…æ/ | "**t**ato", "**d**ado", "**n**√£o", "**s**ala", "**z**ero" |
| **Palatal** | C√©u da boca (parte dura anterior) | / É/, / í/, /…≤/, /j/ | "**ch**ave" (/ É/), "**j**ar" (/ í/), "nho" (/…≤/) |
| **Velar** | V√©u (parte mole do palato, garganta) | /k/, /…°/, /≈ã/ | "**c**asa" (/k/), "**g**ato", "co**ng**o" (/≈ã/) |
| **Labiodental** | L√°bio inferior + dentes superiores | /f/, /v/ | "**f**ogo", "**v**inho" |

#### **Modo de Articula√ß√£o** (Como o ar passa)

Diferentes formas de bloquear/deixar o ar passar:

| Termo | Mecanismo | Exemplos | Como Soa |
|-------|-----------|----------|----------|
| **Oclusiva** (ou "stop") | Bloqueia COMPLETAMENTE o fluxo de ar | /p/, /b/, /t/, /d/, /k/, /…°/ | "**p**√£o" ‚Äî h√° explos√£o de ar |
| **Fricativa** | Ar passa com FRIC√á√ÉO (barulho) | /f/, /v/, /s/, /z/, / É/, / í/, /x/ | "**s**ala" ‚Äî ar passando entre l√≠ngua e dentes |
| **Nasal** | Ar passa pela NARIZ (v√©u abaixado) | /m/, /n/, /…≤/ | "**m**√£o", "**n**√£o" ‚Äî resson√¢ncia nasal |
| **Africada** | Come√ßa OCLUSIVA, termina FRICATIVA | /t É/, /d í/ | "**t**chia" (portugu√™s padr√£o "tia"), "**j**ar" |
| **Lateral** | Ar passa pelos LADOS da l√≠ngua | /l/ | "**l**ado" ‚Äî ar passa lateralmente |
| **Vibrante** | L√≠ngua VIBRA rapidamente | /r/ (m√∫ltipla), /…æ/ (simples) | "ca**rr**o" (/r/ vibrante), "ca**r**a" (/…æ/ simples) |

#### **Vozeamento** (Cordas Vocais Vibram?)

| Termo | O Que Faz | Pares PT-BR |
|-------|-----------|------------|
| **Vozeado** | Cordas vocais **vibram** | /b/, /d/, /…°/, /v/, /z/, / í/ ‚Äî "**b**ola", "**d**ado" |
| **Desvozeado** | Cordas vocais **n√£o vibram** | /p/, /t/, /k/, /f/, /s/, / É/ ‚Äî "**p**√£o", "**t**ato" |

**Teste de vozeamento**: Coloque a m√£o na garganta ao falar `/b/` (sente vibra√ß√£o) vs `/p/` (n√£o sente)

---

### **Dimens√µes Voc√°licas ‚Äî Vogais PT-BR**

Vogais s√£o **sons abertos** ‚Äî o ar flui livremente. A posi√ß√£o da l√≠ngua determina a qualidade:

```
        FRENTE          CENTRAL         TR√ÅS
ALTO      /i/                             /u/
          (como "si")                     (como "tu")

M√âDIO     /e/              /…ô/            /o/
          (como "p√©")    (neutra)        (como "p√≥")

BAIXO               /a/
              (como "p√°")
```

#### **Altura da L√≠ngua** (Vertical)

| N√≠vel | Termo | Exemplos | Sensa√ß√£o |
|-------|-------|----------|----------|
| **Alto** | L√≠ngua perto do palato | /i/, /u/ | "si", "tu" ‚Äî l√≠ngua levantada |
| **M√©dio** | L√≠ngua no meio | /e/, /o/, /…ô/ | "p√©", "p√≥" ‚Äî l√≠ngua meia-altura |
| **Baixo** | L√≠ngua baixa, boca aberta | /a/ | "p√°" ‚Äî boca bem aberta |

#### **Posi√ß√£o Anterior-Posterior** (Horizontal)

| Posi√ß√£o | Exemplos | Sensa√ß√£o |
|---------|----------|----------|
| **Anterior (Frente)** | /i/, /e/, /a/ | L√≠ngua para frente ("si", "p√©", "p√°") |
| **Posterior (Tr√°s)** | /u/, /o/ | L√≠ngua para tr√°s ("tu", "p√≥") |
| **Central** | /…ô/ | L√≠ngua neutra (posi√ß√£o de repouso) |

#### **Arredondamento dos L√°bios**

| Tipo | Exemplos | Sensa√ß√£o |
|------|----------|----------|
| **N√£o-arredondado** | /i/, /e/, /a/ | L√°bios abertos/espalhados |
| **Arredondado** | /u/, /o/ | L√°bios em "O" |

---

### **Pros√≥dia ‚Äî Acentua√ß√£o e Timing**

#### **Stress (Acento T√¥nico)**

Em portugu√™s, uma s√≠laba √© **t√¥nica** (acentuada) ou **√°tona** (desacentuada):

| Termo | O Qu√™ | Exemplo |
|-------|-------|---------|
| **T√¥nica** | S√≠laba **pronunciada com mais for√ßa** | com**PU**-ta-dor (2¬™ s√≠laba enfatizada) |
| **√Åtona** | S√≠laba **pronunciada com menos for√ßa** | com-pu-ta-**DOR** (outras s√£o fracas) |
| **Redu√ß√£o voc√°lica** | Vogal √°tona **muda de timbre** | ca**sa** ‚Üí /…ô/ (em vez de /a/) |

**Representa√ß√£o IPA**: `/Àà/` marca stress. Exemplo: com¬∑**Àà**pu¬∑ta¬∑dor

#### **Silabifica√ß√£o**

Uma s√≠laba cont√©m um **n√∫cleo voc√°lico** cercado opcionalmente por consoantes:

```
  Onset    N√∫cleo    Coda
    ‚Üì        ‚Üì        ‚Üì
   (C)      (V)      (C)

   [con] [som] [ante] ‚Äî estrutura poss√≠vel
```

| Padr√£o | Exemplos | Notas |
|--------|----------|-------|
| **V** (aberta) | a, e, o | Vogal pura |
| **CV** (aberta) | ba, te, do | Consoante + Vogal |
| **CVC** (fechada) | bal, ter, dor | Consoante + Vogal + Consoante |
| **CCV** | pra, tre, gra | 2 consoantes + vogal (clusters) |
| **CCVC** | prat, tren | 2 consoantes + vogal + consoante |

#### **Contexto Fonol√≥gico ‚Äî Influ√™ncias**

**Coda (Posi√ß√£o Final de S√≠laba)**: Consoantes em coda sofrem mudan√ßas:

| Contexto | Fen√¥meno | Exemplo |
|----------|----------|---------|
| **Coda final de palavra** | /r/ final ‚Üí /x/ (fricativa velar) | "**ar**" ‚Üí /ax/ (pronuncia-se como "arr" suave) |
| **Coda antes de C vozeada** | /r/ ‚Üí /…£/ (fricativa velar vozeada) | "borbo**le**ta" ‚Üí /bo…æ**…°**o/**le/**t…ô/ (r assimilado) |
| **Coda antes de C desvozeada** | /z/ antes /p/: /s/ | "despe**dir**" ‚Üí /des**pe**dir/ (z desvozeado ‚Üí s) |

---

## ü§ñ APRENDIZADO DE M√ÅQUINA ‚Äî Conceitos B√°sicos

### **Modelo**
Um **modelo** √© uma fun√ß√£o matem√°tica que aprende padr√µes a partir de dados.

**Analogia**: Como uma crian√ßa aprende a reconhecer uma √°rvore vendo v√°rios exemplos, um modelo aprende a reconhecer padr√µes vendo dados de treino.

```
Dados de treino ‚Üí [Modelo aprende padr√µes] ‚Üí Modelo treinado ‚Üí Predi√ß√µes
```

**No FG2P**: O modelo recebe uma palavra (ex: "computador") e prediz os sons (/k √µ p u t a Àà d o x/).

---

### **Treino (Training)**
Processo de **ajustar os par√¢metros do modelo** para minimizar erro.

| Termo | O Qu√™ |
|-------|-------|
| **√âpoca (Epoch)** | Uma passada completa pelos dados de treino |
| **Batch** | Um pequeno grupo de exemplos processados por vez |
| **Learning Rate** | "Tamanho do passo" ao ajustar par√¢metros (muito r√°pido = inst√°vel; muito lento = demora) |
| **Early Stopping** | Parar o treino quando o modelo para de melhorar (evita overfitting) |

---

### **Valida√ß√£o e Teste**
- **Valida√ß√£o**: Dados usados para monitorar progresso durante treino (n√£o treina, apenas observa)
- **Teste**: Dados **nunca vistos** antes, usados para avaliar o modelo final

**Por qu√™ separar?** Se testar com dados que treinou, o modelo parece melhor do que realmente √© (memoriza√ß√£o).

---

## üìä M√âTRICAS E VALIDA√á√ÉO

### **Cross Entropy (CE) ‚Äî Fun√ß√£o de Perda**

A **Cross Entropy** mede "quanto erro o modelo est√° cometendo".

**Ideia simples**:
- Se o modelo **acerta** completamente ‚Üí perda = 0
- Se o modelo **erra** completamente ‚Üí perda = alta

**Problema do CE no G2P**:
- Tratar `/b/` vs `/p/` como igualmente ruins (dist√¢ncia de 0)
- Tratar `/b/` vs `/…ô/` como igualmente ruins (dist√¢ncia de 0)
- Na realidade, `/b/` e `/p/` s√£o **muito parecidos** (s√≥ vozeamento varia)

**Solu√ß√£o**: Usar **Distance-Aware Loss** (ver abaixo).

---

### **Distance-Aware Loss (DA Loss)**

Uma **loss customizada** que penaliza erros **proporcionalmente √† dist√¢ncia articulat√≥ria**.

```
L = L_CE + Œª ¬∑ d(≈∑, y) ¬∑ p(≈∑)

Componentes:
  L_CE       = perda base (CrossEntropy)
  d(≈∑, y)   = dist√¢ncia articulat√≥ria entre predito e correto (0-1)
  p(≈∑)      = confian√ßa do modelo no token predito (0-1)
  Œª         = peso do sinal fonol√≥gico (0.2 empiricamente)
```

**Interpreta√ß√£o**:
- Se erra `/b/` quando era `/p/` (dist√¢ncia ‚âà 0.05) ‚Üí penalidade pequena
- Se erra `/b/` quando era `/a/` (dist√¢ncia ‚âà 0.90) ‚Üí penalidade grande
- Se est√° CONFIANTE no erro ‚Üí penalidade maior

**Resultado**: Modelo aprende a "preferir erros inteligentes".

---

### **PER (Phoneme Error Rate)**
Porcentagem de **fonemas individuais** errados.

```
PER = (n√∫mero de fonemas errados) / (total de fonemas) √ó 100%

Exemplo:
  Correto:  /k √µ p u t a Àà d o x/       (10 fonemas)
  Predito:  /k √µ p u t …ô Àà d o x/       (substitui /a/‚Üí/…ô/)
  Erros:    1 (um erro em 10)
  PER:      10%
```

**Foco**: Acerto individual de fonemas (importante para TTS, an√°lise lingu√≠stica).

---

### **WER (Word Error Rate)**
Porcentagem de **palavras inteiras** com qualquer erro.

```
WER = (n√∫mero de palavras com ‚â•1 erro) / (total de palavras) √ó 100%

Exemplo:
  Palavra:  "computador"
  Correto:  /k √µ p u t a Àà d o x/
  Predito:  /k √µ p u t …ô Àà d o x/       (1 fonema errado)
  Resultado: FALHA (a palavra inteira conta como erro)
  WER:      100% para essa palavra
```

**Foco**: Qualidade geral (importante para busca, indexa√ß√£o, NLP).

**Trade-off**: PER e WER geralmente s√£o **inversamente correlacionados** (trade-off Pareto).

---

### **Accuracy (Acur√°cia)**
Simples: porcentagem de acertos.

```
Accuracy = (acertos) / (total) √ó 100%
```

---

### **Overfitting (Sobreajuste)**
O modelo **memoriza os dados de treino** em vez de aprender padr√µes gerais.

```
Treino:  99% acur√°cia  ‚úì
Teste:   60% acur√°cia  ‚úó

Conclus√£o: O modelo memorizou treino, n√£o aprendeu regras.
```

**Preven√ß√£o**: Early stopping, valida√ß√£o, regulariza√ß√£o.

---

### **Underfitting (Subajuste)**
O modelo √© **muito simples** para capturar os padr√µes.

```
Treino:  70% acur√°cia
Teste:   68% acur√°cia

Conclus√£o: O modelo n√£o √© bom em nada (nem em treino).
```

**Solu√ß√£o**: Modelo mais complexo, mais dados, treino mais longo.

---

### **Generaliza√ß√£o**
Capacidade do modelo de **fazer boas predi√ß√µes em dados novos**.

**No FG2P**:
- **Overfitting** = modelo s√≥ acerta palavras que viu (30K treino)
- **Boa generaliza√ß√£o** = modelo acerta palavras novas (5/5 palavras OOV)

---

## üß† ARQUITETURA NEURAL

### **RNN (Recurrent Neural Network)**
Uma rede que **processa sequ√™ncias** lembrando do que viu antes.

**Analogia**: Imagine uma pessoa lendo uma palavra letra por letra. Para cada letra, ela **lembra das letras anteriores** para prever o som:

```
Palavra: c-o-m-p-u-t-a-d-o-r
         ‚Üì
    [RNN remembers]
    "vi 'c' + 'o' + 'm' + 'p' + 'u' + 't' + 'a'..."
         ‚Üì
    Prediz: /a/ (e n√£o /…ô/, porque lembra que √© t√¥nica)
```

**LSTM (Long Short-Term Memory)**: Vers√£o melhorada de RNN que "lembra por mais tempo".

---

### **Embedding (Embedding Layer)**
Converte **s√≠mbolos discretos** (letras, fonemas) em **vetores num√©ricos** que a rede entende.

```
Letra 'a' ‚Üí Vetor num√©rico [0.2, -0.5, 0.8, ...]
Letra 'b' ‚Üí Vetor num√©rico [0.3, -0.4, 0.7, ...]
```

**M√°gica**: Letras **parecidas** recebem vetores **parecidos**.

---

### **Attention Mechanism (Mecanismo de Aten√ß√£o)**
Permite o modelo **focar em partes importantes** da entrada.

**Analogia**: Ao ler "computador", o modelo concentra aten√ß√£o em:
- "co**m**p" para decidir a palataliza√ß√£o
- "compu**t**a" para decidir o stress
- "computa**dor**" para decidir a vogal final

Sem aten√ß√£o, o modelo trata todas as letras igualmente (ineficiente).

---

## üìà T√âCNICAS DE TREINAMENTO

### **Data Augmentation (Aumento de Dados)**
Criar **exemplos artificiais** a partir dos reais para treinar melhor.

**No FG2P**: Poderia remover h√≠fens, aplicar filtros graf√™micos, etc.

---

### **Label Smoothing**
Em vez de:
```
Correto: 1.0
Errado:  0.0
```

Usar:
```
Correto:  0.9
Errado:   0.1 / 4 (distribu√≠do)
```

**Efeito**: Modelo fica menos confiante (evita overfitting).

**No FG2P**: Distance-Aware Loss √© vers√£o **n√£o-uniforme** disso ‚Äî penaliza proporcionalmente √† dist√¢ncia.

---

### **Regulariza√ß√£o**
T√©cnicas para evitar overfitting:

| T√©cnica | Fun√ß√£o |
|---------|--------|
| **Dropout** | Desativa neur√¥nios aleatoriamente (for√ßa o modelo a redund√¢ncia) |
| **L1/L2 Regularization** | Penaliza par√¢metros grandes (simplifica modelo) |
| **Early Stopping** | Para treino quando valida√ß√£o para de melhorar |

---

## üéì TERMOS DE AVALIA√á√ÉO

### **SOTA (State-of-the-Art)**
"**Estado da arte**" ‚Äî o melhor resultado conhecido at√© o momento.

```
Exp104b: PER 0.49% ‚Üê SOTA PER (nosso melhor)
Exp9:    WER 4.96% ‚Üê SOTA WER (nosso melhor)
```

**Competidores**:
- LatPhon 2025 (PT-BR especializado, mas corpus pequeno)
- ByT5-Small (multil√≠ngue, mas 30√ó maior)

---

### **Baseline**
Resultado de **refer√™ncia simples** para compara√ß√£o.

```
Exp1 (Baseline): 0.66% PER
Exp104b (SOTA):  0.49% PER
Melhoria:        ~25% relativa
```

---

### **Trade-off (Compromisso)**
Situa√ß√£o onde melhorar uma m√©trica **piora outra**.

**No FG2P**:
```
Com separadores sil√°bicos:
  ‚úì PER melhora: 0.58% ‚Üí 0.52% (menos erros fonema)
  ‚úó WER piora:   4.96% ‚Üí 5.79% (mais erros palavra)

Raz√£o: Um separador mal-posicionado = palavra inteira errada
```

---

### **Distribui√ß√£o Estratificada**
Dividir dados mantendo **propor√ß√µes representativas**.

```
Dataset completo:
  - 60% treino (57.561 palavras)
  - 10% valida√ß√£o (9.594 palavras)
  - 30% teste (28.782 palavras) ‚Üê maior para medi√ß√£o estat√≠stica confi√°vel
```

**Teste de balanceamento**: œá¬≤ = 0.95 (p = 0.678) ‚Äî distribui√ß√£o fonol√≥gica balanceada ‚úì

---

## üî¨ T√âCNICAS E INOVA√á√ïES DO FG2P

### **Separadores Sil√°bicos**
Adicionar token **`.`** entre s√≠labas.

**Entrada com separadores**:
```
Sem:  c-o-m-p-u-t-a-d-o-r
Com:  c-o-.-m-p-u-.-t-a-.-d-o-r
```

**Efeito**:
- ‚úì Modelo aprende limites sil√°bicos
- ‚úì PER melhora (0.58% ‚Üí 0.52%)
- ‚úó WER piora (4.96% ‚Üí 5.79%)

**Trade-off permanece**: Melhoria em fonemas, piora em palavras inteiras.

---

### **Dist√¢ncias Customizadas**
PanPhon (ferramenta padr√£o) tem problema: **marcas diacr√≠ticas** (stress `.`, silabifica√ß√£o `Àà`) t√™m dist√¢ncia = 0.

```
Problema:
  d(., Àà) = 0.0 ‚Üê Loss n√£o diferencia confus√£o!

Solu√ß√£o (Exp104b):
  d(., anything) = 1.0  ‚Üê for√ßa m√°xima penalidade
  d(Àà, anything) = 1.0 ‚Üê for√ßa m√°xima penalidade
```

**Resultado**: Exp104b reduz confus√£o `.‚ÜîÀà` de ~119 para ~106.

---

## üß™ CATEGORIAS DE TESTE

### **Neologismos**
Palavras **novas** criadas no portugu√™s contempor√¢neo.

**Exemplos**:
- "printar" (do ingl√™s "print")
- "tchau" (abrasileiramento)
- "computadorzinho" (diminutivo)

**Teste**: Modelo acerta generaliza√ß√µes PT-BR (portmanteaux, diminutivos)?

---

### **Palavras OOV (Out-of-Vocabulary)**
Palavras **n√£o vistas no treino**, usadas para testar **generaliza√ß√£o genu√≠na**.

```
Treino: 57.561 palavras (60% do corpus)
Teste OOV: 5 palavras PT-BR reais nunca vistas

Resultado: 5/5 corretas (100% de sucesso) ‚Üê prova de generaliza√ß√£o
```

---

### **Geminadas (Consoantes Duplas)**
Consoantes repetidas: "pp", "zz", "tt".

**Desafio**: Treino tem poucas geminadas (maioria s√£o empr√©stimos).

```
Palavra:  "cappuccino" (it√°liano)
Treino:   < 0.01% geminadas
Resultado: Modelo falha (gap conhecido)
```

---

### **Anglicismos**
Empr√©stimos do ingl√™s com **fonologia estrangeira**.

```
Palavra:  "mouse" (ingl√™s)
Esperado: /m a w s …ô/ (passaporte portugu√™s)
Modelo:   Acerta se fonologia PT-BR, erra se tentar ingl√™s

Status: Parcial (fonologia em parte PT-BR)
```

---

### **OOV Caractere**
Caracteres **nunca vistos** (fora do charset de treino).

```
Charset treino: a-z (exceto k,w,y) + √ß + acentos = 39 chars
Palavras fora:  "yoga", "wifi" (t√™m k, w, y)

Resultado: Falha esperada (sem esses sons no treino)
```

---

### **Controles**
Palavras que o modelo **deve acertar** (verifica√ß√£o de sanidade).

```
Controle 1: "biscoito" ‚Üê simples, comum
Controle 2: "computador" ‚Üê complexo, no artigo

Esperado: 100% acur√°cia (sen√£o h√° bug)
Resultado: ‚úì (4/4 controles acertos)
```

---

## üìà M√âTRICAS DE QUALIDADE

### **Phonological Score (Score Fonol√≥gico)**
Medida **n√£o-bin√°ria** de qualidade mesmo quando erra.

```
Exemplo:
  Correto:  /a/ (vogal baixa, central)
  Predito:  /…ô/ (vogal neutra, central)

Score: 95% (mesmo erro, mesma regi√£o articulat√≥ria)
```

**Escala**:
- **100%**: Exato
- **95-99%**: Muito pr√≥ximo (um tra√ßo diferente)
- **80-94%**: Pr√≥ximo (2 tra√ßos diferentes)
- **50-79%**: Parcial (3 tra√ßos diferentes)
- **< 50%**: Distante (> 3 tra√ßos diferentes)

---

### **Character Coverage**
Porcentagem de caracteres de uma palavra que est√£o no vocabul√°rio.

```
Palavra: "yoga"
Vocab:   a-z (sem y,w,k)

Chars:   y-o-g-a
          ‚úó ‚úì ‚úì ‚úì

Coverage: 75% (3 de 4 caracteres conhecidos)
OOV:      {y}
```

---

## üìö ESTRUTURA ACAD√äMICA

### **Artigo (Paper)**
Documento t√©cnico completo (~700 linhas) com:
- Motiva√ß√£o e problema
- Revis√£o de literatura
- Metodologia e dataset
- Resultados e an√°lise
- Conclus√µes e trabalho futuro

**Arquivo**: `docs/16_SCIENTIFIC_ARTICLE.md`

---

### **Apresenta√ß√£o (Presentation)**
Resumo visual (26 slides + gloss√°rios) para comunica√ß√£o em confer√™ncia.

**Formato**: Markdown Marp ‚Üí PPTX gerado automaticamente

**Estrutura**:
1. Motiva√ß√£o (slides 1-3)
2. Metodologia (slides 4-13)
3. Resultados (slides 14-21)
4. Conclus√µes (slides 22-26)
5. Gloss√°rios (refer√™ncia final)

---

### **Relat√≥rio (Report)**
Documento HTML din√¢mico com todos os experimentos dispon√≠veis.

**Gerado automaticamente** de `models/*/metadata.json`.

---

## üìå ABREVIA√á√ïES COMUNS

| Abrevia√ß√£o | Significado |
|------------|------------|
| **PT-BR** | Portugu√™s Brasileiro |
| **G2P** | Grapheme-to-Phoneme |
| **LSTM** | Long Short-Term Memory |
| **RNN** | Recurrent Neural Network |
| **IPA** | International Phonetic Alphabet |
| **CE** | Cross Entropy |
| **DA** | Distance-Aware |
| **PER** | Phoneme Error Rate |
| **WER** | Word Error Rate |
| **SOTA** | State-of-the-Art |
| **OOV** | Out-of-Vocabulary |
| **TTS** | Text-to-Speech |
| **NLP** | Natural Language Processing |
| **Coda** | Posi√ß√£o final de s√≠laba |
| **Onset** | Posi√ß√£o inicial de s√≠laba |

---

**Uso na Apresenta√ß√£o**: Esse gloss√°rio unificado √© consultado quando um termo espec√≠fico √© introduzido, ou visto como refer√™ncia r√°pida ao final da apresenta√ß√£o.
