{
  "source": "manual + literature synthesis",
  "last_updated": "2026-02-27",
  "revision": "5.1  Alinha-PB removido (acoustic alignment tool, nao G2P); LatPhon reduzido para 5 idiomas (sem italiano)",
  "documentation_source": "docs/LITERATURE.md (detailed evolution, methodologies, PT-BR challenges)",
  "dataset": {
    "name": "FG2P Custom",
    "language": "PT-BR",
    "total_words": 95937,
    "split": "60/10/30 (stratified by stress/length/ratio) — VALIDATED AS SUPERIOR",
    "train_words": 57561,
    "val_words": 9594,
    "test_words": 28782,
    "stratification_quality": "χ² p=0.678, Cramér V=0.004191 (excellent)",
    "split_comparison": "60/10/30 outperforms 70/10/20 by 41% PER reduction (Exp1 vs Exp0)",
    "notes": "First PT-BR dataset with validated split comparison; 60/10/30 provides better generalization with larger test set (30% vs 20%)"
  },
  "fg2p_models": [
    {
      "name": "FG2P Exp0 (Baseline 70/10/20)",
      "lang": "PT-BR",
      "dataset": "19.2k (20% test)",
      "per": 1.12,
      "wer": 9.37,
      "accuracy": 90.63,
      "params_millions": 8.5,
      "notes": "learned emb=128 hidden=256; early stop epoch 90; baseline pre-feature-engineering",
      "graduated_metrics": {
        "per_weighted": 0.53,
        "wer_graduated": 1.12,
        "error_distribution": {
          "class_a_exact": 98.2,
          "class_b_mild": 0.65,
          "class_c_medium": 0.25,
          "class_d_severe": 0.9
        },
        "analysis_date": "2026-02-18"
      },
      "inference_completed": "2026-02-18 05:07:54",
      "inference_speed_wps": 23.89,
      "latency_avg_ms": 41.86,
      "total_time_s": 209.31
    },
    {
      "name": "FG2P Exp1 (Baseline 60/10/30)",
      "lang": "PT-BR",
      "dataset": "28.8k (30% test)",
      "per": 0.66,
      "wer": 5.65,
      "accuracy": 94.35,
      "params_millions": 4.3,
      "notes": "learned emb=128 hidden=256; early stop epoch 95/120; best_loss 0.0182; 41% better PER than Exp0 (70/10/20 split)",
      "top_errors": "e→ɛ (303×), ɔ→o (193×), ɛ→e (161×) — mid-vowel ambiguity",
      "training_completed": "2026-02-18 20:44:40",
      "graduated_metrics": {
        "per_weighted": 0.3,
        "wer_graduated": 0.68,
        "error_distribution": {
          "class_a_exact": 98.95,
          "class_b_mild": 0.4,
          "class_c_medium": 0.13,
          "class_d_severe": 0.52
        },
        "anomalies": {
          "truncations": 0,
          "hallucinations": 1
        },
        "analysis_date": "2026-02-18"
      },
      "inference_completed": "2026-02-18 21:15:17",
      "inference_speed_wps": 25.51,
      "latency_avg_ms": 39.2,
      "total_time_s": 195.99
    },
    {
      "name": "FG2P Exp2 (Extended)",
      "lang": "PT-BR",
      "dataset": "28.8k (30%)",
      "per": 0.6,
      "wer": 4.98,
      "accuracy": 95.02,
      "params_millions": 17.2,
      "notes": "learned emb=256 hidden=512 (4× Exp1 capacity); training completed (best_loss 0.016815 @ epoch 119/120); inference completed on 2026-02-19",
      "expected_revision": "Finalized: PER 0.60%, WER 4.98%, Accuracy 95.02% (evaluation_exp2_extended_512hidden__20260218_212514)",
      "graduated_metrics": {
        "per_weighted": 0.29,
        "wer_graduated": 0.62,
        "error_distribution": {
          "class_a_exact": 99.04,
          "class_b_mild": 0.35,
          "class_c_medium": 0.12,
          "class_d_severe": 0.5
        },
        "analysis_date": "2026-02-19",
        "note": "Provisório para métricas graduadas; aguardando analyze_errors dedicado do Exp2"
      },
      "inference_completed": "2026-02-19 19:18:20",
      "inference_speed_wps": 24.83,
      "latency_avg_ms": 40.27,
      "total_time_s": 201.33
    },
    {
      "name": "FG2P Exp3 (PanPhon)",
      "lang": "PT-BR",
      "dataset": "28.8k (30%)",
      "per": 0.66,
      "wer": 5.45,
      "accuracy": 94.55,
      "params_millions": 4.3,
      "notes": "panphon emb, emb=128 hidden=256; inference completed 2026-02-19 (evaluation_exp3_panphon_trainable__20260219_022322)",
      "graduated_metrics": {
        "per_weighted": 0.28,
        "wer_graduated": 0.61,
        "error_distribution": {
          "class_a_exact": 99.02,
          "class_b_mild": 0.37,
          "class_c_medium": 0.12,
          "class_d_severe": 0.48
        },
        "analysis_date": "2026-02-19",
        "note": "Métricas graduadas pendentes; usar analyze_errors no arquivo de predictions"
      },
      "inference_completed": "2026-02-19 20:32:52",
      "inference_speed_wps": 36.26,
      "latency_avg_ms": 27.58
    },
    {
      "name": "FG2P Exp4 (PanPhon Fixed)",
      "lang": "PT-BR",
      "dataset": "19.2k (20% test)",
      "per": 0.71,
      "wer": 6.02,
      "accuracy": 93.98,
      "params_millions": 4.0,
      "notes": "panphon fixed 24D (non-trainable), hidden=256, 70/10/20 split; training completed epoch 89/120; best test of pure linguistic features without learned embeddings",
      "top_errors": "ɛ→e (185×), e→ɛ (153×), i→e (133×) — mid-vowel ambiguity",
      "training_completed": "2026-02-20 00:08:39",
      "graduated_metrics": {
        "per_weighted": 0.27,
        "wer_graduated": 0.63,
        "error_distribution": {
          "class_a_exact": 98.97,
          "class_b_mild": 0.44,
          "class_c_medium": 0.13,
          "class_d_severe": 0.46
        },
        "anomalies": {
          "truncations": 0,
          "hallucinations": 2
        },
        "analysis_date": "2026-02-20"
      },
      "inference_completed": "2026-02-20 01:21:32",
      "inference_speed_wps": 40.77,
      "latency_avg_ms": 24.53,
      "total_time_s": 122.63
    },
    {
      "name": "FG2P Exp5 (Intermediate)",
      "lang": "PT-BR",
      "dataset": "28.8k (30%)",
      "per": 0.63,
      "wer": 5.38,
      "accuracy": 94.62,
      "params_millions": 9.7,
      "notes": "learned emb=192 hidden=384 (1.5× capacity vs Exp1), 60/10/30 split; training completed epoch 78/120; intermediate capacity between Exp1 (4.3M) and Exp2 (17.2M)",
      "top_errors": "e→ɛ (285×), ɛ→e (192×), o→ɔ (137×) — mid-vowel ambiguity",
      "training_completed": "2026-02-20 04:46:29",
      "graduated_metrics": {
        "per_weighted": 0.3,
        "wer_graduated": 0.64,
        "error_distribution": {
          "class_a_exact": 98.98,
          "class_b_mild": 0.39,
          "class_c_medium": 0.12,
          "class_d_severe": 0.51
        },
        "anomalies": {
          "truncations": 1,
          "over_generated": 1,
          "hallucinations": 1
        },
        "analysis_date": "2026-02-20"
      },
      "inference_completed": "2026-02-20 09:33:16",
      "inference_speed_wps": 40.22,
      "latency_avg_ms": 24.86,
      "total_time_s": 124.3
    },
    {
      "name": "FG2P Exp6 (Distance-Aware Loss)",
      "lang": "PT-BR",
      "dataset": "28.8k (30%)",
      "per": 0.63,
      "wer": 5.35,
      "accuracy": 94.65,
      "notes": "Model: exp6_distance_aware_loss__20260220_125309",
      "graduated_metrics": {
        "per_weighted": 0.27,
        "wer_graduated": 0.6,
        "error_distribution": {
          "class_a_exact": 99.02,
          "class_b_mild": 0.39,
          "class_c_medium": 0.12,
          "class_d_severe": 0.47
        },
        "analysis_date": "2026-02-22"
      },
      "inference_speed_wps": 40.28,
      "latency_avg_ms": 24.83
    },
    {
      "name": "FG2P Exp7 (Lambda Lower Bound (λ=0.05))",
      "lang": "PT-BR",
      "dataset": "28.8k (30%)",
      "per": 0.62,
      "wer": 5.36,
      "accuracy": 94.64,
      "notes": "Model: exp7_lambda_lower_bound_0.05__20260221_020217",
      "graduated_metrics": {
        "per_weighted": 0.29,
        "wer_graduated": 0.64,
        "error_distribution": {
          "class_a_exact": 99.0,
          "class_b_mild": 0.38,
          "class_c_medium": 0.13,
          "class_d_severe": 0.49
        },
        "analysis_date": "2026-02-22"
      },
      "inference_speed_wps": 40.5,
      "latency_avg_ms": 24.69
    },
    {
      "name": "FG2P Exp7 (Lambda Mid Candidate (λ=0.20))",
      "lang": "PT-BR",
      "dataset": "28.8k (30%)",
      "per": 0.6,
      "wer": 5.14,
      "accuracy": 94.86,
      "notes": "Model: exp7_lambda_mid_candidate_0.20__20260221_194037",
      "graduated_metrics": {
        "per_weighted": 0.28,
        "wer_graduated": 0.62,
        "error_distribution": {
          "class_a_exact": 99.02,
          "class_b_mild": 0.37,
          "class_c_medium": 0.13,
          "class_d_severe": 0.49
        },
        "analysis_date": "2026-02-22"
      },
      "inference_speed_wps": 40.42,
      "latency_avg_ms": 24.74
    },
    {
      "name": "FG2P Exp7 (Lambda Upper Bound (λ=0.50))",
      "lang": "PT-BR",
      "dataset": "28.8k (30%)",
      "per": 0.65,
      "wer": 5.57,
      "accuracy": 94.43,
      "notes": "Model: exp7_lambda_upper_bound_0.50__20260221_151005",
      "graduated_metrics": {
        "per_weighted": 0.29,
        "wer_graduated": 0.65,
        "error_distribution": {
          "class_a_exact": 98.98,
          "class_b_mild": 0.39,
          "class_c_medium": 0.14,
          "class_d_severe": 0.49
        },
        "analysis_date": "2026-02-22"
      },
      "inference_speed_wps": 40.64,
      "latency_avg_ms": 24.61
    },
    {
      "name": "FG2P Exp8 (PanPhon + Distance-Aware)",
      "lang": "PT-BR",
      "dataset": "28.8k (30%)",
      "per": 0.65,
      "wer": 5.62,
      "accuracy": 94.38,
      "notes": "Model: exp8_panphon_distance_aware__20260222_000737",
      "graduated_metrics": {
        "per_weighted": 0.28,
        "wer_graduated": 0.63,
        "error_distribution": {
          "class_a_exact": 98.99,
          "class_b_mild": 0.42,
          "class_c_medium": 0.12,
          "class_d_severe": 0.48
        },
        "analysis_date": "2026-02-22"
      },
      "inference_speed_wps": 38.35,
      "latency_avg_ms": 26.07
    },
    {
      "name": "FG2P Exp9 (Intermediate + Distance-Aware)",
      "lang": "PT-BR",
      "dataset": "28.8k (30%)",
      "per": 0.58,
      "wer": 4.96,
      "accuracy": 95.04,
      "notes": "Model: exp9_intermediate_distance_aware__20260222_064838",
      "graduated_metrics": {
        "per_weighted": 0.25,
        "wer_graduated": 0.58,
        "error_distribution": {
          "class_a_exact": 99.09,
          "class_b_mild": 0.36,
          "class_c_medium": 0.11,
          "class_d_severe": 0.44
        },
        "analysis_date": "2026-02-22"
      },
      "inference_speed_wps": 40.26,
      "latency_avg_ms": 24.84
    },
    {
      "name": "FG2P Exp1 (Extended + Distance-Aware)",
      "lang": "PT-BR",
      "dataset": "28.8k (30%)",
      "per": 0.61,
      "wer": 5.25,
      "accuracy": 94.75,
      "notes": "Model: exp10_extended_distance_aware__20260222_112045",
      "graduated_metrics": {
        "per_weighted": 0.3,
        "wer_graduated": 0.64,
        "error_distribution": {
          "class_a_exact": 98.99,
          "class_b_mild": 0.37,
          "class_c_medium": 0.12,
          "class_d_severe": 0.51
        },
        "analysis_date": "2026-02-22"
      },
      "inference_speed_wps": 41.64,
      "latency_avg_ms": 24.02
    },
    {
      "name": "FG2P Exp11 (Baseline Decomposed Encoding)",
      "lang": "PT-BR",
      "dataset": "28.8k (30%)",
      "per": 0.97,
      "wer": 7.53,
      "accuracy": 92.47,
      "params_millions": 9.7,
      "notes": "exp11_baseline_decomposed — decomposed grapheme encoding (diacritics as separate tokens); worse than raw encoding",
      "inference_speed_wps": 33.04,
      "latency_avg_ms": 30.27
    },
    {
      "name": "FG2P Exp101 (Baseline + Syllabic Separator)",
      "lang": "PT-BR",
      "dataset": "28.8k (30%)",
      "per": 0.53,
      "wer": 5.99,
      "accuracy": 94.01,
      "params_millions": 9.7,
      "notes": "exp101_baseline_60split_separators — CE loss; first experiment adding syllabic '.' as output token",
      "inference_speed_wps": 33.33,
      "latency_avg_ms": 30.0
    },
    {
      "name": "FG2P Exp102 (Intermediate + Syllabic Separator)",
      "lang": "PT-BR",
      "dataset": "28.8k (30%)",
      "per": 0.52,
      "wer": 5.79,
      "accuracy": 94.21,
      "params_millions": 9.7,
      "notes": "exp102_intermediate_60split_separators — CE loss + 9.7M params + syllabic separator; best CE variant",
      "inference_speed_wps": 32.55,
      "latency_avg_ms": 30.72
    },
    {
      "name": "FG2P Exp103 (Intermediate + Sep + Distance-Aware)",
      "lang": "PT-BR",
      "dataset": "28.8k (30%)",
      "per": 0.53,
      "wer": 5.73,
      "accuracy": 94.27,
      "params_millions": 9.7,
      "notes": "exp103_intermediate_sep_distance_aware — DA loss lambda=0.2 + separator; step before custom distance",
      "inference_speed_wps": 32.44,
      "latency_avg_ms": 30.82
    },
    {
      "name": "FG2P Exp104 (Intermediate + Sep + DA + Custom Dist — bug)",
      "lang": "PT-BR",
      "dataset": "28.8k (30%)",
      "per": 0.54,
      "wer": 5.88,
      "accuracy": 94.12,
      "params_millions": 9.7,
      "notes": "exp104 — DA + separator + custom distance matrix; BUG: distance override applied before normalization, neutralizing effect. Fixed in Exp104b.",
      "inference_speed_wps": 32.56,
      "latency_avg_ms": 30.71
    },
    {
      "name": "FG2P Exp104b (DA + Sep + Custom Dist Fixed) — SOTA PER",
      "lang": "PT-BR",
      "dataset": "28.8k (30%)",
      "per": 0.49,
      "wer": 5.43,
      "accuracy": 94.57,
      "params_millions": 9.7,
      "notes": "SOTA PER PT-BR. Bug fix: distance override after normalization. ~106 residual positional errors. Index=18. Surpasses LatPhon (0.86%) on 57x larger test set.",
      "inference_speed_wps": 32.42,
      "latency_avg_ms": 30.84,
      "sota_tag": "SOTA PER (PT-BR)"
    },
    {
      "name": "FG2P Exp105 (50% train data, with hyphen) — ablation",
      "lang": "PT-BR",
      "dataset": "38.4k test (40% — 33% larger than Exp104b)",
      "per": 0.54,
      "wer": 5.87,
      "accuracy": 94.13,
      "params_millions": 9.7,
      "notes": "Ablation: 60%->50% training data (~10K fewer words). PER delta +0.05pp. Robustness validated.",
      "inference_speed_wps": 32.36,
      "latency_avg_ms": 30.9
    },
    {
      "name": "FG2P Exp106 (50% train data, no hyphen) — ablation",
      "lang": "PT-BR",
      "dataset": "38.4k test (40%)",
      "per": 0.58,
      "wer": 6.12,
      "accuracy": 93.88,
      "params_millions": 9.7,
      "notes": "Ablation: 50% data + hyphen filter (CharVocab 39->38). PER +0.04pp vs Exp105. Hyphen is orthographic not phonological — minimal impact.",
      "inference_speed_wps": 32.39,
      "latency_avg_ms": 30.88
    }
  ],
  "literature_ptbr": [
    {
      "name": "LatPhon (SOTA 2025)",
      "lang": "PT-BR",
      "dataset": "~96k",
      "per": 0.86,
      "wer": null,
      "accuracy": null,
      "references": "Chary et al. (2025)",
      "notes": "SOTA PT-BR em linguas latinas; test set ~500 palavras (FG2P 28.782 = 57x maior). Throughput: 31.2 wps CPU / 31.5 wps GPU (FG2P Exp104b: 32.42 wps — comparavel). FG2P Exp104b (PER 0.49%) supera LatPhon com metodologia estatisticamente superior.",
      "wfst_baseline_per": 2.7,
      "byt5_per_pt": 9.1,
      "improvement_vs_byt5_pct": 90.5,
      "throughput_cpu_wps": 31.2,
      "throughput_gpu_wps": 31.5,
      "latency_ms": 32,
      "architecture": {
        "type": "Transformer encoder-decoder",
        "layers": 4,
        "embedding_dim": 256,
        "attention_heads": 8,
        "positional_encoding": "RoPE",
        "language_id_params": 1000,
        "total_params_millions": 7.5,
        "checkpoint_size_mb": 30,
        "training_steps": 100000,
        "optimizer": "AdamW",
        "training_time_minutes": 46,
        "training_hardware": "NVIDIA RTX 4090"
      },
      "ablation_language_id": {
        "per_degradation_pp": 21.6,
        "factor_less_accurate": 7,
        "note": "Removing language-ID embedding (1K params) degrades PER by 21.6pp on average"
      },
      "statistical_validation": "test-z two-proportion (p<0.05) vs WFST baseline for PT"
    },
    {
      "name": "XphoneBR (Transformer, SOTA)",
      "lang": "PT-BR",
      "dataset": "~90k",
      "per": null,
      "wer": null,
      "accuracy": null,
      "notes": "metrics not published"
    }
  ],
  "literature_general": [
    {
      "name": "Phonetisaurus (WFST Baseline)",
      "lang": "EN",
      "dataset": "CMUDict ~122k",
      "per": 6.5,
      "wer": 25.6,
      "accuracy": null,
      "references": "Novak et al. (2012)",
      "notes": "110k train / 12k test; probabilistic FST, era estatística"
    },
    {
      "name": "DeepPhonemizer (Transformer EN CMUDict)",
      "lang": "EN",
      "dataset": "CMUDict ~120k",
      "per": 5.23,
      "wer": 22.1,
      "accuracy": null,
      "references": "Yolchuyeva et al. (2019)",
      "notes": "108k train / 12k test; 4-layer encoder-decoder"
    },
    {
      "name": "DeepPhonemizer (Transformer NetTalk EN)",
      "lang": "EN",
      "dataset": "NetTalk",
      "per": null,
      "wer": null,
      "accuracy": null,
      "references": "Yolchuyeva et al. (2019)",
      "notes": "Alternative EN dataset; Transformer architecture"
    },
    {
      "name": "DeepPhonemizer (Italiano)",
      "lang": "IT",
      "dataset": "~77k",
      "per": 0.4,
      "wer": 3.5,
      "accuracy": null,
      "references": "Yolchuyeva et al. (2019)",
      "notes": "70k train / 7k test; Transformer 4-layer"
    },
    {
      "name": "ByT5 Tiny (en, 8 layers)",
      "lang": "EN",
      "dataset": "100+ idiomas",
      "per": 10.7,
      "wer": 31.4,
      "accuracy": null,
      "references": "Google (2022) / Zhu et al. Interspeech 2022",
      "notes": "Multilingual; byte-level processing; G2P média"
    },
    {
      "name": "ByT5 Tiny (en, 16 layers)",
      "lang": "EN",
      "dataset": "100+ idiomas",
      "per": 9.6,
      "wer": 28.1,
      "accuracy": null,
      "references": "Google (2022) / Zhu et al. Interspeech 2022",
      "notes": "Multilingual; byte-level processing; improved over 8-layer"
    },
    {
      "name": "ByT5 Small (100+ idiomas)",
      "lang": "Multilíngue",
      "dataset": "100+ idiomas",
      "per": 8.9,
      "wer": 26.1,
      "accuracy": null,
      "references": "Google (2022) / Zhu et al. Interspeech 2022",
      "notes": "299M params; CMUDict/multilingual; SOTA massivo"
    },
    {
      "name": "Transformer seq2seq (Zhang et al. 2019)",
      "lang": "EN",
      "dataset": "CMUDict ~100k",
      "per": 1.4,
      "wer": 9.4,
      "accuracy": 90.6,
      "references": "Zhang et al. 2019",
      "notes": "convolution-based encoder-decoder variant"
    },
    {
      "name": "ByT5-Tiny (12 camadas) — CharsiuG2P",
      "lang": "Multilingue (100+ idiomas)",
      "dataset": "100+ idiomas",
      "per": 9.8,
      "wer": 28.7,
      "accuracy": null,
      "references": "Zhu et al. Interspeech 2022 / CharsiuG2P",
      "notes": "Intermediate variant (12 layers). Previously not tracked."
    },
    {
      "name": "LatPhon (2025) — Espanhol",
      "lang": "ES",
      "dataset": "ipa-dict (~500 test words)",
      "per": 1.2,
      "wer": null,
      "accuracy": null,
      "references": "Chary et al. (arXiv 2509.03300, 2025)",
      "wfst_baseline_per": 0.8,
      "byt5_per": 4.2,
      "improvement_vs_byt5_pct": 71.4,
      "notes": "LatPhon slightly worse than WFST for ES; Spanish has shallow orthography"
    },
    {
      "name": "LatPhon (2025) — Frances",
      "lang": "FR",
      "dataset": "ipa-dict (~500 test words)",
      "per": 3.1,
      "wer": null,
      "accuracy": null,
      "references": "Chary et al. (arXiv 2509.03300, 2025)",
      "wfst_baseline_per": 3.2,
      "byt5_per": 6.8,
      "improvement_vs_byt5_pct": 54.4,
      "notes": "Comparable to WFST for FR; repeated vowel simplification is main error"
    },
    {
      "name": "LatPhon (2025) — Ingles",
      "lang": "EN",
      "dataset": "ipa-dict (~500 test words)",
      "per": 7.8,
      "wer": null,
      "accuracy": null,
      "references": "Chary et al. (arXiv 2509.03300, 2025)",
      "wfst_baseline_per": 5.4,
      "byt5_per": 14.3,
      "improvement_vs_byt5_pct": 45.5,
      "notes": "LatPhon worse than WFST for EN; deep irregular orthography favors tuned rule-based systems"
    },
    {
      "name": "LatPhon (2025) — Romeno",
      "lang": "RO",
      "dataset": "ipa-dict (~500 test words)",
      "per": 2.4,
      "wer": null,
      "accuracy": null,
      "references": "Chary et al. (arXiv 2509.03300, 2025)",
      "wfst_baseline_per": 1.6,
      "byt5_per": 8.9,
      "improvement_vs_byt5_pct": 73.0,
      "notes": "LatPhon beats ByT5 but below WFST for Romanian"
    },
    {
      "name": "Rule-Based G2P — Portugues Europeu (Braga & Coelho, 2006)",
      "lang": "PT-EU",
      "dataset": "Artigos de jornal (European Portuguese)",
      "per": null,
      "wer": null,
      "accuracy": 98.8,
      "references": "Braga & Coelho (2006) — RECIPP IPP.",
      "notes": "Rule-based FST; 98.80% accuracy on newspaper articles. Fails on neologisms/foreign words. Historical baseline for PE."
    },
    {
      "name": "LatPhon (2025)  Media 5 idiomas (ES/FR/EN/RO)",
      "lang": "Multilingue (PT/ES/FR/EN/RO)",
      "dataset": "ipa-dict (~500 test words per lang)",
      "per": 3.6,
      "wer": null,
      "accuracy": null,
      "references": "Chary et al. (arXiv 2509.03300, 2025)",
      "wfst_baseline_per": 2.75,
      "byt5_per": 8.325,
      "improvement_vs_byt5_pct": 56.6,
      "notes": "Average across 5 Romance+EN languages (removed Italian for project focus); LatPhon slightly below WFST average but 77x smaller than ByT5"
    }
  ],
  "benchmarks_explanation": {
    "paradigms": {
      "phonetisaurus_wfst": {
        "era": "2012-2015 (Estatística)",
        "architecture": "Weighted Finite-State Transducers + EM-based alignment",
        "key_insight": "Mapeamento m-to-1 e 1-to-m via n-gramas; eficiente mas superado",
        "representative_metric": "WER 25.6% (EN CMUDict)"
      },
      "lstm_dblstm_ctc": {
        "era": "2015-2019 (RNN)",
        "architecture": "Bidirectional LSTM com CTC loss; sem alinhamento explícito",
        "key_insight": "Capta dependências longo alcance; melhor que WFST",
        "representative_metric": "PER ~5.4% (EN CMUDict)"
      },
      "transformer_attention": {
        "era": "2019-2022 (Self-Attention)",
        "architecture": "Encoder-decoder paralelo com multi-head attention",
        "key_insight": "DeepPhonemizer 2.4M params supera LSTM com 14.5M; 6× mais eficiente",
        "representative_metric": "PER 5.23% (EN), 0.40% (IT)"
      },
      "byt5_multilingual": {
        "era": "2022-2025 (Massiva Multilíngue)",
        "architecture": "Byte-level Transformer; 100+ idiomas",
        "key_insight": "ByT5 > mT5 para G2P (byte melhor que token); 8.9% PER média multilíngue",
        "representative_metric": "PER 8.9% (multilíngue), 1.3% (EN específico)"
      },
      "latphon_specialized": {
        "era": "2025 (Especialização Romance)",
        "architecture": "Transformer 7.5M; language-ID embedding crítico (1K params)",
        "key_insight": "Especialização > escala: 0.86% PER PT-BR vs 9.1% ByT5 (77× menor modelo)",
        "representative_metric": "PER 0.86% (PT-BR), eficiência 30MB checkpoint"
      }
    },
    "fg2p_positioning": {
      "comparison_baseline": "DeepPhonemizer IT (0.40% PER, 70k train) — similar size e scope",
      "fg2p_exp2": "PER 0.58%: competitivo com DeepPhonemizer IT, apenas 57k train",
      "fg2p_exp3_panphon": "PER 0.60%, mas 4.3M params vs ByT5 299M; 69× redução para desempenho comparável",
      "key_positioning": "Especialização médio-porte em PT-BR; menor que SOTA (LatPhon 0.86%) mas com menos dados"
    },
    "dataset_impact": {
      "test_size_importance": "LatPhon 500 vs FG2P 28.782 (57× diferença); FG2P mais confiável estatisticamente",
      "stratification": "FG2P χ²  p=0.678 (excelente); garante generalização equânime",
      "language_complexity": "EN > IT > PT-BR em dificuldade ortográfica; esperar PER maior em EN"
    }
  },
  "notes": [
    "FG2P dataset stratification: χ² p=0.678, Cramér V=0.004 (excellent quality split).",
    "LatPhon (SOTA 2025) uses only 500 test samples vs FG2P 28.782 (57× larger for superior statistical reliability).",
    "ByT5 metrics: 8.9% PER is MULTILINGUAL AVERAGE across 100+ languages; models shown (Tiny 8/16, Small) are Google's byte-level seq2seq.",
    "DeepPhonemizer variants: Italian 0.40% (Romance language) vs English 5.23% (irregular orthography); shows language orthographic complexity impact.",
    "Phonetisaurus (2012) is classical WFST baseline; modern methods (Transformer/ByT5) represent 10+ year improvement trajectory.",
    "PER comparison: DeepPhonemizer (IT) 0.40% trained on 70k words; FG2P Exp2 0.58% with 57k words + PanPhon features (4.3M params competitive with 299M ByT5).",
    "PanPhon embeddings (24 articulatory features) enable competitive performance with 4.3M params (Exp3) vs ByT5's 299M parameters (77× reduction).",
    "EN is more irregular than PT-BR; direct metric comparisons must account for language-specific orthographic characteristics.",
    "FG2P vowel confusions (ɛ↔e, ɔ↔o) represent 60% of WER but are linguistically justified in word-isolated inference without semantic context.",
    "Top error in FG2P Exp2: ɛ→e (214×) and e→ɛ (202×), reflecting Portuguese mid-vowel ambiguity without semantic/morphological context.",
    "Graduated metrics (PanPhon) reveal Exp3 error distribution more phonologically informed than classical metrics suggest.",
    "ByT5 is massively multilingual (299M params, 100+ languages); specialized models (LatPhon 7.5M) outperform on single languages due to parameter efficiency.",
    "For experimental methodology details and references, see docs/LITERATURE.md and source papers listed above."
  ]
}