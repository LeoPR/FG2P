---
marp: true
theme: default
paginate: true
backgroundColor: "#fff"
# [UNIFIED] FG2P Presentation â€” automatically generates full or compact
# Generator: python src/reporting/presentation_generator.py --mode full|compact
author: "Leonardo Marques de Souza"
professor: "Prof. Dr. AndrÃ© EugÃªnio Lazzaretti"
institution: "Universidade TecnolÃ³gica Federal do ParanÃ¡ (UTFPR)"
course: "Deep Learning"
year: "Final de 2025"
sota_per: "0,49%"
sota_wer: "4,96%"
test_words: "28.782"
oov_accuracy: "100%"
style: |
  section { font-size: 22px; }
  h1 { color: #1a3a6b; }
  h2 { color: #1a3a6b; border-bottom: 2px solid #1a3a6b; padding-bottom: 4px; }
  table { font-size: 18px; width: 100%; }
  code { background: #f4f4f4; padding: 2px 4px; border-radius: 2px; }
  pre { background: #1e1e2e; color: #cdd6f4; padding: 16px; border-radius: 6px; }
---

[modes: full, compact]

# FG2P
## ConversÃ£o Grafema-Fonema para o PortuguÃªs Brasileiro

**Modelo BiLSTM com Distance-Aware Loss**

> Dado o texto `"computador"`, o modelo produz `k Ãµ p u t a Ëˆ d o x`

**Resultados alcanÃ§ados**
- PER 0,49% Â· WER 4,96% Â· 28.782 palavras de teste
- 100% de acerto em palavras PT-BR fora do vocabulÃ¡rio de treino

---

[modes: full, compact]

<!-- ref: article/ARTICLE.md Â§1 â€” IntroduÃ§Ã£o -->
## O que Ã© o problema G2P?

**Grafema â†’ Fonema**

```
Entrada  :  "casa"
SaÃ­da    :  k  a  z  a
```

```
Entrada  :  "cena"
SaÃ­da    :  s  e  n  É™
```

**O mesmo grafema `c` â†’ dois fonemas diferentes**
- `c` antes de vogal posterior/baixa â†’ `/k/`
- `c` antes de vogal anterior alta â†’ `/s/`

O modelo nÃ£o memoriza palavras â€” aprende *regras* que generalizam.

---

[modes: full, compact]

<!-- ref: article/ARTICLE.md Â§1 + Â§2.3 â€” Desafios PT-BR, Regra É£/x -->
## Por que PT-BR Ã© difÃ­cil?

### 3 desafios principais

| Desafio | Exemplo | Regra |
|---------|---------|-------|
| Ambiguidade grafÃªmica | "cama" vs "cena" | câ†’k ou câ†’s |
| DependÃªncia de posiÃ§Ã£o | "churrasco" (rrâ†’x) Â· "computador" (r coda finalâ†’x) Â· "borboleta" (r+vozeadaâ†’É£) | r muda conforme posiÃ§Ã£o silÃ¡bica |
| NeutralizaÃ§Ã£o vocÃ¡lica | "seco" (É› tÃ´nico) vs "secada" (e Ã¡tono) | É› tÃ´nico â†’ e/Éª Ã¡tono |

**ConsequÃªncia prÃ¡tica**: ~60% dos erros do modelo sÃ£o neutralizaÃ§Ãµes vocÃ¡licas legÃ­timas â€” ambiguidade irredutÃ­vel sem contexto prosÃ³dico.

---

[modes: full, compact]

<!-- ref: article/ARTICLE.md Â§2.1 + Â§2.2 â€” Corpus e Split -->
## Os Dados

**95.937 pares** (palavra, transcriÃ§Ã£o IPA)
- Fonte: dicionÃ¡rio fonÃ©tico PT-BR
- Charset treinado: `aâ€“z` (exceto k, w, y) + `Ã§ Ã¡ Ã  Ã¢ Ã£ Ã© Ãª Ã­ Ã³ Ã´ Ãµ Ãº Ã¼`

**DivisÃ£o: 60% / 10% / 30%** (estratificada)

| Subconjunto | Tamanho |
|-------------|---------|
| Treino | 57.561 palavras |
| ValidaÃ§Ã£o | 9.594 palavras |
| Teste | **28.782 palavras** |

**Descoberta**: split 60/10/30 supera 70/10/20 em **âˆ’41% PER**
â†’ Mais dados de treino nem sempre = modelo melhor

---

[modes: full, compact]

<!-- ref: article/ARTICLE.md Â§3 â€” Arquitetura BiLSTM -->
## A Arquitetura

```
"c a s a"   â†â€” grafemas de entrada
    â†“
[ Embedding ]  192D: cada letra â†’ vetor
    â†“
[ BiLSTM Encoder ]  2 camadas, 384D
  â†’ lÃª a palavra nos dois sentidos
  â†’ "c" em "cama" vs "cena" â†’ representaÃ§Ãµes diferentes
    â†“
[ AtenÃ§Ã£o Bahdanau ]
  â†’ decoder "olha" para onde precisa na palavra
  â†’ aprende: "nh" â†’ foco nas duas letras juntas
    â†“
[ LSTM Decoder ]  gera fonema por fonema
    â†“
k  a  z  a   â†â€” fonemas de saÃ­da
```

---

[modes: full]

<!-- ref: article/ARTICLE.md Â§3.2 â€” Mecanismo de AtenÃ§Ã£o Bahdanau -->
## Por que AtenÃ§Ã£o?

### O Mecanismo de Bahdanau

**AtenÃ§Ã£o Bahdanau** = sistema que calcula pesos dinÃ¢micos (0â€“1) para cada letra da palavra de entrada. O decoder usa esses pesos para decidir "onde olhar" ao gerar cada fonema:

```
Para cada fonema gerado, o decoder pergunta:
  "Qual letra da palavra Ã© mais importante para gerar este som?"

Bahdanau responde com pesos:
  s=0.70 significa "preste atenÃ§Ã£o em 's' com 70% de confianÃ§a"
  c=0.20 significa "preste atenÃ§Ã£o em 'c' com 20% de confianÃ§a"
  o=0.02 significa "ignore 'o', Ã© sÃ³ 2% relevante"
```

Esses pesos sÃ£o **aprendidos pelo modelo durante o treino**, nÃ£o prÃ©-definidos.

### Por que funciona:

**Sem atenÃ§Ã£o**: encoder cria 1 vetor resumido para TODA a palavra
```
"biscoito" â†’ encoder processa: b-i-s-c-o-i-t-o
                                       â†“ (BiLSTM nas 2 direÃ§Ãµes)
            Comprime tudo em 1 vetor (384 nÃºmeros)
            Este vetor Ã© um "resumo geral" da palavra inteira

Problema: 384 nÃºmeros precisam guardar TUDO sobre a palavra:
  "qual letra estÃ¡ na posiÃ§Ã£o 3? qual na 4? padrÃ£o sc?"
  Ã‰ como comprimir um livro inteiro em um parÃ¡grafo!

Resultado: decoder recebe esse resumo vago e gera cada fonema
  Ao gerar /k/: nÃ£o consegue verificar "letra 3 Ã© s, letra 4 Ã© c"
  Resultado: trata como sÃ­mbolos isolados â†’ /s/ + /k/ (ERRADO!)
```

**Com atenÃ§Ã£o Bahdanau**: decoder pode consultar TODOS os estados intermediÃ¡rios
```
"biscoito" â†’ encoder TAMBÃ‰M comprime (384D por letra):
  b(384D)  i(384D)  s(384D)  c(384D)  o(384D)  i(384D)  t(384D)  o(384D)
  â†“ (cada um Ã© um "resumo" dessa letra + contexto)

Ao gerar /k/ na posiÃ§Ã£o 3:
  AtenÃ§Ã£o calcula pesos dinÃ¢micos:
    b=0.02  i=0.03  s=0.70  c=0.20  o=0.02  i=0.02  t=0.01  o=0.00
  â†“
  Decoder acessa: 0.70 Ã— s(384D) + 0.20 Ã— c(384D) + ...
  Resultado: "olha fortemente para s e c" â†’ reconhece padrÃ£o "sc"
  â†“
  Gera /k/ corretamente!
```

Essencial para padrÃµes de alinhamento n:1 como:
- `ch` â†’ `/Êƒ/` (2 grafemas â†’ 1 fonema)
- `nh` â†’ `/É²/` (2 grafemas â†’ 1 fonema)
- `x` â†’ `/Êƒ/` ou `/ks/` dependendo do contexto

---

[modes: full]

<!-- ref: article/ARTICLE.md Â§4.1 â€” LimitaÃ§Ã£o da CrossEntropy -->
## O Problema da CrossEntropy

**CrossEntropy Ã© binÃ¡ria: certo (0) ou errado (1) â€” sem gradaÃ§Ã£o**

```
CenÃ¡rio A â€” Erro de 1 feature (quase certo):
  PrediÃ§Ã£o: É› (aberta)    Correto: e (fechada)
  DiferenÃ§a: mesma posiÃ§Ã£o, sÃ³ altura da lÃ­ngua
  CrossEntropy: penalidade = 1.0

CenÃ¡rio B â€” Erro catastrÃ³fico (completamente errado):
  PrediÃ§Ã£o: k (oclusiva velar)    Correto: a (vogal baixa)
  DiferenÃ§a: classes fonolÃ³gicas opostas
  CrossEntropy: penalidade = 1.0  â† PROBLEMA: penalidade IDÃŠNTICA!
```

**O Problema**: Ambos recebem penalidade = 1.0, mesmo sendo muito diferentes!
â†’ Modelo nÃ£o consegue aprender que É›â†’e (quase acerto) merecia penalidade menor
â†’ Trata erros de "quase acerto" igual a erros "catastrÃ³ficos"

---

[modes: full, compact | label: da_loss_full, da_loss_compact]

<!-- ref: article/ARTICLE.md Â§4.2 â€” Distance-Aware Loss -->
## A Distance-Aware Loss

**SoluÃ§Ã£o**: Adicionar um sinal fonolÃ³gico ao erro

```
L = L_CE + Î» Â· d(Å·, y) Â· p(Å·)
```

**O que cada parte faz:**
- **L_CE**: Penalidade base do CrossEntropy
- **Î» (lambda)**: Peso do sinal fonolÃ³gico â€” empiricamente Ã³timo = **0,20**
- **d(Å·, y)**: DistÃ¢ncia articulatÃ³ria entre predito e correto
- **p(Å·)**: ConfianÃ§a do modelo na sua prediÃ§Ã£o (softmax)

â†’ Permite ao modelo aprender que `É›â†’e` Ã© "quase OK" enquanto `kâ†’a` Ã© "crÃ­tico"

---

[modes: full]

<!-- ref: article/ARTICLE.md Â§4.2 â€” FunÃ§Ã£o de distÃ¢ncia fonolÃ³gica -->
## DA Loss â€” ExplicaÃ§Ã£o de d(Å·, y)

**A "rÃ©gua fonolÃ³gica" que mede distÃ¢ncia entre fonemas**

```
Tabela de DistÃ¢ncias (PanPhon 24 features articulatÃ³rios):

d(e, É›) = 0.10    â† mesma posiÃ§Ã£o (mÃ©dia anterior), sÃ³ abertura
d(p, b) = 0.05    â† oclusivas bilabiais, sÃ³ vozeamento
d(s, Êƒ) = 0.15    â† fricativas, ponto diferente (alveolar vs palatal)
d(a, k) = 0.90    â† vogal baixa vs. oclusiva velar â€” classe oposta!
d(., Ëˆ) = 1.0     â† sÃ­mbolos estruturais (mÃ¡xima distÃ¢ncia)
```

**Insight**: Erros "prÃ³ximos" (d pequeno) recebem penalidade fraca
â†’ Erros "distantes" (d grande) recebem penalidade forte

---

[modes: full]

<!-- ref: article/ARTICLE.md Â§4.2 â€” Exemplo numÃ©rico DA Loss -->
## DA Loss â€” Exemplo Passo a Passo

**Palavra**: "cena" Â· **PosiÃ§Ã£o**: grafema "c" Â· **Correto**: `/s/`

```
PASSO 1 â€” Modelo produz distribuiÃ§Ã£o de probabilidades (softmax):
  s=42%   Êƒ=35%   z=12%   t=6%   ...
  â†“ argmax (escolhe o maior)
  PrediÃ§Ã£o: Êƒ  (errado! esperado era s)

PASSO 2 â€” CrossEntropy (sÃ³ olha para o correto, que Ã© s):
  p(s) = 0.42   â† a probabilidade que o modelo deu para o fonema CORRETO
  L_CE = âˆ’log(0.42) = 0.87   â† penaliza por nÃ£o ter escolhido s

PASSO 3 â€” DistÃ¢ncia articulatÃ³ria (Êƒ â‰  s, mas prÃ³ximos):
  d(Êƒ, s) = 0.15   â† fricativas, mesmo modo, sÃ³ ponto diferente

PASSO 4 â€” Term extra da DA Loss:
  Î» Ã— d Ã— p(pred) = 0.20 Ã— 0.15 Ã— 0.35 = 0.010
                    (lambda) (distÃ¢ncia) (confianÃ§a do modelo em Êƒ)

TOTAL: 0.87 + 0.01 = 0.88
```

**ComparaÃ§Ã£o**: Se tivesse predito `k` (completamente errado)?
â†’ d(k,s) = 0.80 â†’ extra = 0.056 â†’ total = 0.93  (penalidade 5% maior!)

**Detalhe importante**: CE sÃ³ penaliza "nÃ£o escolheu s", mas DA Loss tambÃ©m penaliza "escolheu algo muito distante de s"

---

[modes: full]

## Por que multiplicar por $p(\hat{y})$?

**O fator de confianÃ§a evita punir incerteza honesta:**

```
Ã‰poca 5 â€” modelo incerto:
  Prediz k com 52% â†’ penalidade moderada
  "Ainda aprendendo, sÃ³ corrigindo a direÃ§Ã£o"

Ã‰poca 40 â€” modelo confiante:
  Prediz k com 91% â†’ penalidade alta
  "VocÃª estÃ¡ MUITO certo de algo completamente errado"
```

AnÃ¡logo ao **label smoothing**, mas proporcional Ã  distÃ¢ncia fonolÃ³gica â€” nÃ£o uniforme.

---

[modes: full]

<!-- ref: article/ARTICLE.md Â§8.1 â€” Separadores silÃ¡bicos -->
## Separadores SilÃ¡bicos â€” O Trade-off

**Adicionando `.` como token de fronteira silÃ¡bica:**

```
Exp9   (sem sep):  k Ãµ p u t a Ëˆ d o x
Exp102 (com sep):  k . Ãµ p . u . t a . Ëˆ d o x .
```

**Efeito nas mÃ©tricas:**

| Experimento | PER | WER | ComentÃ¡rio |
|---|-----|-----|---|
| Sem separadores (Exp9) | 0,58% | **4,96%** | SOTA WER â† menos erros de palavra |
| Com separadores (Exp102/104b) | **0,49â€“0,52%** | 5,43â€“5,79% | SOTA PER â† menos erros de fonema |

**Por quÃª?** Cada separador mal-posicionado = palavra inteira errada (WER binÃ¡rio)
â†’ Trade-off Pareto fundamental: *nÃ£o* se resolve ajustando hiperparÃ¢metros
â†’ DA Loss + separadores testados (Exp103/104b) â€” trade-off persiste independente da loss function

---

[modes: full]

<!-- ref: article/ARTICLE.md Â§4.3 â€” Override de distÃ¢ncia -->
## DistÃ¢ncias Customizadas â€” O Bug que Virou Feature

**Problema**: `.` e `Ëˆ` tÃªm vetor **zero** no PanPhon

```
d(., Ëˆ) = 0.0   â† Loss nÃ£o penaliza confusÃ£o entre eles!
d(., a) = d(Ëˆ, a)   â† mesmo valor â€” indistinguÃ­veis
```

**SoluÃ§Ã£o (Exp104b)**: override pÃ³s-normalizaÃ§Ã£o

```python
for sym in {'.', 'Ëˆ'}:
    for other in vocab:
        distance[sym][other] = 1.0  # distÃ¢ncia mÃ¡xima
```

**Resultado:**

| Exp | PER | WER | Erros .â†”Ëˆ |
|-----|-----|-----|-----------|
| Sem override (baseline) | 0,53% | 5,73% | ~107 |
| Exp104 (bug: prÃ©-normalizaÃ§Ã£o) | 0,54% | 5,88% | ~119 |
| **Exp104b (pÃ³s-normalizaÃ§Ã£o âœ“)** | **0,49%** | **5,43%** | ~106 |

â†’ **NOVO SOTA PER: 0,49%** mesmo sem eliminar as confusÃµes estruturais

---

[modes: full, compact | label: experiments_full, experiments_compact]

## Todos os Experimentos â€” EvoluÃ§Ã£o

```
PER (%)
1.12 â”‚ â— Exp0 (70/10/20)
0.66 â”‚         â— Exp1 (60/10/30) âˆ’41%
0.63 â”‚                 â— Exp5 (9.7M)  â— Exp6 (DA Loss)
0.61 â”‚                         â— Exp7 (Î»=0.20)
0.60 â”‚                 â— Exp2 (17.2M)
0.58 â”‚                                 â— Exp9 â† SOTA WER (4.96%)
0.52 â”‚                                         â— Exp102 (sep)
0.49 â”‚                                                 â— Exp104b â† SOTA PER
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      Fase1   Fase2    Fase3    Fase4    Fase5    Fase6
```

Phase 6C (ablaÃ§Ãµes): Exp105 0,54% Â· Exp106 0,58% + **30.2 w/s** âš¡ Â· Phase 7: Exp107 em preparo (95% treino)

---

[modes: full]

## Ranking Final (Phase 6C Completa)

| Modelo | PER | WER | Speed | Melhor para |
|--------|-----|-----|-------|-------------|
| **Exp104b** | **0,49%** | 5,43% | 11.7 w/s | TTS, alinhamento fonÃ©tico |
| **Exp9** | 0,58% | **4,96%** | 11.7 w/s | NLP, busca, indexaÃ§Ã£o |
| **Exp106** | 0,58% | 6,12% | **30.2 w/s âš¡** | LatÃªncia crÃ­tica (2.58Ã—) |
| Exp105 | 0,54% | 5,87% | 11.7 w/s | ValidaÃ§Ã£o com menos dados |
| Exp1 | 0,66% | 5,65% | â€” | Baseline histÃ³rico |

Todos: 9.7M parÃ¢metros Â· BiLSTM 2 camadas Â· Embedding 192D

---

[modes: full]

<!-- ref: article/ARTICLE.md Â§8.4 â€” AblaÃ§Ã£o Exp105/Exp106 -->
## Phase 6C: AblaÃ§Ã£o de Dados e Ortografia (Exp105 + Exp106)

**Exp105 â€” ReduÃ§Ã£o de Dados (50% treino)**
- Pergunta: Quanto dados Ã© suficiente? Modelo robusto com 10% menos?
- Resultado: PER 0,54% (vs 0,49% Exp104b) â€” +0.05% modesto
- ConclusÃ£o: âœ… Modelo escala robustamente com menos dados

**Exp106 â€” Filtro de HÃ­fen (50% treino, sem `-`)**
- Pergunta: HÃ­fen (-) Ã© ortogrÃ¡fico ou fonolÃ³gico? Impacto?
- Entrada: "abaixo-assinado" â†’ sem-hÃ­fen: "abaixoassinado"
- Resultado: PER 0,58% (vs 0,54% Exp105) â€” +0.04% negligenciÃ¡vel
- **ğŸš€ Descoberta**: Velocidade 2,58x mais rÃ¡pida! (30.2 w/s vs 11.7 w/s)
- ConclusÃ£o: âœ… HÃ­fen nÃ£o afeta fonologia. CharVocab menor (38 vs 39) permite speedup prÃ¡tico

**Impactos Resumidos:**
- 10% menos dados (Exp105): +0.05% PER â€” AceitÃ¡vel âœ…
- Sem hÃ­fen (Exp106): +0.04% PER, +2.58x Speed â€” Use para latÃªncia crÃ­tica âš¡

---

[modes: full, compact | label: generalization_full, generalization_compact]

<!-- ref: article/ARTICLE.md Â§7 â€” AvaliaÃ§Ã£o de GeneralizaÃ§Ã£o -->
## AvaliaÃ§Ã£o de GeneralizaÃ§Ã£o â€” Design

**Pergunta central**: o modelo *memorizou* ou *aprendeu regras*?

**31 palavras em 6 categorias:**

- **GeneralizaÃ§Ã£o PT-BR** (9): Neologismos e portmanteaux com chars no vocab
- **Consoantes duplas** (5): lazzaretti, cappuccino â†’ reduÃ§Ã£o de geminadas
- **Anglicismos** (5): mouse, site â†’ fonologia inglesa
- **Chars OOV** (3): wifi, yoga â†’ falha esperada e documentada
- **PT-BR reais OOV** (5): puxadinho, zunido â†’ **prova de generalizaÃ§Ã£o**
- **Controles** (4): biscoito, computador â†’ sanidade

---

[modes: full, compact]

<!-- ref: article/ARTICLE.md Â§7.3 + Â§7.5 â€” OOV 5/5 -->
## Resultado que mais importa

### Palavras PT-BR reais fora do vocabulÃ¡rio: **5/5 âœ“**

**Exemplos testados (todos corretos):**
- `puxadinho` â†’ p u Êƒ a Ëˆ d Ê’ Ä© É² ÊŠ âœ“
- `malcriado` â†’ m a w k É¾ i Ëˆ a d ÊŠ âœ“
- `arrombado` â†’ a x Ãµ Ëˆ b a d ÊŠ âœ“
- `abacatada` â†’ a b a k a Ëˆ t a d É™ âœ“
- `zunido` â†’ z u Ëˆ n i d ÊŠ âœ“

**O modelo aprendeu regras produtivas do PT-BR:**
â†’ PalatalizaÃ§Ã£o (xâ†’Êƒ, dÊ’), coda (lâ†’w, rrâ†’x), nasalizaÃ§Ã£o (omâ†’Ãµ)
â†’ **NÃ£o memorizou, aprendeu regras!**

---

[modes: full]

## Resultados de GeneralizaÃ§Ã£o â€” VisÃ£o Geral

**Resumo por categoria de teste:**

- **PT-BR reais OOV**: 5/5 (100%) | Score 100% â†’ Aprendeu regras, nÃ£o memorizou âœ“
- **Controles**: 4/4 (100%) | Score 100% â†’ Regra É£/x aprendida corretamente âœ“
- **GeneralizaÃ§Ã£o PT-BR**: 4/9 (44%) | Score 97% â†’ Near-misses articulatÃ³rios
- **Consoantes duplas**: 1/5 (20%) | Score 81% â†’ Geminadas estrangeiras: gap
- **Anglicismos**: 1/5 (20%) | Score 71% â†’ Fonologia inglesa Ã© OOV
- **Chars OOV** (k/w/y): 0/3 (0%) | Score 68% â†’ Falha esperada e documentada

**Score fonolÃ³gico** = mÃ©trica de 0â€“100% independente do G2P
â†’ "97%" = mesmo quando erra, o fonema estÃ¡ na famÃ­lia articulatÃ³ria certa

---

[modes: full, compact]

<!-- ref: article/ARTICLE.md Â§2.3 â€” DistribuiÃ§Ã£o complementar É£/x -->
## Descoberta FonolÃ³gica â€” Regra É£/x no PT-BR

### O que Ã© Coda?

**Coda silÃ¡bica** = consoante(s) que fecham a sÃ­laba (apÃ³s vogal)
```
com-pu-ta-dor
           â””â”€ "r" em coda final = /x/ (r no fim da palavra)

bor-bo-le-ta
â””â”€ "r" em coda interna = /É£/ (r nÃ£o-final, antes de consoante vozeada)
```

### DistribuiÃ§Ã£o Complementar Perfeita (0 exceÃ§Ãµes no corpus)

```
/r/ em coda FINAL de palavra          â†’ x   (fricativa surda)
/r/ em coda INTERNA antes C vozeada   â†’ É£   (fricativa sonora â€” assimilaÃ§Ã£o)
```

**Exemplos**:
- computador â†’ x (coda final) âœ“
- churrasco â†’ x (rr) âœ“
- borboleta â†’ É£ (antes de b vozeada) âœ“
- aÃ§ucarzÃ£o â†’ É£ (antes de z vozeada) âœ“

**Dados**: 19.730 Ã— x (final) Â· 5.449 Ã— É£ (prÃ©-vozeado) Â· **zero exceÃ§Ãµes**

â†’ O modelo aprendeu **assimilaÃ§Ã£o regressiva de vozeamento** (fenÃ´meno universal) por puro contato com dados â€” validaÃ§Ã£o da capacidade de generalizaÃ§Ã£o

---

[modes: full]

## A MÃ©trica FonolÃ³gica (Score)

**Problema**: mÃ©tricas binÃ¡rias (certo/errado) nÃ£o mostram *o quanto* se errou

**SoluÃ§Ã£o implementada** â€” score 0â€“100% independente do G2P:

```python
_group_dist("É£", "x") = 0.1   # mesma famÃ­lia FR_velar
_group_dist("a",  "k") = 0.9   # V_baixo vs OC_velar â€” opostos
```

| Score | RÃ³tulo | Significado |
|-------|--------|-------------|
| 100% | exato | TranscriÃ§Ã£o idÃªntica |
| 90â€“99% | muito prÃ³ximo | 1 sub. na mesma famÃ­lia |
| 70â€“89% | prÃ³ximo | Subs. em famÃ­lias relacionadas |
| 50â€“69% | parcial | DiferenÃ§as estruturais |
| < 50% | distante | Falha substancial |

**Uso**: `G2PPredictor._phonological_score(pred, ref)` â†’ independente de treino

---

[modes: full, compact]

## Como Usar â€” 3 comandos essenciais

**1. Testar uma palavra:**
```bash
python src/inference_light.py --index 18 --word computador
# â†’ k Ãµ p u t a Ëˆ d o x .
```

**2. Avaliar banco de generalizaÃ§Ã£o:**
```bash
python src/inference_light.py --index 18 --neologisms docs/data/generalization_test.tsv
```

**3. Modo interativo:**
```bash
python src/inference_light.py --index 18 --interactive
```

---

[modes: full]

## Escolha do Modelo na PrÃ¡tica

```
VocÃª quer...
    â”œâ”€ Acertar mais palavras inteiras?
    â”‚   â””â”€ Use Exp9 (index=11) â€” WER 4.96%
    â”‚       ex: indexaÃ§Ã£o de texto, busca fonÃ©tica, NLP
    â”‚
    â””â”€ Acertar mais fonemas individuais?
        â””â”€ Use Exp104b (index=18) â€” PER 0.49%
            ex: TTS, alinhamento fonÃ©tico, anÃ¡lise linguÃ­stica
```

**Para palavras PT-BR "novas"**: ambos generalizam bem.
**Para anglicismos** e **geminadas**: espere erros â€” estÃ£o alÃ©m do corpus.
**Para k/w/y**: mapeamento para UNK â€” avise o usuÃ¡rio.

---

[modes: full, compact]

## ComparaÃ§Ã£o com Estado da Arte

| Sistema | PER | WER | Idioma | Teste (N) | Params |
|---------|-----|-----|--------|-----------|--------|
| **FG2P Exp104b** | **0,49%** | 5,43% | PT-BR | 28.782 | 9,7M |
| **FG2P Exp9** | 0,58% | **4,96%** | PT-BR | 28.782 | 9,7M |
| LatPhon 2025 | 0,86% | â€” | PT-BR | 500 | n/d |
| ByT5-Small | 8,9% | â€” | 100 idiomas | ~500/lang | 299M |

**FG2P usa 9,7M params** â€” ByT5-Small usa 299M (30Ã— maior, zero-shot)

---

[modes: full, compact]

<!-- ref: article/ARTICLE.md Â§9 â€” LimitaÃ§Ãµes -->
## Limites Bem-Definidos

| Limite | Causa | SoluÃ§Ã£o Futura |
|--------|-------|----------------|
| HomÃ³grafos heterÃ³fonos (jogo, gosto) | Ambiguidade lÃ©xico-sintÃ¡tica sem contexto | Pipeline NLPâ†’G2P em sÃ©rie |
| Geminadas (zz, pp, tt) | Sem exemplos no corpus | Ampliar corpus com emprÃ©stimos |
| Fonologia inglesa (site, mouse) | OOV fonolÃ³gico | Corpus bilÃ­ngue adaptado |
| k, w, y | OOV de charset | Re-treinar com charset ampliado |
| É£â†’x em coda | Sem restriÃ§Ã£o fonotÃ¡tica | Integrar fonotÃ¡tica PT-BR |
| `.`â†”`Ëˆ` confusÃ£o | Posicional, nÃ£o apenas distÃ¢ncia | MÃ©tricas separadas + beam restrito |

---

[modes: full, compact]

## PrÃ³ximos Passos

### Curto prazo
- **Stress Accuracy**: % de acentos na sÃ­laba certa
- **Boundary F1**: precisÃ£o/revocaÃ§Ã£o das fronteiras silÃ¡bicas
- Corpus ampliado com emprÃ©stimos e geminadas

### MÃ©dio prazo
- **EspaÃ§o articulatÃ³rio 7D contÃ­nuo**: substituir PanPhon binÃ¡rio
  - SÃ­mbolos estruturais (`.`, `Ëˆ`) distinguÃ­veis intrinsecamente
  - Suporta interpolaÃ§Ã£o entre sons

### Longo prazo
- **UniversalizaÃ§Ã£o multilÃ­ngue**: o espaÃ§o 7D Ã© universal
  - Transfer learning para novos idiomas com corpus reduzido
  - PT-BR â†’ Espanhol â†’ InglÃªs via fine-tuning

---

[modes: full, compact]

## Resumo em 5 Pontos

1. **BiLSTM + AtenÃ§Ã£o** â€” arquitetura clÃ¡ssica, bem compreendida, SOTA em PT-BR com 9,7M params

2. **Distance-Aware Loss** â€” sinal fonolÃ³gico que ensina o modelo a "preferir erros inteligentes"; Î»=0,20 Ã³timo empÃ­rico

3. **Separadores criam trade-off Pareto** â€” PERâ†“ + WERâ†‘ de forma irredutÃ­vel; escolha depende da aplicaÃ§Ã£o

4. **DistÃ¢ncias customizadas corrigem vetor zero** â€” bug no PanPhon para sÃ­mbolos estruturais; fix pÃ³s-normalizaÃ§Ã£o â†’ SOTA PER 0,49%

5. **O modelo generaliza regras PT-BR** â€” 100% em palavras reais OOV; falhas tÃªm limites bem-definidos (charset, corpus, fonologia estrangeira)

---

[modes: full, compact]

# Obrigado

**FG2P** Â· PT-BR G2P BiLSTM

```
"biscoitinhozÃ£o" â†’ b i s k o y t Êƒ Ä© É² É” Ëˆ z Ã£ ÊŠÌƒ
```

CÃ³digo: `src/` Â· Dados: `dicts/` Â· Docs: `docs/article/ARTICLE.md`

```bash
# Experimente agora:
python src/inference_light.py --index 18 --interactive
```

---

[modes: full, compact]

# APÃŠNDICE A: ArticulaÃ§Ãµes VocÃ¡licas

## Como os Sons Nascem na Boca

**Ponto** (Onde?)
| Zona | Exemplos | SensaÃ§Ã£o |
|------|----------|----------|
| Labial | /p/, /b/, /m/ | LÃ¡bios tocam |
| Alveolar | /t/, /d/, /s/, /z/, /n/ | LÃ­ngua nos dentes |
| Palatal | /Êƒ/, /Ê’/, /É²/, /j/ | LÃ­ngua no cÃ©u da boca |
| Velar | /k/, /É¡/ | LÃ­ngua na garganta |

**Modo** (Como passa o ar?)
- **Oclusiva**: Bloqueia completamente (/p/, /b/, /t/, /d/, /k/, /É¡/)
- **Fricativa**: Ar com atrito (/f/, /s/, /Êƒ/, /x/, /z/, /Ê’/)
- **Nasal**: Ar pela nariz (/m/, /n/, /É²/)
- **Lateral**: Ar pelos lados da lÃ­ngua (/l/)

**Vozeamento** (Cordas vibram?)
- **Vozeadas**: /b/, /d/, /É¡/, /v/, /z/, /Ê’/ â€” vibra
- **Desvozeadas**: /p/, /t/, /k/, /f/, /s/, /Êƒ/ â€” nÃ£o vibra

**Vogais** (Onde a lÃ­ngua fica)
- **Alto**: /i/, /u/ â€” lÃ­ngua perto do palato
- **MÃ©dio**: /e/, /o/, /É™/ â€” posiÃ§Ã£o intermÃ©dia
- **Baixo**: /a/ â€” boca bem aberta
- **Frente**: /i/, /e/ â€” lÃ­ngua para frente
- **TrÃ¡s**: /u/, /o/ â€” lÃ­ngua para trÃ¡s

---

[modes: full, compact]

# APÃŠNDICE B: Termos de Algoritmos

## ML BÃ¡sico

| Termo | O QuÃª |
|-------|-------|
| **Modelo** | FunÃ§Ã£o que aprende padrÃµes dos dados |
| **Treino** | Processo de ajustar parÃ¢metros para minimizar erro |
| **ValidaÃ§Ã£o** | Dados para monitorar progresso (nÃ£o treina) |
| **Teste** | Dados nunca vistos para avaliar resultado final |

## Losses (FunÃ§Ãµes de Erro)

- **Cross Entropy (CE)**: Erro base â€” todos os erros tÃªm mesma penalidade
- **Distance-Aware (DA)**: Nosso sinal â€” penalidade proporcional Ã  distÃ¢ncia articulatÃ³ria
- **FÃ³rmula**: `L = L_CE + Î» Â· d(Å·, y) Â· p(Å·)` onde Î»=0.2 (empiricamente Ã³timo)

## Arquitetura

- **RNN**: Rede que processa sequÃªncias "lembrando" do passado
- **LSTM**: VersÃ£o melhorada de RNN com memÃ³ria de longo prazo
- **Attention**: Mecanismo que permite focar em partes importantes
- **Embedding**: Converte sÃ­mbolos (letras) em vetores numÃ©ricos

## MÃ©tricas

| MÃ©trica | Foco |
|---------|------|
| **PER (Phoneme Error Rate)** | % de fonemas errados (importante para TTS) |
| **WER (Word Error Rate)** | % de palavras inteiras erradas (importante para busca) |
| **Accuracy** | % de acertos simples |

---

[modes: full, compact]

# APÃŠNDICE C: Termos do Projeto

## Conceitos Principais

- **G2P**: Converter grafemas (letras) em fonemas (sons) â€” objetivo principal
- **PT-BR**: PortuguÃªs brasileiro â€” variante modelada
- **SOTA**: State-of-the-Art â€” melhor resultado atÃ© agora
- **Trade-off**: SituaÃ§Ã£o onde melhorar uma mÃ©trica piora outra

## FenÃ´menos LinguÃ­sticos

- **Coda**: PosiÃ§Ã£o final de sÃ­laba â€” consoantes sofrem mudanÃ§as aqui
- **Stress**: AcentuaÃ§Ã£o â€” sÃ­laba tÃ´nica vs. Ã¡tona
- **ReduÃ§Ã£o vocÃ¡lica**: Vogal Ã¡tona muda de som
- **PalatalizaÃ§Ã£o**: /t/, /d/ â†’ /tÊƒ/, /dÊ’/ antes de /i/

## AvaliaÃ§Ã£o

- **Overfitting**: Memoriza dados de treino em vez de aprender regras
- **GeneralizaÃ§Ã£o**: Capacidade de acertar em dados novos e desconhecidos
- **OOV (Out-of-Vocabulary)**: SÃ­mbolos/palavras nunca vistos antes
