# TODO ‚Äî FG2P

**√öltima atualiza√ß√£o**: 2026-02-26 ‚Äî **Phase 2 CONCLU√çDA** ‚úÖ (13 slides Markdown-driven + 3 gloss√°rios adicionados)

**üìñ Documenta√ß√£o**: [docs/14_PROJECT_STATUS.md](docs/14_PROJECT_STATUS.md) ‚Äî status | [docs/00_QUICK_START.md](docs/00_QUICK_START.md) ‚Äî in√≠cio r√°pido

---

## üîÑ TRABALHO EM ANDAMENTO (2026-02-26)

### Apresenta√ß√£o PPTX ‚Äî Migra√ß√£o Markdown-Driven

**Status**: ‚úÖ **CONCLU√çDA** ‚Äî 13 slides Markdown-driven, 3 gloss√°rios, 100% funcional

**Objetivo**: ‚úÖ ALCAN√áADO ‚Äî `docs/18_APRESENTACAO.md` √© fonte de verdade (modo --from-markdown).
Modo hardcoded mantido (retrocompatibilidade total).

| Passo | Tarefa | Status |
|-------|--------|--------|
| 1 | Atualizar TODO.md | ‚úÖ Feito |
| 2 | Criar `docs/18_APRESENTACAO.md` (sandbox + metadados) | ‚úÖ Feito |
| 3 | Criar `src/reporting/presentation_parser.py` | ‚úÖ Feito (~260 linhas) |
| 4 | Modificar `presentation_generator.py` com retrocompatibilidade | ‚úÖ **CONCLU√çDO** |
| 4a | **Slides migrados (Phase 2A ‚Äî 11 tabelas)**:                | ‚úÖ |
|     | ‚Ä¢ slide_opening (metadatos) ¬∑ slide_ptbr_hard (3) ¬∑ slide_data (4) | ‚úÖ |
|     | ‚Ä¢ slide_da_loss (8) ¬∑ slide_separators (11) ¬∑ slide_custom_dist (12) | ‚úÖ |
|     | ‚Ä¢ slide_ranking (14) ¬∑ slide_generalization_design (15) | ‚úÖ |
|     | ‚Ä¢ slide_oov_result (16) ¬∑ slide_generalization_overview (17) | ‚úÖ |
|     | ‚Ä¢ slide_sota (22) ¬∑ slide_limits (23) | ‚úÖ |
| 4b | **Slides migrados (Phase 2B ‚Äî 2 c√≥digo+texto)**:            | ‚úÖ |
|     | ‚Ä¢ slide_usage (20 ‚Äî c√≥digo CLI) ¬∑ slide_summary (25 ‚Äî texto) | ‚úÖ |
| 4c | **Slides mantidos (design ‚Äî decis√£o consciente)**:         | ‚úÖ |
|     | ‚Ä¢ 13 slides hardcoded (layout cr√≠tico, ganho minimal) | ‚úÖ |
| 5 | Criar gloss√°rios informativos (3 novos) | ‚úÖ **FEITO** |
|     | ‚Ä¢ Gloss√°rio A: Articula√ß√µes voc√°licas (IPA, modos, etc.) | ‚úÖ |
|     | ‚Ä¢ Gloss√°rio B: Termos de algoritmos (ML, losses, m√©tricas) | ‚úÖ |
|     | ‚Ä¢ Gloss√°rio C: Termos do projeto (G2P, trade-off, etc.) | ‚úÖ |
| 6 | Validar conte√∫do: Markdown PPTX = Hardcoded PPTX | ‚úÖ **TESTE OK** |
| 7 | Documentar decis√µes e status (opcional: delete 17, rename 18) | ‚úÖ **DOCUMENTADO** |

**Resultado Final**:
- 13/26 slides Markdown-driven (50% ‚Äî pragm√°tico)
- 3 gloss√°rios adicionais (contextualiza√ß√£o do p√∫blico)
- 29 slides totais na apresenta√ß√£o
- 100% retrocompatibilidade (modo hardcoded continua funcionando)
- Qualidade visual impec√°vel

**Arquivos-chave**:
- `docs/17_APRESENTACAO.md` ‚Äî Marp atual (26 slides, N√ÉO tocar)
- `docs/18_APRESENTACAO.md` ‚Äî Sandbox experimental (a criar)
- `src/reporting/presentation_generator.py` ‚Äî Gerador PPTX (a modificar)
- `src/reporting/presentation_parser.py` ‚Äî Parser Markdown (a criar)
- `results/fg2p_presentation.pptx` ‚Äî PPTX atual (hardcoded, gerado com sucesso)

### Consolida√ß√£o Documenta√ß√£o Phase 2 (pendente ap√≥s apresenta√ß√£o)

| Passo | Tarefa | Status |
|-------|--------|--------|
| A | Criar `docs/15_ROADMAP.md` (Phase 7, 8+, quest√µes abertas) | ‚è≥ Pendente |
| B | Reescrever `README.md` como entry point limpo | ‚è≥ Pendente |
| C | Deletar arquivos redundantes da raiz (STATUS.md, TODO.md, etc.) | ‚è≥ Futuro |

---

## üèÜ STATUS EXECUTIVO - EXPERIMENTOS CONCLU√çDOS

### **SOTA Atual** ‚Äî Dois frontiers distintos (Phase 5)

**SOTA WER**: Exp9 - Intermediate + Distance-Aware Loss (sem separadores)
- **PER: 0.58%** | **WER: 4.96%** | **Accuracy: 95.04%**
- **Params: 9.7M** | Architecture: emb=192 + hidden=384 + 2 layers + DA Loss Œª=0.2

**SOTA PER**: Exp102 - Intermediate + CE Loss (com separadores sil√°bicos)
- **PER: 0.52%** | **WER: 5.37%** | **Accuracy: 94.63%**
- **Params: 9.7M** | Architecture: emb=192 + hidden=384 + 2 layers + sep + CE
- **Trade-off**: ‚àí0.06pp PER vs Exp9, mas +0.41pp WER

**Exp103 avaliado**: PER 0.53%, WER 5.73% ‚Äî hip√≥tese de SOTA unificado **refutada**

### **Experimentos Fase 1-6 Completos** (17 modelos treinados)
| Fase | Experimentos | Status | Key Findings |
|------|-------------|--------|--------------|
| **Phase 1** | Exp0-2 | ‚úÖ Complete | 60/10/30 split > 70/10/20 (-41% PER); Capacity 17.2M saturates |
| **Phase 2** | Exp3-5 | ‚úÖ Complete | PanPhon features ‚âà learned; Intermediate 9.7M sweet spot |
| **Phase 3** | Exp6-8 | ‚úÖ Complete | DA Loss Œª=0.2 optimal; Works @ baseline/intermediate capacity |
| **Phase 4** | Exp9-10 | ‚úÖ Complete | **Exp9 SOTA WER (4.96%)**; Exp10 proves DA doesn't scale to 17.2M |
| **Phase 5** | Exp101-102 | ‚úÖ Complete | Sep +17% PER abs (0.52%); WER cost +8%; trade-off claro |
| **Phase 6A** | Exp103 | ‚úÖ Complete | DA+sep N√ÉO aditivos; WER 5.73% (marginal vs 5.79%); hip√≥tese refutada |

### **Conclus√µes Cr√≠ticas P√≥s-Phase 6** üö®
1. ‚úÖ **Dois SOTA distintos permanecem**: Exp9 (SOTA WER: 4.96%) vs Exp102 (SOTA PER: 0.52%)
2. ‚ùå **Separadores de s√≠laba melhoram PER mas pioram WER**: trade-off fundamental, n√£o corrig√≠vel por loss
3. ‚ùå **Arquitetura maior N√ÉO ajuda**: Exp2 (17.2M, CE) WER 4.98% > Exp9 (9.7M, CE+DA) 4.96%
4. ‚ùå **Hip√≥tese Exp103 refutada**: DA Loss N√ÉO compensa WER cost dos separadores
5. ‚úÖ DA+sep reduz confus√µes `.`‚Üî`Àà` (sa√≠ram do top 5 de erros)
6. üì¶ **Tooling completo**: inference_light.py (pacote), neologisms_test.tsv (35 OOV words)

### **An√°lise: Split 50/10/40 N√ÉO recomendado**
- **Ganho**: +10k palavras de test (+35% vs 28.8k atual) ‚Üí confian√ßa estat√≠stica marginal
- **Custo**: ‚àí9.6k palavras de treino (‚àí17%) ‚Üí pior performance esperada
- **Situa√ß√£o atual**: œá¬≤ p=0.678 (excelente); test set j√° 57√ó maior que LatPhon
- **Conclus√£o**: Modelos piores sem ganho estat√≠stico. Documentar como ablation opcional apenas.

### **Pr√≥ximos Passos**
- **Avaliar neologismos**: 35 OOV words via `docs/neologisms_test.tsv` com Exp9 e Exp102
- **Phase 6B**: Exp104 com dist√¢ncias customizadas para s√≠mbolos estruturais (`.` e `Àà`) ‚Äî em andamento
- **Phase 7**: Refatora√ß√£o inference (tutorial + study) ‚Äî ver se√ß√£o Phase 7 abaixo
- **Estudos futuros**: S√≠mbolos estruturais ([doc 08](docs/08_STRUCTURAL_SYMBOLS.md)), Fonot√°tica ([doc 09](docs/09_PHONOTACTIC_CONSTRAINTS.md))

---

## üî¨ PHASE 6B ‚Äî DIST√ÇNCIAS CUSTOMIZADAS PARA S√çMBOLOS ESTRUTURAIS (EM DESENVOLVIMENTO)

**Status**: Implementa√ß√£o iniciada (2026-02-24)

### **Contexto**

O problema de `distance(., Àà) = 0.0` identificado em Exp102/Exp103 resulta em ~107 erros de confus√£o estrutural (. ‚Üî Àà) por 8600 palavras do test set. A Distance-Aware Loss n√£o penaliza essas confus√µes porque ambos os s√≠mbolos recebem vetores zero do PanPhon (s√£o suprassegmentais).

**Solu√ß√£o implementada**: Override p√≥s-hoc em `_build_distance_matrix()` (losses.py linhas 200-217) e `_compute_distance_matrix()` (phonetic_features.py linhas 254-271).

### **Pesquisa: Eleg√¢ncia Matem√°tica da Solu√ß√£o**

Uma pesquisa completa foi realizada analisando **5 abordagens** para resolver este problema de forma matematicamente mais elegante:

| # | Abordagem | Eleg√¢ncia | Tempo | Recomenda√ß√£o |
|---|-----------|-----------|-------|--------------|
| 1 | Vectoriza√ß√£o NumPy | ‚≠ê‚≠ê‚≠ê | 1-2h | Stepping stone para Abordagem 2 |
| **5** | **Symbol Type Hierarchy** | **‚≠ê‚≠ê‚≠ê‚≠ê** | **2-3h** | **üèÜ RECOMENDADA** |
| 2 | Classe Customizada StructuralAwareDistanceMatrix | ‚≠ê‚≠ê‚≠ê‚≠ê | 3-4h | Evolu√ß√£o natural ap√≥s Exp104 |
| 3 | Learnable Distance Metric | ‚≠ê‚≠ê‚≠ê | 5-7h | Experimental (futuro) |
| 4 | Structured Embedding Space | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | 6-8h | Longo prazo (3-6 meses) |

**Conclus√£o**: Enquanto a solu√ß√£o atual (loop expl√≠cito) parece "infantil", ela √© **funcionalmente correta e se executa apenas uma vez** (na inicializa√ß√£o). A verdadeira eleg√¢ncia vem de:
- **Abordagem 5 recomendada**: Sistema de tipos com pesos parametriz√°veis ‚Äî permite abla√ß√£o experimental (Exp105-107)
- **Abordagem 2**: Refatora√ß√£o para classe customizada ‚Äî implementar ap√≥s sucesso de Exp104

### **Documenta√ß√£o Artefatos**

- `docs/07_STRUCTURAL_ANALYSIS.md` ‚Äî An√°lise t√©cnica completa + implementa√ß√£o atual (Exp104b)
- `STRUCTURAL_SYMBOLS_MOCK_CODE.py` ‚Äî C√≥digo funcional de todas as 5 abordagens (testado)

### **Implementa√ß√£o Exp104**

- ‚úÖ **src/losses.py** (linhas 200-217): Override estrutural adicionado
- ‚úÖ **src/phonetic_features.py** (linhas 254-271): Override estrutural adicionado
- ‚úÖ **config_exp104_intermediate_sep_da_custom_dist.json**: Config criada

**Pr√≥ximo passo**: Treinar Exp104 e avaliar redu√ß√£o de erros `.‚ÜîÀà` (meta: <30 vs ~107 atual).

---

## üî¨ PHASE 7 ‚Äî AN√ÅLISE DE GENERALIZA√á√ÉO (NOVO)

**Status**: Planejamento (2026-02-24)

### **Problema**
Corpus loading (~2s) em `inference_light` √© caro para `predict(word)` simples. Mas corpus √â √∫til para **an√°lise** de padr√µes n√£o-treinados.

Exemplo: "lazzaretti" (duplo ZZ, TT) ‚Üí nunca foi treinado ‚Üí predi√ß√£o √© PREVIS√çVEL ou IMPREVIS√çVEL?

### **Solu√ß√£o: Dois arquivos**

**Phase 7A ‚Äî Refatora√ß√£o**:

`inference_tutorial.py` ‚Üê NOVO: minimalista (produ√ß√£o)
- Carrega: APENAS modelo (~1s)
- Uso: `predict("computador")`

`inference_study.py` ‚Üê NOVO: an√°lise (pesquisa)
- Carrega: modelo + corpus (~3-5s)
- M√©todos: `analyze(word)`, `evaluate_tsv(file)`
- Retorna: cobertura, similares, confian√ßa, padr√µes

**Phase 7B ‚Äî Features de inference_study**:
1. Coverage analyzer ‚Äî % n-gramas no dataset
2. Similar words ‚Äî Edit distance pr√≥ximas
3. Confidence metrics ‚Äî Entropia LSTM/softmax
4. Pattern analysis ‚Äî Sequ√™ncias raras = alerta

**Phase 7C ‚Äî Valida√ß√£o**:
- inference_tutorial: < 1s
- inference_study: analisa "lazzaretti"
- Comparar com neologisms_test.tsv

---

## üåç PHASE 8 ‚Äî ESPA√áO ARTICULAT√ìRIO UNIVERSAL (UNIVERSALIZA√á√ÉO PARA QUALQUER IDIOMA)

**Status**: Pesquisa te√≥rica conclu√≠da (2026-02-25); Planejamento de implementa√ß√£o

### **Vis√£o Geral**

O objetivo de Phase 8 √© deslocar G2P de uma abordagem **discreta e language-specific** (s√≠mbolos PT-BR ‚Üí PanPhon features) para uma abordagem **cont√≠nua e universal** (mapa articulat√≥rio 7D baseado em biomec√¢nica do aparelho fonador).

**Motiva√ß√£o**:
- PanPhon usa features **bin√°rias** ‚Äî perde nuances cont√≠nuas (ex: graus entre /e/ e /i/)
- S√≠mbolos estruturais (`.` e `Àà`) s√£o mapeados para **zero vector** ‚Äî indistingu√≠veis em Exp103
- Coarticula√ß√£o natural n√£o √© capturada por features est√°ticas
- Sem espa√ßo universal, cada idioma novo requer novo vocabul√°rio de features

**Conceito Central**: Um mapa articulat√≥rio 7D cont√≠nuo onde:
- **Cada ponto representa um poss√≠vel som humano** (baseado na biomec√¢nica)
- **S√≠mbolos de qualquer idioma s√£o quantiza√ß√µes** desse espa√ßo cont√≠nuo
- **Novos sons podem ser "inventados"** por interpola√ß√£o (ex: graus entre /e/ e /i/)
- **Din√¢mica articulat√≥ria natural** (coarticula√ß√£o, sobreposi√ß√£o de gestos)
- **Universalidade**: Mesma 7D para PT-BR, Ingl√™s, Espanhol, Mandarim, etc

---

### **Teoria Base (Documentado em docs/11-14_*.md)**

#### **Fonte 1: Articulatory Phonology (Browman & Goldstein 1992)**
- Fonologia fundamentada em **gestos articulat√≥rios cont√≠nuos** (n√£o fonemas discretos)
- Task Dynamics: gestos especificados por equa√ß√µes diferenciais 2¬™ ordem
- Sobreposi√ß√£o temporal (coarticula√ß√£o) natural no modelo gestural
- 6-8 "tract variables" (vari√°veis de controle do trato vocal) cont√≠nuas

#### **Fonte 2: Espa√ßos Ac√∫sticos Cont√≠nuos**
- **Formants (F1-F2-F3)**: Vogais formam espa√ßo cont√≠nuo 3D
- **MFCC (128D em mel-filterbank)**: Compress√£o de espa√ßo ac√∫stico cont√≠nuo
- **Evid√™ncia**: TTS neural (Tacotron, FastSpeech) trabalha em espa√ßos cont√≠nuos ‚Üí interpola√ß√£o suave

#### **Fonte 3: Quantiza√ß√£o Universal (Liljencrants & Lindblom 1972, Clements 2003)**
- Diferentes idiomas "quantizam" o mesmo espa√ßo cont√≠nuo de vogais diferentemente
- UPSID-92 mostra que invent√°rios de fonemas variam, mas n√£o arbitrariamente
- H√° um espa√ßo universal subjacente que cada l√≠ngua discretiza

---

### **Proposta: Mapa Articulat√≥rio 7D Cont√≠nuo**

```
Dimens√£o [0]: HEIGHT        ‚àà [-0.1, 1.0]  altura lingual
Dimens√£o [1]: BACKNESS      ‚àà [-0.1, 1.0]  ant√©rioridade (anterior ‚Üî posterior)
Dimens√£o [2]: ROUNDING      ‚àà [0, 1]       arredondamento labial
Dimens√£o [3]: CONSTR_LOC    ‚àà [-0.1, 1.0]  localiza√ß√£o de constric√ß√£o (labial ‚Üí glotal)
Dimens√£o [4]: CONSTR_DEG    ‚àà [-0.1, 1.0]  grau de constric√ß√£o (-0.1=boundary, 0=aberto, 1=oclusiva)
Dimens√£o [5]: NASALITY      ‚àà [0, 1]       nasalidade (oral ‚Üî nasal)
Dimens√£o [6]: VOICING       ‚àà [0, 1]       vozeamento (surdo ‚Üî sonoro)

Dist√¢ncia: Euclidiana (‚Ñì‚ÇÇ) em 7D
Range: ~2.5 (dist√¢ncia m√°xima entre pontos poss√≠veis)
```

**Vantagens vs PanPhon**:
- ‚úÖ **Estruturais distingu√≠veis**: d(`.`, `Àà`) ‚âà 1.0 vs d=0.0 em PanPhon
- ‚úÖ **Coarticula√ß√£o natural**: Blending cont√≠nuo entre trajet√≥rias
- ‚úÖ **Interpola√ß√£o**: Novos "sons" em graus (ex: entre /e/ e /i/)
- ‚úÖ **Universal**: Qualquer idioma mape√°vel para o mesmo espa√ßo
- ‚úÖ **F√≠sica realista**: Baseado em DOF biomec√¢nicos do trato vocal

---

### **Roadmap de Implementa√ß√£o (8 semanas, 4 Fases)**

#### **PHASE 8.1 ‚Äî Setup & Validation** (Semana 1)
- **Artefato**: `data/vocab_to_articulatory.json` com mapeamento de 52 s√≠mbolos PT-BR para 7D
- **Implementa√ß√£o**: `src/phonetic_features.py:ArticulatoryMetric` class
- **Valida√ß√£o**: Unit tests, visualiza√ß√£o PCA, benchmark distance vs PanPhon
- **Tempo**: 4-6h

#### **PHASE 8.2 ‚Äî Exp107: Articulatory Prior Loss** (Semana 2)
- **Config**: `config_exp107_articulatory_prior.json`
- **Mudan√ßa**: Substituir PanPhon distance matrix por ArticulatoryMetric
- **Loss**: DA Loss com dist√¢ncias articulat√≥rias (n√£o bin√°rias)
- **Resultado esperado**: WER 5.73% ‚Üí 5.50% (-0.23%); . ‚Üî Àà: 107 ‚Üí 50 erros
- **Tempo**: 1h implementa√ß√£o + 8h treino

#### **PHASE 8.3 ‚Äî Exp108: Continuous Phoneme Space** (Semanas 3-4)
- **Mudan√ßa**: LSTM prediz **cont√≠nuo 7D** em vez de √≠ndice discreto
- **Output**: 7D vetor (altura, backness, etc) em vez de token
- **Loss**: Regress√£o + quantiza√ß√£o p√≥s-hoc
- **Capacidade**: "Inventar" novos sons por interpola√ß√£o
- **Resultado esperado**: WER 5.73% ‚Üí 5.35% (-0.38%); PER: 0.53% ‚Üí 0.48%
- **Tempo**: 4h implementa√ß√£o + 10h treino

#### **PHASE 8.4 ‚Äî Multilingual Validation** (Semanas 5-8)
- **Teste 1**: Adicionar corpus de outro idioma (ex: ingl√™s, espanhol)
- **Teste 2**: Mesmo mapa 7D, diferentes quantiza√ß√µes por idioma
- **Teste 3**: Transfer learning entre idiomas
- **Resultado esperado**: Mapa 7D universal funciona para idiomas novos
- **Tempo**: 4h setup + 12h experimentos + 4h an√°lise

---

### **Impacto Esperado: Phase 8 Completa**

| M√©trica | Exp103 (PanPhon) | Exp108 (Articulatory) | Ganho |
|---------|------------------|-----------------------|-------|
| WER | 5.73% | 5.20% | -0.53% (9.2%) |
| PER | 0.53% | 0.40% | -0.13% (24.5%) |
| . ‚Üî Àà erros | 107 | <20 | -83% |
| Boundary Acc | ~89% | >95% | +6% |
| Universalidade | 1 idioma | 3+ idiomas | ‚úÖ Provado |
| Interpola√ß√£o | N/A | Graus de sons | ‚úÖ Novo |

---

### **Por Que Isso Muda Tudo (Universaliza√ß√£o)**

**Abordagem Tradicional (Exp9-Exp103)**:
```
PT-BR dataset ‚Üí LSTM (9.7M params) ‚Üí PanPhon features (21D binary)
Problema: Features are hardcoded para PT-BR
Extens√£o para novo idioma: Recriar features, retrainer modelo
```

**Abordagem Articulat√≥ria Cont√≠nua (Phase 8)**:
```
PT-BR dataset ‚Üí LSTM (9.7M params) ‚Üí Espa√ßo Articulat√≥rio 7D (universal)
                                   ‚Üì
                            Quantiza√ß√£o idioma-espec√≠fica
                            (ex: PT-BR quantiza em 38 s√≠mbolos,
                                 Ingl√™s em 44 s√≠mbolos)

Novo idioma (ex: Espanhol):
- Mesmo modelo pr√©-treinado em PT-BR (7D articulat√≥rio)
- Fine-tune com corpus Espanhol (transfer√™ncia natural)
- Requantizar em s√≠mbolos Espanhol
- Esperado: WER < 6.0% em Espanhol mesmo com dados limitados
```

---

### **Pr√≥ximas A√ß√µes (Imediatas)**

**Semana de 25-28 fev**:
1. ‚úÖ Ler docs/11-14_*.md (pesquisa te√≥rica j√° conclu√≠da)
2. ‚¨ú Revisar TODO.md Phase 8 (este documento)
3. ‚¨ú Implementar Phase 8.1: `vocab_to_articulatory.json` + `ArticulatoryMetric`
4. ‚¨ú Unit tests e valida√ß√£o

**Semana de 3 mar**:
5. ‚¨ú Implementar Exp107 (articulatory prior + DA Loss)
6. ‚¨ú Treinar Exp107, comparar vs Exp103
7. ‚¨ú Analisar ganhos

**Roadmap completo**: 8 semanas at√© Phase 8.4 (universaliza√ß√£o validada para 3+ idiomas)

---

### **Refer√™ncias Documentadas**

- [docs/11_CONTINUOUS_PHONETIC_THEORY.md](docs/11_CONTINUOUS_PHONETIC_THEORY.md) ‚Äî Teoria base (30 KB)
- [docs/12_ARTICULATORY_SPACE_MAPPING.md](docs/12_ARTICULATORY_SPACE_MAPPING.md) ‚Äî Mapeamento PT-BR 7D (14 KB)
- [docs/13_CONTINUOUS_SPACE_ROADMAP.md](docs/13_CONTINUOUS_SPACE_ROADMAP.md) ‚Äî Roadmap detalhado (23 KB)
- [docs/14_ACADEMIC_REFERENCES.md](docs/14_ACADEMIC_REFERENCES.md) ‚Äî 50+ refs acad√™micas (18 KB)

---

## ‚ö†Ô∏è URGENTE - BUGS CR√çTICOS (22/02/2026)

### **BUG 1: Cache Collision entre grapheme_encodings diferentes** ‚úÖ FIXADO
- **Status**: ‚úÖ IMPLEMENTADO E TESTADO (22/02/2026 21:20)
- **Mudan√ßa**: Cache filenames agora s√£o sens√≠veis a configura√ß√£o completa
  - encoding (`raw`/`decomposed`)
  - separadores (`sep`/`nosep`)
  - split (`60-10-30`/`70-10-20` etc.)
  - seed (`s42` etc.)
- **Exemplo**:
  - `train_raw_nosep_60-10-30_s42.txt`
  - `train_raw_nosep_70-10-20_s42.txt`
  - `train_decomposed_sep_60-10-30_s42.txt`
- **Valida√ß√£o**: ‚úÖ Sem sobrescrita entre configs diferentes
  - Teste: `test_cache_separation.py` (sucesso)
  - MD5s diferentes confirma sem sobrescrita
- **Pr√≥ximo passo**: ‚úÖ Exp11 pode rodar seguro agora!

### **BUG 2: Syllable Separators sendo removidos** ‚úÖ RESOLVIDO
- **Problema**: Dataset processado **REMOVE pontos sil√°bicos (.)**
  - Entrada: `a . b a . k a . Àà  É i`
  - Sa√≠da:   `a b a k a Àà  É i` ‚Üê **Pontos foram deletados!**
- **Localiza√ß√£o**: 
  - src/g2p.py:355-357 (PRINCIPAL ‚Äî durante treino)
  - src/prepare_data.py:29-31 (LEGACY/DEAD CODE)
- **Motivo da Remo√ß√£o** (coment√°rio em g2p.py:354): "Clean: remove separadores de s√≠laba, mant√©m fonemas puros"
  - √â claramente intencional (decis√£o deliberada)
  - Raz√£o: Reduzir complexidade do treino
- **IMPACTO COMPROVADO** (teste executado):
  - ‚úÖ COM separadores: **+30.1% mais tokens por palavra**
  - M√©dia sem separadores: 9.48 tokens
  - M√©dia com separadores: 12.33 tokens
  - Implica√ß√£o: Modelos ~7-10% maiores, sequ√™ncias mais longas
- **Consequ√™ncia de manter SEM separadores**:
  - ‚úÖ Backward compatibility com Exp0-10 (mant√©m SOTA v√°lida)
  - ‚ùå Perde informa√ß√£o lingu√≠stica valiosa (estrutura sil√°bica)
  - ‚ùå Exp13+ (se usar separadores) teriam arquitetura incompat√≠vel
-- **Status**: ‚úÖ Implementado como flag opcional (default False)
- **Implementa√ß√£o**:
  - Flag `data.keep_syllable_separators` em configs
  - `G2PCorpus` respeita manter/remover
  - Metadados registram flag
  - Treino/Infer√™ncia/An√°lise usam flag do config/metadata
- **Config ativo**:
  - Exp0-10: sem separadores (backward compat)
  - Exp11-13: com separadores (novo baseline experimental)
- **Pr√≥xima a√ß√£o**:
  - Criar e rodar Exp101 (baseline raw + separadores) para medir impacto direto



---


- ‚úÖ Sistema de relat√≥rios HTML com m√©tricas graduadas PanPhon
- ‚úÖ Gr√°ficos de treino/valida√ß√£o integrados no relat√≥rio (`analysis.py` + `report_generator.py`)
- ‚úÖ Gerenciador de experimentos com detec√ß√£o de plots faltantes (`manage_experiments.py --guide`)
- ‚úÖ Dataset statistics cache com m√©tricas de representatividade
- ‚úÖ FileRegistry para rastreabilidade de artefatos
- ‚úÖ Integra√ß√£o literatura SOTA em `docs/performance.json`
- üü° **Planejado**: Gerador de apresenta√ß√µes PowerPoint (.pptx) cient√≠ficas (implementar ap√≥s Exp7-10)

### **Dataset e Normaliza√ß√£o** ‚úÖ COMPLETO
- ‚úÖ Dataset IPA normalizado (10,252 linhas corrigidas 'g'‚Üí'…°')
- ‚úÖ Split 70/10/20 com stratification (œá¬≤=0.95, Cram√©r V=0.0007)
- ‚úÖ Cache persistente em `data/dataset_stats.json`
- ‚úÖ Backup em `docs/dicts.7z`

### **PyTorch Otimiza√ß√µes de Treinamento** üü°

#### ‚úÖ IMPLEMENTADAS (2026-02-23)

- ‚úÖ **`gather()` no hot path** (`losses.py:253` e `losses.py:317`)
  - `probs[torch.arange(N), pred_phonemes]` ‚Üí `probs.gather(1, pred_phonemes.unsqueeze(1)).squeeze(1)`
  - Elimina aloca√ß√£o de tensor por batch; ~5-8% mais r√°pido; idiom√°tico PyTorch
- ‚úÖ **`pin_memory=True` nos DataLoaders** (`g2p.py:520`)
  - Transfer CPU‚ÜíGPU via pinned memory; ~5-15% por epoch; ativo apenas com CUDA
- ‚úÖ **`optimizer.zero_grad(set_to_none=True)`** (`train.py:69`)
  - Define grads para `None` em vez de tensor zerado; evita aloca√ß√£o; ~3-8% speedup
- ‚úÖ **`allow_tf32` para matmul e cuDNN** (`train.py:23-24`) ‚Äî RTX 3060 confirmado Ampere (cap 8.6)
  - `torch.backends.cuda.matmul.allow_tf32 = True` + `torch.backends.cudnn.allow_tf32 = True`
  - TF32: mantissa 10 bits (vs 23 fp32), expoente completo; ~20-30% speedup em GEMM/LSTM
  - Sem instabilidade: loss e gradientes permanecem fp32; TF32 apenas nas ops matriciais internas
- ‚úÖ **`num_workers=2 + persistent_workers=True`** (`g2p.py:529`)
  - Workers criados **uma vez no in√≠cio** (n√£o por epoch) ‚Äî evita reimporta√ß√£o de m√≥dulo
  - Resolve causa raiz do problema anterior com num_workers; s√≥ ativo com CUDA

#### üü° INVESTIGADO MAS N√ÉO IMPLEMENTADO

- üü° **`torch.compile()`** ‚Äî **N√ÉO compat√≠vel com LSTM din√¢mico**
  - `pack_padded_sequence` usa dynamic shapes; falha ou bugs sutis com LSTM bidirecional
  - Veredito: evitar at√© PyTorch 3.x ou refactoring para sequ√™ncias est√°ticas
- üü° **AMP (Automatic Mixed Precision)** ‚Äî 4 problemas cr√≠ticos identificados (ver se√ß√£o abaixo)
- üü° **`nn.LSTM(proj_size=N)`** ‚Äî 10-15% mais r√°pido; trade-off em expressividade; testar em branch separada
- üü° **`pack_padded_sequence(enforce_sorted=True)`** ‚Äî +5-10% se batches ordenados; colide com `shuffle=True`

#### üü° PENDENTE ‚Äî Backlog (n√£o urgente)

- üü° **`forward_debug` recalcula tudo duas vezes** (`losses.py:280`)
  - Chama `self.forward()` e depois refaz argmax/softmax/distances do zero ‚Üí 2√ó custo
  - Fix: extrair intermedi√°rios em `_compute_components()`, reusar em ambos
- üü° **`_build_distance_matrix` vectorizar** (`losses.py:161`)
  - Duplo loop Python ‚Üí `scipy.spatial.distance.cdist(features, features, 'euclidean')`
  - S√≥ no `__init__`, impacto m√≠nimo no treino
- üü° **`_compute_distance_matrix` vectorizar** (`phonetic_features.py:227`)
  - Duplo loop Python ‚Üí broadcasting numpy: `(X[:, None, :] != X[None, :, :]).sum(axis=-1) / 24.0`
- üü° **`ignore_index=0` + mask manual** (`losses.py:125, 266`) ‚Äî sem√¢ntica confusa, sem impacto
- üü° **Pipeline de features com 3 convers√µes** (`train.py:209`) ‚Äî numpy ‚Üí dict ‚Üí tensor
- üü° **`graph_distance` sem cache** (`phonetic_features.py:499`) ‚Äî `@lru_cache` trivial
- üü° **Busca linear de √≠ndice** (`phonetic_features.py:750`) ‚Äî dict reverso resolve

#### ‚ùå N√ÉO IMPLEMENTAR ‚Äî AMP (Automatic Mixed Precision)

An√°lise completa (2026-02-23) identificou 4 problemas cr√≠ticos com AMP + LSTM:
- `pack_padded_sequence` requer `char_lengths` em CPU; `train.py:60` move para GPU ‚Üí conflito
- `CrossEntropyLoss` inst√°vel em fp16 (softmax + log em precis√£o baixa ‚Üí NaN)
- `distance_matrix` herdaria dtype fp16 do modelo via `register_buffer` ‚Üí overflow em dist√¢ncias
- `F.softmax` inst√°vel em fp16 com logits de magnitude variada
- Requereria refactoring extenso para Exp101 diagn√≥stico sem ganho justific√°vel

**Detalhes t√©cnicos**: ver [docs/02_ARCHITECTURE.md#L385](docs/02_ARCHITECTURE.md#L385)

---

### **Relat√≥rio HTML ‚Äî Bugs e Melhorias (Backlog)** üü°

Diagn√≥stico do relat√≥rio HTML (2026-02-22). N√£o quebra funcionalidade; corrigir durante paralelo com Exp11-13.

**Bugs de ordena√ß√£o** (urgente, ~15 min):
- üü° Colunas de Classes B/C/D nas tabelas graduadas n√£o t√™m `data-value` ‚Üí ordenam lexicograficamente em vez de num√©rico
  - Afeta: `graduated-metrics-phonemes` (colunas 2-5) e `graduated-metrics-words` (colunas 2-5)
  - Fix: adicionar `<td data-value="0.15">0.15%</td>` em todas as c√©lulas de porcentagem sem `data-value`

**Inconsist√™ncia de dados** (clareza, ~30 min):
- üü° Tabela "Distribui√ß√£o por Fonemas" mostra PER Weighted mas n√£o PER cl√°ssico para compara√ß√£o
- üü° Tabela "Distribui√ß√£o por Palavras" mostra WER Graduated mas n√£o WER cl√°ssico ao lado
  - Fix: adicionar coluna "PER Cl√°ssico" e "WER Cl√°ssico" em cada tabela para permitir compara√ß√£o direta

**Melhorias ergon√¥micas** (~60 min):
- üü¢ Adicionar tooltip explicando diferen√ßa PER Cl√°ssico vs PER Weighted
- üü¢ Adicionar seta de destaque visual no best model (Exp9) em todas as tabelas
- üü¢ Link direto de cada experimento para seus artefatos (model file, history CSV)

---

### **M√©tricas Graduadas ‚Äî Explicabilidade (Backlog)** üü°
- üü° **Estudar m√©trica de eros√£o cumulativa por palavra** (al√©m da regra atual de "pior classe").
  - Objetivo: diferenciar casos com m√∫ltiplos erros leves (ex.: `bala‚Üíbolo`) de casos com 1 √∫nico erro leve.
  - Hip√≥teses para avaliar (sem substituir A/B/C/D por enquanto):
    1. Score cumulativo de severidade por palavra (soma/m√©dia ponderada de classes por fonema).
    2. √çndice de "degrada√ß√£o lexical" para estimar quando a pron√∫ncia resultante pode aproximar outra palavra v√°lida.
    3. M√©trica complementar para palavras curtas (4-5 fonemas), onde poucos erros mudam muito o sentido.
  - Entreg√°vel: benchmark comparando explicabilidade vs correla√ß√£o com percep√ß√£o humana (MOS/avalia√ß√£o qualitativa).

- üü° **Analisar tratamento de s√≠mbolos modificadores IPA** (`Àà`, `.`, `~`, `^` etc.)
  - Objetivo: entender impacto de representar cada modificador como token vs feature vs parte de fonema composto.
  - Quest√µes a responder:
    * Apostrophe (`Àà`) como marca de tonicidade: token separado (rede trata como fonema) ou incorporado √† vogal acentuada?
    * Ponto (`.`) como separador de s√≠labas: manter no output ou descarregar (pr√©-processar) e usar apenas para alinhamento?
    * Diacr√≠ticos de nasaliza√ß√£o/tonalidade: decompor (`a`+`~`) ou manter como s√≠mbolo √∫nico (`√£`)?
    * Dist√¢ncia de embedding: modificadores devem ter vetores muito distantes para indicar fun√ß√£o n√£o-ac√∫stica?
  - M√©todo: gerar variantes do dataset com diferentes codifica√ß√µes e comparar PER + PER_graduated + an√°lise qualitativa.
  - Entreg√°vel: recomenda√ß√£o de codifica√ß√£o (mant√©m tokens atuais ou refatorar) e poss√≠vel refatora√ß√£o de `prepare_data.py`.

- üü° **Codifica√ß√£o graf√™mica (lado entrada): `raw` vs `decomposed`**
  - Objetivo: reduzir alfabeto efetivo de grafemas preservando informa√ß√£o diacr√≠tica via segmenta√ß√£o.
  - Exemplo alvo: `ma√ß√£` ‚Üí `ma'c~a`.
  - Estrat√©gia em est√°gios (conservadora):
    1. **S0**: baseline `raw` (comportamento hist√≥rico)
    2. **S1**: `decomposed` opcional por config (implementado)
    3. **S2**: abla√ß√£o controlada `raw` vs `decomposed` (mesmo seed/split)
    4. **S3**: decis√£o final para produ√ß√£o por PER/WER/Acc + m√©tricas graduadas
  - Implementa√ß√£o t√©cnica (S1):
    - Campo `data.grapheme_encoding` em configs (`raw` default, expl√≠cito)
    - Transforma√ß√£o Unicode NFD + marcadores ASCII no `G2PCorpus`
    - Cache/metadados registram `grapheme_encoding`
    - Infer√™ncia mant√©m sa√≠da com palavra original (transpar√™ncia)


### **Gerador de Apresenta√ß√µes Cient√≠ficas (Backlog)** üü°
- üü° **presentation_generator.py** ‚Äî Apresenta√ß√µes PowerPoint autom√°ticas estilo artigo cient√≠fico
  - **Objetivo**: Gerar slides .pptx atualiz√°veis incrementalmente para cada experimento conclu√≠do
  - **Biblioteca**: `python-pptx==0.6.23` (PowerPoint nativo, edit√°vel p√≥s-gera√ß√£o)
  - **Estrutura da apresenta√ß√£o** (padr√£o acad√™mico):
    1. T√≠tulo + Autoria
    2. Motiva√ß√£o / Problema (dataset PT-BR, aplica√ß√µes TTS)
    3. Objetivos (PER minimizado, m√©tricas graduadas)
    4. Dataset (estat√≠sticas, split 60/10/30, qualidade œá¬≤/Cram√©r V)
    5. Arquitetura (BiLSTM Encoder-Decoder + Aten√ß√£o Bahdanau, diagrama conceitual)
    6. Metodologia de Experimentos (Fase 1-5: baseline ‚Üí capacity ‚Üí features ‚Üí loss)
    7-N. **Resultados por Experimento** (1 slide/experimento):
        - Config (params, split, loss function)
        - Gr√°fico converg√™ncia (import PNG existente)
        - M√©tricas principais (PER/WER/Acc) com destaque cores
        - Insights chave (bullets)
    N+1. Compara√ß√£o Consolidada (tabela formatted: verde=melhor, vermelho=pior)
    N+2. An√°lise de Erros (PanPhon graduado: Classes A/B/C/D)
    N+3. Benchmark vs Literatura (LatPhon, SOTA PT-BR)
    N+4. Conclus√µes + Trabalhos Futuros
    N+5. Refer√™ncias

  - **Features t√©cnicas**:
    - Template cient√≠fico profissional (paleta azul acad√™mico #1e3a8a + cinza)
    - Tabelas com destaque para melhores resultados (conditional formatting)
    - Importa√ß√£o autom√°tica de plots PNG (convergence, analysis)
    - Text formatting: bullets, code blocks, bold/italic
    - Detec√ß√£o incremental: adiciona apenas novos experimentos
    
  - **Integra√ß√£o com pipeline**:
    - Mesmos dados de `performance.json`, `*_metadata.json`, `*_history.csv`
    - `manage_experiments.py --guide` sugere gerar apresenta√ß√£o quando h√° novos experimentos
    - Auto-detecta plots, m√©tricas, error analysis
    
  - **API CLI**:
    ```bash
    python src/reporting/presentation_generator.py                    # Gera apresenta√ß√£o completa
    python src/reporting/presentation_generator.py --exp 7            # Adiciona apenas Exp7
    python src/reporting/presentation_generator.py --template modern  # Escolhe template
    python src/reporting/presentation_generator.py --output custom.pptx
    ```
  
  - **Depend√™ncias adicionais**:
    ```
    python-pptx==0.6.23
    Pillow==10.1.0  # manipula√ß√£o de imagens existente
    ```
  
  - **Versionamento**: Arquivo .pptx pode ser commitado em Git, edit√°vel no Office/LibreOffice/Google Slides
  
  - **Timing de implementa√ß√£o**: Ap√≥s Exp7-10 completos (quando houver dataset robusto de experimentos)
  
  - **ROI**: ‚≠ê‚≠ê‚≠ê M√âDIO (acelera prepara√ß√£o de defesas/papers, mas n√£o cr√≠tico para pesquisa)

### **Experimentos - Baseline (70/10/20)**
- ‚úÖ **Exp0** (baseline 70/10/20): COMPLETO
  - Training: 71 epochs, early stop, best_loss=0.0176
  - Evaluation: PER 1.12%, WER 9.37%, Acc 90.63%
  - Graduated: PER_w 0.53%, WER_g 1.12%, A=98.20%
  - Artefatos: 10/11 completos (17.66 MB)
  - **Status**: ‚úÖ Integrado em `docs/performance.json`

### **Experimentos - Series 60/10/30 (capacity sweep)**

**üîç DESCOBERTA CR√çTICA: Split 60/10/30 SUPERIOR ao 70/10/20**
```
           Treino  Split     PER‚Üì    WER‚Üì    Acc‚Üë     Descoberta
Exp0       67k     70/10/20  1.12%   9.37%   90.63%   Baseline
Exp1       57k     60/10/30  0.66%   5.65%   94.35%   ‚úì 41% melhor PER
           ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Conclus√£o: -15% dados de treino ‚Üí m√©tricas MELHORES (+50% test size)
```

- ‚úÖ **Exp1** (baseline 60/10/30): COMPLETO
  - Training: 95 epochs, early stop, best_loss=0.0182
  - Evaluation: PER 0.66%, WER 5.65%, Acc 94.35%
  - Config: emb=128, hidden=256, 4.3M params
  - **Descoberta**: 41% melhor que Exp0 (confirma split 60/10/30 > 70/10/20)
  - Top erros: e‚Üí…õ (303√ó), …î‚Üío (193√ó), …õ‚Üíe (161√ó) ‚Äî padr√£o voc√°lico PT-BR
  - **Status**: ‚úÖ Completo, aguardando integra√ß√£o em performance.json

- ‚úÖ **Exp2** (extended 60/10/30): COMPLETO
  - Config: emb=256, hidden=512, 17.2M params (4√ó exp1)
  - Training: 120 epochs, best_loss=0.016815 @ epoch 119
  - Time: 309.7m (5.2h), avg 154.8s/epoch
  - Inference: PER 0.60%, WER 4.98%, Acc 95.02% (2026-02-19)
  - **Status**: ‚úÖ COMPLETO, infer√™ncia conclu√≠da

- ‚úÖ **Exp3** (PanPhon trainable 60/10/30): COMPLETO
  - Config: PanPhon embeddings 24D trainable, hidden=256, 4.3M params
  - Training: 90 epochs (early stop), best_loss=0.017606 @ epoch 72
  - Time: 237.5m (4h), avg 158.3s/epoch
  - Inference: PER 0.66%, WER 5.45%, Acc 94.55% (2026-02-19)
  - **Status**: ‚úÖ COMPLETO, infer√™ncia conclu√≠da

- üîÑ **Exp4** (PanPhon fixed 70/10/20): RODANDO (RESTART)
  - Run: `exp4_panphon_fixed_24d__20260219_195619`
  - Config: emb=24 fixed, hidden=256, 3,988,443 params
  - Progresso inicial: epoch 1‚Üí8 | val_loss 0.2671 ‚Üí 0.0410
  - Throughput inicial: ~419‚Äì428 samples/s (~165s/epoch)
  - Status atual: epoch 26 | best_loss 0.0265
  - Warmup: early stopping ativo apenas ap√≥s epoch 80
  - **Status**: üîÑ RODANDO (reiniciado ap√≥s travamento)

- üßπ **Limpeza de incompletos**
  - `manage_experiments.py --prune-incomplete --dry-run` usado para validar
  - Incompletos removidos com seguran√ßa; rodando preservado

- ‚úÖ **Exp5** (intermediate 60/10/30): COMPLETO ‚úÖ
  - Training: 78 epochs, early stop, best_loss=0.0175
  - Evaluation: PER 0.63%, WER 5.38%, Acc 94.62%
  - Config: emb=192, hidden=384, 9.7M params (1.5√ó exp1)
  - Graduated: PER_w 0.30%, WER_g 0.64%, A=98.98%
  - Time: 4.8h
  - **Conclus√£o**: Sweet spot entre Exp1 (4.3M) e Exp2 (17.2M); PER igual a Exp6 (0.63%)
  - **Status**: ‚úÖ COMPLETO, infer√™ncia conclu√≠da 2026-02-20

- ‚úÖ **Exp6** (Distance-Aware Loss 60/10/30): COMPLETO ‚úÖ
  - **Training**: 107 epochs, early stop epoch 97, best_loss=0.01714
  - **Time**: 280.0m (4.7h), avg 157.0s/epoch, speed 367 samples/s
  - **Evaluation**: PER **0.63%**, WER **5.35%**, Acc **94.65%**
  - **Config**: emb=128, hidden=256, 4.3M params (same as Exp1 baseline)
  - **Loss**: Distance-Aware (Œª=0.1), formula: L = L_CE + Œª¬∑d_panphon¬∑p_pred
  - **Top erros**: e‚Üí…õ (265√ó), …õ‚Üíe (202√ó), o‚Üí…î (139√ó) ‚Äî voc√°licas PT-BR
  - **Comparative vs Exp1** (baseline id√™ntico):
    - PER: -4.5% (0.66% ‚Üí 0.63%)
    - WER: -5.3% (5.65% ‚Üí 5.35%)
    - Loss: -6.6% (0.0183 ‚Üí 0.0171)
  - **Conclus√£o**: ‚úÖ **Distance-Aware Loss VALIDADA**! Pequena mas consistente melhoria confirma hip√≥tese de pondera√ß√£o fon√©tica. Erra "mais inteligentemente" (erros fonologicamente pr√≥ximos).
  - **Status**: ‚úÖ INTEGRADO em `performance.json`, `01_OVERVIEW.md`, `04_EXPERIMENTS.md` (2026-02-20)
  - **Pending**: M√©tricas graduadas PanPhon completas (aguardando `analyze_errors.py`)

**An√°lise Comparativa Series 60/10/30** (Exp1/2/3/5/6 completos):
```
Exp    Params  T√©cnica              PER‚Üì    WER‚Üì    Acc‚Üë     Loss     
Exp1   4.3M    Baseline (learned)   0.66%   5.65%   94.35%   0.0182   Baseline id√™ntico
Exp6   4.3M    Distance-Aware Loss  0.63%   5.35%   94.65%   0.0171   ‚úì -4.5% PER, -6.6% loss
Exp5   9.7M    Intermediate         0.63%   5.38%   94.62%   0.0175   Sweet spot capacity
Exp3   4.3M    PanPhon trainable    0.66%   5.45%   94.55%   0.0176   Articulatory features
Exp2   17.2M   Extended (4√ó Exp1)   0.60%   4.98%   95.02%   0.0168   ‚úì Melhor PER/WER

Key Findings:
1. ‚úÖ Distance-Aware Loss (Exp6): Mesma arquitetura Exp1, resultados Exp5 (9.7M params)!
2. ‚úÖ Capacity sweet spot: Exp5 (9.7M) ‚âà Exp6 (4.3M + loss inteligente) > Exp1
3. ‚úÖ Scaling trend: Exp1 < Exp5 ‚âà Exp6 < Exp2 (curva linear; mais params sempre ajudam)
4. ‚úÖ PanPhon features (Exp3): PER igual Exp1, mas m√©tricas graduadas melhores (erros mais "inteligentes")
5. üéØ Winner t√©cnico: Exp6 (melhor ROI: 4.3M params com performance 9.7M)
6. üéØ Winner absoluto: Exp2 (PER 0.60%, mas 4√ó params e treina mais lento)
```

- üîÑ **Exp4** (PanPhon fixed 70/10/20): RODANDO (RESTART)

### **‚úÖ (2026-02-20): Exp6 ‚Äî Distance-Aware Loss ‚Äî COMPLETO**

**RFC Document**: [docs/RFC_EXP6_PHONETIC_DISTANCE.md](docs/RFC_EXP6_PHONETIC_DISTANCE.md) ‚Äî An√°lise cr√≠tica de 3 propostas:
- ‚ùå **1D Linear Projection**: SKIP (risco alto, perda de informa√ß√£o)
- ‚úÖ **Distance-Aware Loss** (Exp6): COMPLETO ‚úÖ PER 0.63%, WER 5.35% (melhor que Exp1 baseline)
- üü° **g2p.py Refactoring**: DEFER (low priority, nice-to-have p√≥s Exp6)

**Status**: ‚úÖ COMPLETO ‚Äî Documentado em performance.json, 01_OVERVIEW.md, 04_EXPERIMENTS.md, COMPARATIVE_ANALYSIS.

---

### **üöÄ Exp7-10 ‚Äî Otimiza√ß√£o + Sinergias (OP√á√ÉO B APROVADA)**

**Estrat√©gia Revisada**: Consolidada neste TODO + [docs/04_EXPERIMENTS.md](docs/04_EXPERIMENTS.md).

**Ordem de Execu√ß√£o**: Otimizar Œª ‚Üí Testar sinergia fon√©tica ‚Üí Escalar capacity com loss otimizado

#### ‚è≥ **Exp7 (HIGH PRIORITY)** ‚Äî Busca Adaptativa de Lambda (corte bin√°rio)

**Objetivo**: Otimizar hiperpar√¢metro Œª (distance weight) com **2-3 runs informativos** ANTES de escalar capacity.

**Configs (nomes autoexplicativos)**:
- `config_exp7_lambda_anchor_baseline_0.10.json` ‚Äî Œª=0.10 (√¢ncora Exp6 j√° conhecida)
- `config_exp7_lambda_lower_bound_0.05.json` ‚Äî Œª=0.05 (limite inferior)
- `config_exp7_lambda_upper_bound_0.50.json` ‚Äî Œª=0.50 (limite superior)
- `config_exp7_lambda_mid_candidate_0.20.json` ‚Äî Œª=0.20 (meio candidato para refinamento)

**Fluxo adaptativo (acelera wallclock)**:
1. Usar Exp6 (Œª=0.10) como baseline j√° observado
2. Rodar extremos: Œª=0.05 e Œª=0.50
   - Œª=0.05 PER ‚âà0.63% (melhor loss 0.0170)
   - Œª=0.50 PER ‚âà0.65% (pior que baseline; infer√™ncia conclu√≠da ‚Äì ver `evaluation_exp7_lambda_upper_bound*.txt`)
   ‚Üí esses resultados indicam que o √≥ptimo est√° abaixo de 0.50 e possivelmente ‚â§0.10.
3. Rodar Œª=0.20 **sim** para: 
   - verificar se a curva possui m√≠nimo suave entre 0.05 e 0.10,
   - confirmar se a estabilidade em 0.05‚Äì0.10 n√£o √© apenas ru√≠do de treino.

**Nota metodol√≥gica (neur√¥nios/capacidade)**: Exp7 isola apenas `distance_lambda`; aumento de neur√¥nios (`hidden_dim`/`emb_dim`) fica para Exp9/Exp10 para n√£o misturar efeitos.

**Hip√≥tese**: Œª optimal ‚àà [0.10, 0.20] ‚Üí Expected PER 0.60-0.62%

**Custo**: 2-3 runs √ó 4.7h = **~9.4h a ~14.1h GPU** (vs ~19h sweep fixo)

**ROI**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê ALT√çSSIMO (otimiza TODOS experimentos Exp8-10)

**Output esperado**: Œª optimal documentado por decis√£o incremental ‚Üí Exp8-10 usar√£o Œª_optimal

---

#### ‚è≥ **Exp8 (HIGH PRIORITY)** ‚Äî PanPhon + Distance-Aware Loss (Œª optimal)

**Objetivo**: Testar **SINERGIA FON√âTICA** (features articulat√≥rias + loss fon√©tico AMPLIFICAM?).

**Config**: `config_exp8_panphon_distance_aware.json`
- Arquitetura: Exp3 (PanPhon 24D trainable, 4.3M params)
- Loss: Distance-Aware (Œª optimal from Exp7)

**Hip√≥tese**: PanPhon (PER_w 0.28%) + Distance-Aware (PER 0.63%) ‚Üí **PER_weighted <0.25%** (SOTA qualitativo)

**Compara√ß√£o cr√≠tica**:
```
Exp1 (Learned + CE):       PER 0.66%, PER_w 0.30%, Classe D 0.52%
Exp3 (PanPhon + CE):       PER 0.66%, PER_w 0.28%, Classe D 0.48%  ‚Üê features ajudam qualidade
Exp6 (Learned + Distance): PER 0.63%, PER_w ?, Classe D ?         ‚Üê loss ajuda quantidade
Exp8 (PanPhon + Distance): PER 0.60-0.63%?, PER_w <0.25%?, D <0.40%?  ‚Üê SINERGIA?
```

**Expected**: PER 0.60-0.63%, **PER_weighted <0.25%** (melhor que QUALQUER exp atual)

**Custo**: ~4.7h GPU

**ROI**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê ALT√çSSIMO (aprendizado cient√≠fico m√°ximo ‚Äî hip√≥tese n√£o-√≥bvia)

**Decis√£o p√≥s-Exp8**:
- Se PER_weighted <0.25%: **SINERGIA FON√âTICA CONFIRMADA** ‚Üí Novo baseline TTS
- Se PER_weighted ‚âà0.27%: Features + loss ADITIVOS (n√£o amplificativos)

---

#### ‚úÖ **Exp9 (MEDIUM PRIORITY)** ‚Äî Exp5 + Distance-Aware Loss (Œª optimal) ‚Äî TREINO CONCLU√çDO

**Objetivo**: Capacity intermedi√°ria (9.7M) + Loss inteligente ‚Üí Sweet spot ROI.

**Config**: `config_exp9_intermediate_distance_aware.json`
- Arquitetura: Exp5 (emb=192, hidden=384, 9.7M params)
- Loss: Distance-Aware (Œª optimal from Exp7)

**Hip√≥tese**: Capacity + Distance-Aware combinam ADITIVAMENTE ‚Üí PER 0.57-0.60% (approach Exp2 0.60%)

**Compara√ß√£o**:
```
Exp5 (9.7M + CE):        PER 0.63%
Exp6 (4.3M + Distance):  PER 0.63%
Exp9 (9.7M + Distance):  PER 0.57-0.60%? ‚Üê Expected sweet spot
Exp2 (17.2M + CE):       PER 0.60% (SOTA atual)
```

**Expected**: PER 0.58-0.60% (56% params Exp2, mesma performance)

**Custo**: ~4.8h GPU

**Status atual (2026-02-22)**:
- ‚úÖ Treino conclu√≠do com early stopping no epoch 99
- ‚úÖ Melhor checkpoint no epoch 89 (`val_loss=0.0165`)
- ‚úÖ Artefatos de treino gerados (`.pt`, `_metadata.json`, `_history.csv`, `_summary.txt`)
- ‚è≥ Pendente: infer√™ncia no test set + `analyze_errors.py`

**ROI**: ‚≠ê‚≠ê‚≠ê M√âDIO (resultado previs√≠vel, mas √∫til para produ√ß√£o)

**Decis√£o p√≥s-Exp9**:
- Se PER <0.58%: **Novo sweet spot produ√ß√£o documentado**
- Se PER ‚âà0.60%: Confirma Exp2 necess√°rio para SOTA absoluto

---

#### ‚úÖ **Exp10 (COMPLETED)** ‚Äî Exp2 + Distance-Aware Loss (Œª optimal) ‚Äî **RESULTADO: SATURA√á√ÉO CONFIRMADA**

**Objetivo**: SOTA ceiling test ‚Äî High capacity + Loss inteligente ‚Üí Novo SOTA PT-BR?

**Config**: `config_exp10_extended_distance_aware.json`
- Arquitetura: Exp2 (emb=256, hidden=512, 17.2M params)
- Loss: Distance-Aware (Œª=0.2 optimal from Exp7)
- Treino: Epoch 82/120, best val_loss 0.0173

**RESULTADO OBTIDO**:
- **PER: 0.61%** (pior que Exp2 0.60% e Exp9 0.58%)
- **WER: 5.25%** (pior que Exp2 4.98% e Exp9 4.96%)
- **Accuracy: 94.75%** (pior que Exp2 95.02% e Exp9 95.04%)
- **Throughput: 26.5 palavras/s**

**Compara√ß√£o final**:
```
Exp2 (17.2M + CE):        PER 0.60%, WER 4.98%, Acc 95.02%  [Baseline high-capacity]
Exp9 (9.7M + DA):         PER 0.58%, WER 4.96%, Acc 95.04%  [‚úì SOTA ATUAL - SWEET SPOT]
Exp10 (17.2M + DA):       PER 0.61%, WER 5.25%, Acc 94.75%  [‚úó PIOR que ambos]
LatPhon (SOTA 2025):      PER 0.86% (apenas 500 test samples)
```

**üö® CONCLUS√ïES CR√çTICAS**:
1. **‚ùå Distance-Aware Loss N√ÉO escala com high capacity** (17.2M params)
2. **‚úÖ Exp9 (9.7M) CONFIRMADO COMO SOTA**: Melhor PER/WER/Acc com 56% dos par√¢metros
3. **‚ö†Ô∏è Overfitting prov√°vel**: 17.2M + DA Loss ‚Üí pior generaliza√ß√£o que CE puro (Exp2)
4. **üí° Satura√ß√£o em ~0.58% PER**: Limite alcan√ßado com arquitetura atual

**Decis√£o p√≥s-Exp10**:
- ‚úÖ **Exp9 √© NOVO BASELINE DE PRODU√á√ÉO** (0.58% PER, 9.7M params, best ROI)
- ‚ùå High-capacity + DA Loss n√£o vale o custo (1.8√ó params, -5% performance)
- üéØ Pr√≥ximos experimentos: Testar decomposed encoding (Exp11-13) para superar 0.58%

**ROI final Exp6/9/10**:
- Exp6 (4.3M):  PER 0.63%, budget option (25% params Exp10)
- Exp9 (9.7M):  PER 0.58%, **SWEET SPOT** (56% params Exp10, melhor acc)
- Exp10 (17.2M): PER 0.61%, custo/benef√≠cio NEGATIVO

---

### **üéØ Phase 5A ‚Äî Inference Light + Neologisms Testing (HIGH PRIORITY, paralelo)**

**Status**: Planejado

**Motiva√ß√£o Phase 5A**: Validar Exp9 SOTA em **neologismos/OOV words** (caso de uso prim√°rio G2P), criar ferramentas para demos, garantir dataset health antes de multilingual.

---

#### **Task 1: inference_light.py** (4h work)
- **Objetivo**: Teste r√°pido interativo + batch de palavras
- **Uso**:
  ```bash
  python src/inference_light.py --model-index 9   # Interativo Exp9
  python src/inference_light.py --model-index 9 --test data/neologisms_test.tsv --output results/neologisms_eval.json
  ```
- **Features**:
  - Interactive mode (word: > stdin)
  - Batch mode (read TSV predictions)
  - JSON output com: IPA, confidence, in_dict status, nearest match, category
  - Reutiliza `G2PLSTMModel`, `G2PCorpus` existentes
- **Outputs**:
  - `inference_light.py`: novo arquivo em src/
  - `results/neologisms_eval.json`: predictions estruturadas para an√°lise
  - `results/neologisms_statistics.txt`: resumo (NWER^novel, confidence distribution)
- **Status**: ‚è≥ Pendente implementa√ß√£o (semana 1 Phase 5)

---

#### **Task 2: neologisms_test.tsv** (6h curation + expert review)
- **Objetivo**: Dataset teste com palavras inventadas/OOV
- **Estrutura**:
  ```tsv
  word	ipa_approx	category	difficulty	notes
  smartphone	smar'tfo'n	loanword	medium	Modern technology
  brun√¢teca	bru'na't…õka	invented	very_hard	bruneta + biblioteca blend
  tiktoker	ti'kto'ker	slang	medium	TikTok user
  pixela√ß√£o	pi'kse'la's…êÃÉwÃÉ	technical	easy	Modern (pixel + -√ß√£o)
  ```
- **Cobertura**: 120+ palavras em 5 categorias:
  - Loanwords (20%): smartphone, fluxograma, database, browser
  - Slang moderno (20%): selfie, tiktoker, tweeter, cancelado
  - T√©cnico (20%): pixela√ß√£o, microagress√£o, neuroplasticidade
  - Inventado puro (20%): brun√¢teca, megaloide, queimologia
  - Nomes estrangeiros (20%): M√ºller‚Üím√ºler, G√∂del‚Üíg√∂del
- **Valida√ß√£o**:
  - Revisar IPA approximations com fonologo PT-BR (expert review cr√≠tica)
  - Validar contra inventory fon√™mico PT-BR (43 fonemas)
  - Documentar dificuldade por padr√£o segmental (raro vs comum)
- **Outputs**:
  - `data/neologisms_test.tsv`: 120 linhas validadas
  - `docs/NEOLOGISMOS_CURATION_NOTES.md`: decis√µes, rationales, expert feedback
- **Status**: ‚è≥ Pendente cura√ß√£o + expert review (semana 1 Phase 5)

---

#### **Task 3: dataset_health_check.py** (8h work)
- **Objetivo**: Validar dicts/pt-br.tsv antes de multilingual
- **Checks**:
  - **Duplicatas**: palavras com m√∫ltiplos IPA + sugest√µes de merge
  - **Typos**: cluster por Levenshtein (detecta "acucar" vs "a√ß√∫car")
  - **Encoding**: NFC vs NFD mismatch (previne problemas unicode)
  - **IPA Validity**: caracteres contra inventory v√°lido (43 PT-BR fonemas)
  - **Coverage**: % de bigramas/trigramas em train/val/test
  - **Quality Score**: A+/A/B/C rating
- **Outputs**:
  ```
  results/
  ‚îú‚îÄ‚îÄ health_report.html          (visualiza√ß√£o colorida com charts)
  ‚îú‚îÄ‚îÄ health_report.json          (dados estruturados, machine-readable)
  ‚îî‚îÄ‚îÄ dicts_pt-br_CLEAN.tsv       (vers√£o corrigida)
  ```
- **CLI**:
  ```bash
  python src/dataset_health_check.py --input dicts/pt-br.tsv --output-dir results/
  ```
- **Status**: ‚è≥ Pendente implementa√ß√£o (semana 1-2 Phase 5)

---

#### **Integra√ß√£o Phase 5A com Experimentos**

```
Timeline paralela:

GPU (Exp11-13):                     CPU (Phase 5A Tools):
‚îú‚îÄ Exp11 training (~4h)            ‚îú‚îÄ inference_light.py (4h)
‚îú‚îÄ Exp12 training (~5h)            ‚îú‚îÄ neologisms_test.tsv (6h)
‚îî‚îÄ Exp13 training (~4h)            ‚îî‚îÄ dataset_health_check.py (8h)
  Total: ~13h GPU                    Total: ~18h CPU (parallelizable)

Ap√≥s Exp11-13 + Phase 5A complete:
‚îú‚îÄ Testar Exp9/11/12/13 com inference_light em neologisms_test.tsv
‚îú‚îÄ Gerar NWER^novel (Novel Word Error Rate) para cada modelo
‚îú‚îÄ Comparar OOV behavior Exp9 vs Exp11-13
‚îî‚îÄ Documentar findings em STATUS.md + paper preps
```

---

#### **M√©tricas Phase 5A**

| M√©trica | Target | Valida√ß√£o |
|---------|--------|-----------|
| inference_light accuracy | ‚â• 0.95 match vs inference.py | Testar 100 words |
| neologisms coverage | ‚â• 120 words, 5 categorias | Cura√ß√£o completa + review |
| dataset_health issues | ‚â§ 5 cr√≠ticos | Report + clean TSV |
| **NWER^novel** | < 3% (Exp9 expected) | Metric novo, baseline |
| Time to inference | < 1s per word | CLI performance |

**M√©trica Nova**: `NWER^novel` (Novel Word Error Rate)
- PER apenas em words NOT in training dictionary
- Expected Exp9: ~2-3% (vs 0.58% overall PER)
- Valida generaliza√ß√£o em OOV
- Diferencia "lookup performance" de "generalization capability"

---

#### **P√≥s-Phase 5A Deliverables**

‚úì Relat√≥rio completo: "Exp9 SOTA Performance on OOV/Neologisms"  
‚úì Ferramenta diagn√≥stico `inference_light.py` para demos/publications  
‚úì Dataset validation assurance (dicts/pt-br.tsv clean)  
‚úì Novo √¢ngulo para paper: "G2P generalization on invented words" (NWER^novel metric)  
‚úì Pronto para Phase 6 multilingual (se decide incluir Tupi)

**ROI**: ‚≠ê‚≠ê‚≠ê‚≠ê Alto (produ√ß√£o-ready tools + novo metric + paper angle)  
**Timeline**: Semana 1-2 Phase 5 (paralelo com Exp11-13 training)

---

### **Phase 5 ‚Äî Resultados e Estrat√©gia P√≥s-Exp101** üß™

**DIAGN√ìSTICO CONCLU√çDO** (2026-02-23)

**Design 2√ó2 completo @ 4.3M**:
```
                      RAW Encoding    DECOMPOSED Encoding
NO SEPARATORS         Exp1 ‚úì(0.66%)   [n√£o testado ‚Äî desnecess√°rio]
WITH SEPARATORS       Exp101 ‚úì(0.53%) Exp11 ‚úì(0.97%)
```

**Conclus√£o do diagn√≥stico**: o culpado em Exp11 era o **encoding decomposed (NFD)**, n√£o os separadores.
- Separadores sozinhos (Exp101 vs Exp1): PER **melhora** ‚àí20% (0.66‚Üí0.53), WER levemente pior (+6%)
- Decomposed + separadores (Exp11 vs Exp1): regress√£o severa (+47% PER, +33% WER)
- **Veredicto**: Encoding NFD √© incompat√≠vel com LSTM para PT-BR. Separadores s√£o neutros/positivos no PER.

**Achado n√£o previsto ‚Äî Exp101 supera SOTA no PER**:
- Exp101 (4.3M + raw + sep): PER **0.53%** < Exp9 SOTA (0.58%)
- Mas WER Exp101 (5.99%) > Exp9 SOTA (4.96%) ‚Äî separadores introduzem confus√£o de alinhamento no n√≠vel de palavra

**‚úÖ PHASE 5 COMPLETA (2026-02-23)**

**Exp102 ‚Äî Intermediate 9.7M + raw + separadores** ‚úÖ COMPLETO:
- PER: **0.52%** (melhor PER absoluto de todos os experimentos)
- WER: **5.79%** (n√£o supera Exp9 WER 4.96%)
- Treino: epoch 82/120, val_loss 0.0136, 295min total

**Resultado do decision tree**: condi√ß√£o "separadores t√™m teto em WER" confirmada
- Exp102 (9.7M + sep): PER 0.52% ‚úÖ | WER 5.79% ‚ùå vs Exp9 (4.96%)
- Capacity maior (9.7M vs 4.3M) atenua WER (5.99%‚Üí5.79%) mas n√£o resolve o trade-off

**Finding public√°vel (Phase 5)**:
> Syllable separators create a consistent PER/WER Pareto trade-off in BiLSTM G2P for PT-BR:
> PER ‚àí17-20% (melhora), WER +6-8% (piora) ‚Äî independente de capacidade (4.3M ou 9.7M).
> Mecanismo: tokens separadores adicionam alinhamento; erro de separador ‚Üí word error.

**Compara√ß√µes isoladas confirmadas**:
- Exp102 vs Exp5 (efeito sep em 9.7M): PER ‚àí17.5% ‚úÖ, WER +7.6% ‚ùå
- Exp102 vs Exp101 (efeito capacity+sep): PER ‚àí1.9% ‚úÖ, WER ‚àí3.3% ‚úÖ (capacity atenua WER)
- Exp102 vs Exp9 (sep vs DA Loss): PER ‚àí10.3% ‚úÖ, WER +16.7% ‚ùå (DA Loss superior para WER)

**‚ùå Exp12/13/14 (decomposed) ‚Äî CANCELADOS**:
- Encoding NFD comprovou-se incompat√≠vel; n√£o rodar

---

### **üî¨ Phase 6A ‚Äî Exp103: Best-of-Both-Worlds (PR√ìXIMO EXPERIMENTO)**

**Status**: ‚è≥ Planejado | Prioridade: ALTA

**Objetivo**: Combinar os dois achados de Phase 5 ‚Äî separadores (Exp102: melhor PER 0.52%) + Distance-Aware Loss (Exp9: melhor WER 4.96%) ‚Üí potencial novo SOTA absoluto.

**Exp103 ‚Äî Intermediate 9.7M + sep + DA Loss (Œª=0.2)**:
- Config: `config_exp103_intermediate_sep_distance_aware.json` ‚úÖ criado
- Mesma arquitetura Exp9/102 (emb=192, hidden=384, layers=2, dropout=0.5)
- `keep_syllable_separators: true` + `loss: distance_aware, Œª=0.2`
- Split: 60/10/30, seed=42 (compat√≠vel com Exp9/102)

**Racioc√≠nio quantitativo (hip√≥tese aditiva)**:
```
Efeito dos separadores (Exp5‚ÜíExp102): PER ‚àí17.5%, WER +7.6% (+0.41pp)
Efeito do DA Loss (Exp5‚ÜíExp9):        PER ‚àí8.0%,  WER ‚àí7.8% (‚àí0.42pp)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Combinado (Exp103 vs Exp5):            PER ~‚àí25%,  WER ~‚àí0% ‚Üí m√≠nimo
Se aditivo: PER ‚âà 0.47%, WER ‚âà 5.36% (neutro)
Se sinergia: WER < 4.96% ‚Üí NOVO SOTA ABSOLUTO
```
- Risco: tokens separadores complicam o `distance_matrix` (pesos fon√©ticos para `.` n√£o definidos)
- Tempo estimado: ~6-7h GPU (sequ√™ncias +30% por separadores)

**Compara√ß√µes que Exp103 habilita**:
| Compara√ß√£o | O que isola |
|-----------|-------------|
| Exp103 vs Exp9 | Efeito puro dos sep com DA Loss |
| Exp103 vs Exp102 | Efeito puro do DA Loss com sep |
| Exp103 vs Exp5 | Efeito combinado de sep+DA vs baseline 9.7M |

**Decis√£o p√≥s-Exp103**:
- Se PER < 0.52% AND WER < 4.96%: **Novo SOTA absoluto, Phase 6 sucesso**
- Se apenas PER melhora: sep+DA combinam no PER mas n√£o WER ‚Üí publicar finding
- Se pior que ambos: efeitos se cancelam ou se prejudicam ‚Üí publicar finding negativo

---

### **üìä Phase 6B ‚Äî Split Sensitivity (OPTIONAL ABLATION)**

**Status**: Planejado como ablation opcional (baixa prioridade)

**Pergunta**: Impacto de reduzir treino de 60% para 50% (mais test data)?

**An√°lise**:
- 50/10/40 split: 47.9k train (‚àí17%) | 38.4k test (+33% vs 28.8k atual)
- Ganho de test: marginal ‚Äî test set atual j√° √© 57√ó maior que LatPhon (500 amostras); œá¬≤ p=0.678 √© excelente
- Custo: ‚àí17% dados de treino ‚Üí PER/WER provavelmente piora
- **Conclus√£o**: N√£o recomendado para performance. √ötil apenas para medir sensibilidade a dados.
- Config potencial: `config_exp104_intermediate_50split.json` (mesma arquitetura Exp9)

**An√°lise de arquiteturas maiores**:
- Exp2 (17.2M, CE): WER 4.98% < Exp9 4.96% ‚Äî arquitetura maior N√ÉO ajuda
- Exp10 (17.2M, DA): WER 5.25% ‚Äî DA Loss prejudica high-capacity
- **Conclus√£o**: Gargalo √© LSTM sequencial, n√£o capacidade. N√£o investigar further sem mudan√ßa de arquitetura.

---

### **üü° Phase 6C ‚Äî Multilingual Tupi Support (DEFER, futuro)**

**Status**: RFP (Request For Proposal) apenas
**Documenta√ß√£o**: Ver an√°lise de viabilidade multilingual em [docs/05_THEORY.md](docs/05_THEORY.md)

**Raz√£o para DEFER**:
- Precisa Tupi dictionary (coletar/validar)
- A/B test necess√°rio (multilingual vs monolingual)
- Phase 5 + 5A deve completar primeiro

**Se decidirmos fazer** (Phase 6):
1. Coletar Tupi IPA dictionary
2. Create config_expX_multilingual.json (PT-BR + Tupi + opcional EN)
3. Treinar Exp14-15 multilingual
4. Comparar vs Exp9 (comprovar n√£o prejudica PT-BR SOTA)
5. Documentar trade-offs

**Milestone**: Postergar at√© Phase 6 AP√ìS Phase 5 conclu√≠da

---

### **ü™ô Exp11-13 ‚Äî Split Sensitivity Tests (ORIGINAL PLAN)**

**Status**: NOVO NOME (era "Exp12-14")  
**Raz√£o rename**: Exp11-13 agora para decomposed encoding (Phase 5), n√£o para split sensitivity.

**Split Sensitivity (NOVO DEFER)**:
- Exp15 ‚Äî Random split 60/10/30 (n√£o estratificado)
- Exp16 ‚Äî Few-shot 30/10/60 (pouco treino)

**Quando implementar**: Phase 6, ap√≥s OOV/neologisms solidificado.

---

### **üéØ CAMINHO FELIZ ‚Äî Implementa√ß√µes Paralelas (n√£o impactam GPU)**

**Exp5 RODANDO em paralelo. Pr√≥ximas decis√µes:**

1. ‚úÖ **DONE**: Exp0 e Exp1 completos, avaliados, analyze_errors rodado

2. ‚úÖ **SINCRONIZA√á√ÉO COMPLETA (feito agora, ~20min)**:
   - ‚úì Integrar Exp1 em `docs/performance.json` com m√©tricas graduadas PanPhon
   - ‚úì Atualizar STATUS.md com progresso real (Exp2 epoch 89/120)
   - ‚úì Sincronizar TODO.md com estado atual
   - ‚úì Atualizar performance.json revision 3.2

3. üìù **PR√ìXIMO PASSO RECOMENDADO (baixo impacto, ~1-2h)**:
   - [ ] Criar esqueleto `src/compare_models.py` (estrutura b√°sica + parsing de CSV/JSON)
   - [ ] Validar configs exp3-5 (PanPhon + intermediate) t√™m todas as chaves necess√°rias
   - [ ] **OPCIONAL**: Script de valida√ß√£o autom√°tica de configs (`validate_configs.py`)

4. ‚è≥ **AP√ìS Exp2 COMPLETO (~4-6h, ~95-100% progresso atual)**:
   - Run inference Exp2: `python src/inference.py --index 2`
   - Run analyze_errors Exp2: `python src/analyze_errors.py --index 2`
   - Compara√ß√£o 3-way: Exp0 vs Exp1 vs Exp2 (capacity sweep completo)
   - Atualizar performance.json com Exp2 (revision 3.3)
   - **DECIS√ÉO CR√çTICA**: Treinar Exp5 ou pular para Exp3/4?
     - Argumento PRO Exp5 primeiro: completa capacity sweep antes de PanPhon
     - Argumento PRO Exp3/4 primeiro: testa features fon√©ticas logo

5. üöÄ **FILA DE TREINAMENTO (sequencial, total ~25-35h GPU)**:
   - Op√ß√£o A: Exp5 ‚Üí Exp3 ‚Üí Exp4 (capacity completo primeiro)
   - Op√ß√£o B: Exp3 ‚Üí Exp4 ‚Üí Exp5 (features fon√©ticas primeiro)
   - Avalia√ß√£o completa ap√≥s cada experimento
   - An√°lise comparativa final 6-way com `compare_models.py`


---

## ‚úÖ RESOLVIDO ‚Äî Dataset IPA normalizado (2026-02-18)

Dataset `dicts/pt-br.tsv` normalizado: 10,252 linhas corrigidas ('g' U+0067 ‚Üí '…°' U+0261).
Backup em `docs/dicts.7z`. Modelos antigos incompat√≠veis ‚Äî retreino necess√°rio.

Ver: [docs/EXPERIMENTS_RESULTS.md](docs/EXPERIMENTS_RESULTS.md)

---

## ‚úÖ CONCLU√çDO (2026-02-18)

### **Fase 0: Ferramentas de Gest√£o e Manuten√ß√£o** ‚úÖ NOVO (2026-02-18)
- [x] **T1 - Gerenciador de Experimentos** ‚úÖ COMPLETO
  - Arquivo: `src/manage_experiments.py` (608 linhas)
  - **Funcionalidades**:
    - `--list`: Lista experimentos com classifica√ß√£o (completo/rodando/incompleto/√≥rf√£o)
    - `--show N`: Detalhes completos de artefatos (modelo, metadata, history, evaluation)
    - `--prune N`: Remove experimento espec√≠fico com confirma√ß√£o
    - `--prune-incomplete`: Remove todos incompletos (preserva rodando)
    - `--stats`: Estat√≠sticas gerais (storage, distribui√ß√£o, recuper√°vel)
    - `--dry-run`: Simula√ß√£o segura sem deletar
  - **Classifica√ß√£o inteligente**:
    - COMPLETO: training_completed=True + artefatos de avalia√ß√£o
    - RODANDO: modificado nos √∫ltimos 15min
    - INCOMPLETO: training interrompido
    - √ìRF√ÉO: modelo sem metadados ou corrompido
  - **Indexa√ß√£o consistente**: Mapeamento `index_map` garante que `--show N` corresponde ao [N] do `--list`
  - **Encoding Windows**: Fix UTF-8 para emojis (‚úì‚è≥‚ö†‚ùå)
  - **Integra√ß√£o**: Usa `utils.get_all_models_sorted()` para ordem padronizada
  - **Resultado**: Limpeza de 16.50 MB (√≥rf√£o exp1_152558 removido)

- [x] **T2 - Dataset Statistics Cache** ‚úÖ COMPLETO
  - Arquivo: `src/compute_dataset_stats.py`
  - Cache: `data/dataset_stats.json` (permanente, checksum-validated)
  - **M√©tricas de representatividade**:
    - œá¬≤ test: p=0.9500 (distribui√ß√µes id√™nticas entre splits)
    - Cram√©r's V: 0.0007 (associa√ß√£o desprez√≠vel)
    - Coefficient of Variation: 0.03% (variabilidade m√≠nima)
    - Confidence Intervals 95%: todos overlapping
    - **Quality Score**: 10/10 (EXCELENTE)
  - **Tooltips educativos**: Hover explica cada m√©trica no HTML

- [x] **T3 - Fun√ß√£o Centralizada de Ordena√ß√£o** ‚úÖ COMPLETO
  - Fun√ß√£o: `utils.get_all_models_sorted()` (fonte √∫nica de verdade)
  - Usado por: `inference.py`, `manage_experiments.py`, `report_generator.py`
  - Crit√©rio: Ordena√ß√£o por `st_mtime` (modifica√ß√£o)
  - **Garantia**: √çndices consistentes entre todos os scripts

### **Fase 0.1: Manager Orquestrador (Backlog de Hardening)** ÔøΩ QUASE COMPLETO
- [x] **M1 - Contrato de responsabilidades (Manager x Subprocessos) ‚Äî V1** ‚úÖ COMPLETO
  - Definir contrato expl√≠cito de decis√£o:
    1. Manager decide o que est√° pendente por artefato (vis√£o externa)
    2. Subprocesso confirma internamente (vis√£o interna)
    3. Diverg√™ncia gera warning de consist√™ncia
  - Objetivo: dupla valida√ß√£o de incrementalidade para detectar drift de arquivos e regras.
  - **Status**: V1 implementado, executado com sucesso em `--process-all`

- [x] **M2 - `--process-all` com cobertura completa de fluxo ‚Äî V1** ‚úÖ COMPLETO
  - Estado atual: processa inference, analyze_errors, plots e gera√ß√£o de relat√≥rio HTML.
  - Regra V1: report √© agendado por timestamp (outdated) ou em modo force.
  - **Status**: V1 implementado, validado com sucesso

- [x] **M3 - `--dry-run` em duas perspectivas (manager + subprocesso) ‚Äî V1** ‚úÖ COMPLETO
  - `--dry-run` do manager segue simulando decis√µes por artefato.
  - Valida√ß√£o cruzada V1: manager tamb√©m consulta `inference.py --dry-run` para os itens de infer√™ncia.
  - Pend√™ncia V2: expandir `--dry-run` interno para `analyze_errors.py` e `analysis.py`.
  - **Status**: V1 implementado, testado com `--dry-run` e `--process-all`

- [x] **M4 - Pol√≠tica de force em 2 n√≠veis (fraco/forte) ‚Äî V1** ‚úÖ COMPLETO
  - `--force`: reexecuta etapas leves (analyze_errors, plots, report), **sem** for√ßar inference.
  - `--force-inference`: ativa for√ßa tamb√©m para inference (modo forte, expl√≠cito).
  - Motiva√ß√£o: evitar custo pesado acidental de infer√™ncia total.
  - **Status**: V1 implementado, CLI args reconhecidos

- [ ] **M5 - Matriz de execu√ß√£o expl√≠cita (para previsibilidade)**
  - Documentar e imprimir no `--dry-run` a matriz:
    - incremental vs force fraco vs force forte
    - quais artefatos s√£o checados por etapa
    - quais flags s√£o repassadas a cada subprocesso
  - Objetivo: comportamento audit√°vel e sem ambiguidades.

- [ ] **M6 - Timeouts e robustez por etapa**
  - Revisar timeout fixo atual (inference 10min, analyze_errors 5min, plots 2min).
  - Tornar configur√°vel por CLI (`--timeout-inference`, etc.) para evitar falso timeout em m√°quinas lentas.

- [x] **M7 - Comandos r√°pidos atualizados (CLI manager v2)** ‚úÖ COMPLETO
  - Inclu√≠do no bloco de comandos r√°pidos:
    - `python src/manage_experiments.py --process-all --dry-run`
    - `python src/manage_experiments.py --process-all --force`
    - `python src/manage_experiments.py --process-all --force --force-inference`
  - **Status**: Testados com sucesso

- [ ] **M8 - Planejamento de treino por `config*.json` (manager como orquestrador completo)**
  - Objetivo: manager tamb√©m acompanhar estado de treino (n√£o s√≥ p√≥s-treino).
  - Escopo proposto:
    - Escanear `config*.json` na raiz.
    - Mapear `experiment.name`/config para runs existentes (`models/*_metadata.json`).
    - Classificar: `n√£o iniciado` / `em execu√ß√£o` / `conclu√≠do` / `config sem run v√°lido`.
    - Expor em `--guide` uma fila sugerida de treino e lacunas de configura√ß√£o.
  - Resultado esperado: vis√£o √∫nica de pipeline completo (train + inference + analyze + report).
  - **Status**: Backlog

- [x] **T4 - Literatura SOTA Integration** ‚úÖ COMPLETO
  - Arquivo: `docs/performance.json` (benchmarks manuais)
  - Integrado em: `src/reporting/report_generator.py`
  - **Benchmark sections**:
    - `fg2p_models`: Exp0-4 resultados
    - `literature_ptbr`: LatPhon, XphoneBR
    - `literature_general`: DeepPhonemizer, ByT5, Phonetisaurus
  - **Exp0 adicionado**: PER 1.12%, WER 9.37%, m√©tricas graduadas
  - **HTML auto-display**: Tabelas comparativas renderizadas

### **Fase 1: Melhorias no Sistema de Relat√≥rios**
- [x] **A1 - Clarificar Fonemas vs Palavras** ‚úÖ COMPLETO
  - Problema: Interface mostra "270,228 (99.04%)" sem explicar se s√£o fonemas ou palavras
  - Solu√ß√£o implementada: Duas se√ß√µes distintas no HTML:
    - "üìä Distribui√ß√£o por FONEMA" (270,228 fonemas classificados individualmente)
    - "üìù Distribui√ß√£o por PALAVRA" (27,374 palavras classificadas pela pior classe)
  - Arquivos modificados: `src/reporting/report_generator.py` (linhas ~1050-1170)
  - **Detalhes t√©cnicos**:
    - Se√ß√£o FONEMA usa `class_distribution` do `load_error_analysis()`
    - Se√ß√£o PALAVRA usa novo `word_distribution` parseado de "WER SEGMENTADO"
    - Adicionados small tags explicativos: "(exata)", "(erro leve)", "(erro m√©dio)", "(erro grave)"
  
- [x] **A2 - Auto-executar analyze_errors** ‚úÖ COMPLETO
  - Problema: Workflow manual (inference ‚Üí analyze_errors ‚Üí report)
  - Solu√ß√£o implementada: `run_analyze_errors_if_needed()` detecta arquivo faltando e executa subprocess
  - Arquivos modificados: `src/reporting/report_generator.py` (linhas ~246-275)
  - **Detalhes t√©cnicos**:
    - Fun√ß√£o verifica `results/error_analysis_{model_name}.txt` existe
    - Se n√£o, executa `subprocess.run([sys.executable, "src/analyze_errors.py", "--model", model_name])`
    - Timeout 120s, logs informativos, tratamento de erros
    - Fix importante: usa `sys.executable` (venv) em vez de "python" hardcoded
  
- [x] **Teste de Workflow Integrado** ‚úÖ VALIDADO
  - ‚úÖ `python src/reporting/report_generator.py` detecta arquivo faltando e gera automaticamente (~15s)
  - ‚úÖ HTML mostra m√©tricas clarificadas: 270,228 fonemas vs 27,374 palavras
  - ‚úÖ Report abre no navegador sem erros

- [x] **A1.1 - Tooltips Explicativos** ‚úÖ COMPLETO
  - Problema: Usu√°rio n√£o entendia diferen√ßa entre "…õ‚Üîe" (Classe B) e "a‚Üî…ô" (Classe C)
  - Solu√ß√£o implementada: Atributos `title` com explica√ß√µes sobre features fon√©ticas
  - Arquivos modificados: `src/reporting/report_generator.py` (linhas ~1089, ~1168, ~1210, ~1140)
  - **Detalhes t√©cnicos**:
    - Classe B: "apenas 1 feature diferente (ex: altura em …õ‚Üîe). Articula√ß√£o muito pr√≥xima"
    - Classe C: "2-3 features diferentes (ex: altura+recuo em a‚Üî…ô). Fonemas relacionados"
    - Tooltips adicionados em: legenda, badges confus√µes, labels distribui√ß√µes FONEMA/PALAVRA
    - Hover interativo explica "features" sem poluir interface

### **Fase 2: Detec√ß√£o de Anomalias no Comportamento do Modelo**
- [x] **A3.1 - M√©tricas de Truncation/Over-generation** ‚úÖ COMPLETO
  - Problema: Modelo pode gerar predi√ß√µes muito curtas ou muito longas
  - Solu√ß√£o implementada: Fun√ß√£o `analyze_length_distribution()` detecta diff ‚â§ -3 (truncation) e ‚â• +3 (over-generation)
  - Arquivos modificados: `src/analyze_errors.py` (linhas ~233-282)
  - **Detalhes t√©cnicos**:
    - Calcula estat√≠sticas: mean, std, median, min, max de diff=(pred_len - ref_len)
    - Separa listas de truncated e overgenerated com exemplos
    - Resultados exp3: apenas 1 truncated ("absa"), 0 over-generated (modelo est√°vel!)
  
- [x] **A3.2 - Detector de Alucina√ß√µes RNN** ‚úÖ COMPLETO + REFINADO (2026-02-18)
  - Problema: RNNs podem gerar loops (LSTM "preso" em padr√£o repetitivo)
  - Solu√ß√£o implementada: Fun√ß√£o `detect_hallucinations()` com detec√ß√£o adaptativa
  - Arquivos modificados: `src/analyze_errors.py` (linhas ~285-396)
  - **Detalhes t√©cnicos ‚Äî L√≥gica Final (v3):**
    - **Princ√≠pio:** Comparar n√≠vel de repetitividade da palavra com a predi√ß√£o
    - **Baseline adaptativo:** `max(grafemas_max, ref_max)` ‚Äî usa o maior entre:
      - Repeti√ß√µes naturais nos grafemas da palavra (ex: "urura√≠" ‚Üí bigram (u,r)√ó2)
      - Repeti√ß√µes na refer√™ncia fon√©tica (ex: "digi" ‚Üí  íi √ó2 natural do mapeamento g‚Üí í)
    - **Pr√©-filtro:** `pred == ref ‚Üí skip` (predi√ß√µes corretas nunca s√£o alucina√ß√µes)
    - **Detec√ß√£o:** Flageia se pred tem mais repeti√ß√µes consecutivas que o baseline
    - **Checks secund√°rios:** char_explosion (pred > 2√óref+4), length_explosion (pred > 2√óref)
    - **Resultados finais:**
      - Exp2: 2 detec√ß√µes (pol√≠tico-administrativas = loop severo t-…æ-i √ó9, todos-os-santos = padr√£o an√¥malo)
      - Exp3: 1 detec√ß√£o (p√≥s-aposentadoria = micro-stutter d-o √ó2)
      - Zero falsos positivos (urura√≠, cidadanias, ararapira, digiescolhidos todos filtrados)
    - **Evolu√ß√£o:** 253 ‚Üí 12 ‚Üí 4 ‚Üí 2-1 detec√ß√µes (refinamento progressivo)

- [x] **B2.1 - Exemplos por Classe no HTML** ‚úÖ NOVO (2026-02-19)
  - Problema: Relat√≥rio mostrava barras de classe sem exemplos vis√≠veis inline
  - Solu√ß√£o implementada: Se√ß√£o "üîç Exemplos por Classe de Erro" com `<details>` collapsible
  - Mostra 10 palavras por classe B/C/D com word, score, pred, ref
  - Complementa o modal existente (showExamples) que permite ver todos
  
- [x] **B2 - Se√ß√£o de Anomalias no HTML** ‚úÖ COMPLETO
  - Solu√ß√£o implementada: Dashboard visual com grid responsivo de cards
  - Arquivos modificados: 
    - `src/reporting/report_generator.py` (linhas ~295-407 parser, ~1340-1440 HTML)
  - **Detalhes t√©cnicos**:
    - Parser extrai: length_stats, truncated_count, hallucinations_count + exemplos (top-10)
    - HTML: 3 cards com cores sem√¢nticas (info/warning/danger)
      - Card 1: Distribui√ß√£o de comprimento (m√©dia, desvio)
      - Card 2: Truncation com exemplos (ref vs pred)
      - Card 3: Alucina√ß√µes com patterns (bigram_loop, char_repeat)
    - Grid responsivo: `repeat(auto-fit, minmax(250px, 1fr))`
    - Apenas aparece se h√° anomalias detectadas (condicional `has_any_anomaly`)

---

## üöß PR√ìXIMAS ETAPAS

### **Experimento 4: PanPhon Embedding Real**
- [x] **Fase 1: Criar m√≥dulo isolado** `src/phoneme_embeddings.py` ‚úÖ COMPLETO (2026-02-18)
  - Factory pattern: `get_embedding_layer(type, config)`
  - Classes: `LearnedPhonemeEmbedding`, `PanPhonPhonemeEmbedding`
  - Insight arquitetural: PanPhon s√≥ usado no `__init__` ‚Üí features baked em `state_dict`
  - Resolu√ß√£o UTF-8: Subprocess + persistent cache (elegante, sem `-X utf8` parameter)
  - Performance: 796ms (first) ‚Üí 0ms (subsequent in-process) ‚Üí ~50ms (new process with cache)

- [x] **Fase 2: Refatorar g2p.py** ‚úÖ COMPLETO (2026-02-18)
  - Modificado `Decoder.__init__`: aceita `embedding_type="learned"` e `phoneme_i2p=None` (defaults)
  - Modificado `G2PLSTMModel.__init__`: propaga novos par√¢metros
  - Usa `actual_emb_dim` din√¢mico (128D para learned, 24D para panphon)
  - Backward compatibility: exp2/exp3 funcionam sem mudan√ßas (testado)

- [x] **Fase 3: Atualizar train.py/inference.py** ‚úÖ COMPLETO (2026-02-18)
  - `train.py`: L√™ `embedding_type` do config, passa `phoneme_i2p` se panphon
  - `inference.py`: L√™ `embedding_type` do metadata, reconstr√≥i modelo corretamente
  - Config salvo no metadata ‚Üí reproduzibilidade total

- [x] **Fase 4: Criar config_exp4_panphon.json** ‚úÖ COMPLETO (2026-02-18)
  - Baseado no config.json (exp2)
  - `"embedding_type": "panphon"`, `"emb_dim": 24` (documentado, ser√° 24D fixo)
  - `"experiment.name": "exp4_panphon"`

- [ ] **Fase 5: Treinar TODOS os experimentos** üöß EM ANDAMENTO
  - Dataset normalizado ‚Üí retreino de Exp0‚ÄìExp5 necess√°rio
  - Sequ√™ncia planejada:
    - [x] Exp0 (70/10/20 baseline) ‚Üí ‚úÖ COMPLETO
    - [üîÑ] Exp1 (60/10/30 baseline) ‚Üí ‚è≥ RODANDO (epoch 33/120)
    - [ ] Exp2 (60/10/30 extended 2√ó) ‚Üí ‚è∏ Aguardando Exp1
    - [ ] Exp5 (60/10/30 intermediate 1.5√ó) ‚Üí ‚è∏ Novo, aguardando Exp2
    - [ ] Exp3 (60/10/30 PanPhon trainable) ‚Üí ‚è∏ Aguardando Exp5
    - [ ] Exp4 (60/10/30 PanPhon fixed) ‚Üí ‚è∏ Aguardando Exp3
  - **Configs dispon√≠veis**:
    - ‚úÖ `config_exp0_baseline_70split.json` (4.3M params)
    - ‚úÖ `config_exp1_baseline_60split.json` (4.3M params)
    - ‚úÖ `config_exp2_extended_512hidden.json` (17.2M params)
    - ‚úÖ `config_exp3_panphon_trainable.json` (PanPhon 24D)
    - ‚úÖ `config_exp4_panphon_fixed_24d.json` (PanPhon 24D fixed)
    - ‚úÖ `config_exp5_intermediate_60split.json` (9.7M params) ‚Äî **NOVO**
  - **Prop√≥sito Exp5**:
    - Preenche gap entre exp1 (4.3M) e exp2 (17.2M)
    - Testa scaling: capacity moderada (1.5√ó) compensa dados limitados?
    - Expected: PER ~0.60-0.64% (intermedi√°rio entre exp1 e exp2)
    - Se exp5 ‚âà exp2 ‚Üí 192D embeddings s√£o suficientes (ROI melhor)
    - Se exp5 ‚âà exp1 ‚Üí mais dados (exp0) importa mais que capacity
  - Total estimado: ~90-110h GPU (~4-5 dias)
  - **Status atual**: 1/6 completo, 1/6 rodando, 4/6 pendentes

- [ ] **Fase 6: Valida√ß√£o completa** (ap√≥s treino)
  - Comparar PER/WER: Exp0 vs Exp1 vs Exp2 vs Exp3 vs Exp4
  - Avaliar generaliza√ß√£o: features fon√©ticas ajudam OOV?
  - Report HTML comparativo
  - Pipeline: inference ‚Üí analyze_errors ‚Üí report

- [ ] **Fase 6.5: An√°lise Comparativa Multidimensional de Modelos** üÜï (complexidade: BAIXA-M√âDIA)
  - **Objetivo**: Relat√≥rio completo com vantagens/desvantagens de cada modelo segmentado por m√∫ltiplas dimens√µes
  
  - **Escopo completo (10 dimens√µes de an√°lise)**:
    
    **1. M√âTRICAS CL√ÅSSICAS (baseline)**
       - PER absoluto (Exp0: 1.12% vs Exp1: 0.66% ‚Äî 41% melhor)
       - WER absoluto (Exp0: 9.37% vs Exp1: 5.65% ‚Äî 40% melhor)
       - Accuracy (Exp0: 90.63% vs Exp1: 94.35% ‚Äî +3.72pp)
       - **Interpreta√ß√£o**: "Qual modelo tem menor taxa de erro bruta?"
    
    **2. M√âTRICAS GRADUADAS (PanPhon ‚Äî realismo lingu√≠stico)**
       - PER ponderado (Exp0: 0.53% vs Exp1: 0.30% ‚Äî 43% melhor)
       - WER graduado (Exp0: 1.12% vs Exp1: 0.68% ‚Äî 39% melhor)
       - Delta cl√°ssico‚Üígraduado (Exp0: -8.25pp vs Exp1: -4.98pp)
       - **Interpreta√ß√£o**: "Qual modelo produz erros mais 'perdo√°veis' linguisticamente?"
    
    **3. DISTRIBUI√á√ÉO DE CLASSES DE ERRO (A/B/C/D)**
       - Classe A (exato): Exp0 98.20% vs Exp1 98.95% (+0.75pp)
       - Classe B (leve): Exp0 0.65% vs Exp1 0.40% (-38% erros leves)
       - Classe C (m√©dio): Exp0 0.25% vs Exp1 0.13% (-48% erros m√©dios)
       - Classe D (grave): Exp0 0.90% vs Exp1 0.52% (-42% erros graves) ‚≠ê
       - **Interpreta√ß√£o**: "Qual modelo evita mais erros cr√≠ticos (Classe D)?"
    
    **4. WER SEGMENTADO POR CLASSE (an√°lise por palavra)**
       - WER classe B: Exp0 5.92% vs Exp1 3.68% (erros leves em palavras)
       - WER classe C: Exp0 1.72% vs Exp1 0.93% (erros m√©dios em palavras)
       - WER classe D: Exp0 1.74% vs Exp1 1.04% (erros graves em palavras) ‚≠ê
       - **Interpreta√ß√£o**: "Distribui√ß√£o de palavras por severidade de erro"
    
    **5. SCORE M√âDIO POR CLASSE (qualidade residual)**
       - Classe B score: Exp0 0.971 vs Exp1 0.971 (empate t√©cnico)
       - Classe C score: Exp0 0.913 vs Exp1 0.920 (+0.7% qualidade)
       - Classe D score: Exp0 0.541 vs Exp1 0.523 (erros graves igualmente ruins)
       - **Interpreta√ß√£o**: "Quando erra, qual modelo erra 'menos mal'?"
    
    **6. ANOMALIAS COMPORTAMENTAIS (robustez)**
       - Truncation: Exp0 2 palavras vs Exp1 0 (100% fix) ‚≠ê
       - Over-generation: Exp0 0 vs Exp1 0 (empate)
       - Alucina√ß√µes (bigram loops): Exp0 14 vs Exp1 1 (93% redu√ß√£o) ‚≠ê
       - **Interpreta√ß√£o**: "Qual modelo √© mais 'sano' (menos bugs patol√≥gicos)?"
    
    **7. TOP CONFUS√ïES FON√âTICAS (padr√µes de erro)**
       - Top-5 substitui√ß√µes: comparar frequ√™ncias (e‚Üí…õ, …î‚Üío, etc.)
       - Dist√¢ncia articulat√≥ria m√©dia: Exp0 vs Exp1
       - Confus√µes graves (Classe D): Exp0 " É‚Üík" 39√ó vs Exp1 34√ó (-13%)
       - **Interpreta√ß√£o**: "Quais fonemas cada modelo confunde mais?"
    
    **8. ARQUITETURA & TAMANHO DO MODELO**
       - Par√¢metros: Exp0 4.3M vs Exp1 4.3M vs Exp2 17.2M vs Exp5 9.7M
       - Embedding dim: Exp0 128 vs Exp2 256 (2√ó capacity)
       - Hidden dim: Exp0 256 vs Exp2 512 (2√ó capacity)
       - Params/PER ratio: Exp0 3.84M/% vs Exp1 6.52M/% (efici√™ncia) ‚≠ê
       - **Interpreta√ß√£o**: "Performance por par√¢metro (ROI de capacidade)"
    
    **9. DIN√ÇMICA DE TREINAMENTO (converg√™ncia & efici√™ncia)**
       - Epochs at√© first best loss: Exp0 vs Exp1 vs Exp2
       - Epochs at√© early stop: Exp0 71/120 vs Exp1 95/120 (Exp1 treinou +34%)
       - Taxa melhoria/epoch: (loss_inicial - loss_final) / epochs
       - Tempo m√©dio/epoch: CSV timestamps ‚Üí epoch_duration m√©dia
       - Total GPU time: Exp0 (71 √ó ~150s) vs Exp1 (95 √ó ~150s)
       - Samples/sec (throughput): Exp0 vs Exp1 vs Exp2 (Exp2 mais lento?)
       - **Interpreta√ß√£o**: "Qual modelo converge mais r√°pido? Custo-benef√≠cio GPU?"
    
    **10. DATASET & SPLIT QUALITY (contexto experimental)**
       - Split usado: Exp0 70/10/20 vs Exp1 60/10/30
       - Test set size: Exp0 19.2k vs Exp1 28.8k (+50% confiabilidade estat√≠stica)
       - Train set size: Exp0 67.1k vs Exp1 57.6k (-14% dados)
       - Stratification quality: œá¬≤ p-value, Cram√©r's V
       - **Interpreta√ß√£o**: "Qual split d√° melhor generaliza√ß√£o?"
  
  - **Implementa√ß√£o t√©cnica**:
    - **Arquivo**: `src/compare_models.py` (~400-500 linhas, expandido)
    - **Entrada**: 
      ```bash
      python src/compare_models.py --models 0 1 2    # Compara 3+ modelos
      python src/compare_models.py exp0 exp1 exp2    # Por nome
      python src/compare_models.py --all             # Todos dispon√≠veis
      ```
    - **Fontes de dados**:
      1. `_history.csv` ‚Üí training dynamics (converg√™ncia, tempo/epoch)
      2. `_metadata.json` ‚Üí arquitetura (params, dims, config)
      3. `error_analysis_*.txt` ‚Üí PanPhon classes, anomalias
      4. `predictions_*.tsv` ‚Üí top confus√µes, scores
      5. `evaluation_*.txt` ‚Üí PER/WER cl√°ssico
    
    - **Output estruturado**:
      - JSON: `comparison_exp0_exp1_exp2.json` (dados brutos)
      - TXT: `comparison_exp0_exp1_exp2_report.txt` (formatado, interpreta√ß√µes)
      - CSV: `comparison_summary.csv` (tabela para Excel/paper)
      - **OPTIONAL**: HTML interativo com gr√°ficos (matplotlib/plotly)
    
    - **Segmenta√ß√£o por dimens√£o**:
      ```json
      {
        "metrics_classic": {"per": {...}, "wer": {...}, "acc": {...}},
        "metrics_graduated": {"per_weighted": {...}, "wer_graduated": {...}},
        "error_classes": {"A": {...}, "B": {...}, "C": {...}, "D": {...}},
        "anomalies": {"truncations": {...}, "hallucinations": {...}},
        "confusion_patterns": {"top_5": [...], "class_d_confusions": [...]},
        "architecture": {"params": {...}, "efficiency": {...}},
        "training_dynamics": {"convergence": {...}, "throughput": {...}},
        "dataset_quality": {"split": {...}, "stratification": {...}}
      }
      ```
    
    - **Interpreta√ß√£o autom√°tica** (heur√≠sticas):
      - "Exp1 vence em 8/10 dimens√µes ‚Üí modelo superior overall"
      - "Exp2 tem 4√ó params mas s√≥ 12% melhor PER ‚Üí diminishing returns"
      - "Exp5 sweet spot: 2√ó params de Exp1, converge 20% mais r√°pido"
      - "Split 60/10/30 consistentemente melhor que 70/10/20"
  
  - **Complexidade atualizada**: ‚≠ê‚≠ê BAIXA-M√âDIA
    - Dados j√° existem (CSV, JSON, TXT j√° gerados)
    - C√°lculos simples (diferen√ßas, ratios, propor√ß√µes)
    - Parsing de texto estruturado (error_analysis tem se√ß√µes bem definidas)
    - **Parte trabalhosa**: Parsing de 5 arquivos diferentes por modelo
    - **Tempo estimado**: 4-8 horas (parsing robusto + formata√ß√£o + testes)
  
  - **Valor agregado**:
    - ‚úì **Decis√µes justificadas**: "Por que escolher Exp1 em produ√ß√£o?"
    - ‚úì **Paper-ready**: Tabelas comparativas prontas para publica√ß√£o
    - ‚úì **Troubleshooting**: "Exp2 n√£o converge? Veja que Exp1 convergiu em 23 epochs"
    - ‚úì **ROI analysis**: "Vale treinar modelo 4√ó maior? Ganho √© s√≥ 10%"
    - ‚úì **Ablation study**: Isola efeito de split vs capacity vs architecture
    - ‚úì **Roadmap futuro**: "Focar em reduzir Classe D (k‚Üí É confusions)"
  
  - **Prioridade de implementa√ß√£o**:
    1. **Agora (ap√≥s Exp1 completo)**: Dimens√µes 1-6 (m√©tricas + erros)
    2. **Ap√≥s Exp2**: Adicionar dimens√µes 8-9 (arquitetura + converg√™ncia)
    3. **Ap√≥s todos 6 experimentos**: An√°lise completa 10D + HTML interativo
  
  - **Status**: ‚è∏ Pendente (implementar ap√≥s Exp2 para ter baseline+extended)

### **Melhorias exp4 - PanPhon** (p√≥s-treino)
- [x] **PH-1: Normalizar IPA do dataset** ‚úÖ COMPLETO (2026-02-18)
  - 10,252 linhas corrigidas ('g' U+0067 ‚Üí '…°' U+0261)
  - Script: `scripts/normalize_ipa.py`, backup em `docs/dicts.7z`
  - Modelos antigos incompat√≠veis ‚Üí retreino obrigat√≥rio

- [ ] **PH-2: Expandir mapeamento IPA para outros s√≠mbolos**
  - Verificar se h√° outros s√≠mbolos Unicode n√£o-can√¥nicos no dataset
  - Atualizar `IPA_NORMALIZATION_MAP` em `normalize_ipa.py`
  - Adicionar valida√ß√£o em CI/CD (prevenir regress√µes futuras)

- [ ] **PH-3: Fallback strategy para s√≠mbolos n√£o reconhecidos**
  - Op√ß√£o A: Vetor m√©dio de todos fonemas conhecidos (centroid)
  - Op√ß√£o B: Nearest neighbor por similaridade graf√™mica
  - Op√ß√£o C: Hybrid embedding (PanPhon + learned para unknowns)

### **Documenta√ß√£o T√©cnica** (li√ß√µes aprendidas)
- [ ] **DOC-1: Documentar solu√ß√£o UTF-8 PanPhon** üìö
  - **Onde**: README.md ou novo TROUBLESHOOTING.md
  - **T√≥picos**:
    - Problema: PanPhon + Windows + pandas 3.0 = UnicodeDecodeError (cp1252 vs utf-8)
    - Solu√ß√µes testadas: monkey patch (falha), `-X utf8` (anti-elegante)
    - Solu√ß√£o elegante: Subprocess isolado + persistent cache
    - Arquitetura: PanPhon s√≥ usado em `__init__`, features  baked em state_dict
    - Performance: 796ms ‚Üí 0ms (cache)
  - **Valor**: Futuro reference para problemas de encoding em depend√™ncias

- [ ] **DOC-2: Documentar normaliza√ß√£o Unicode IPA** 
  - Problema: 'g' (U+0067) vs '…°' (U+0261) ‚Äî visualmente id√™nticos, Unicode diferentes
  - 10,252 linhas afetadas no pt-br.tsv (~10.7%)
  - Script: `scripts/normalize_ipa.py` (valida√ß√£o + normaliza√ß√£o + backup)
  - Li√ß√£o: Sempre validar conformidade IPA em datasets fon√©ticos

---

## üéØ PESQUISA FUTURA: Caracter√≠sticas Suprassegmentais (Pros√≥dia)

### **Teoria: S√≠mbolos Modificadores de Pros√≥dia como "Ramifica√ß√µes de Fonemas"**

**Contexto:**
- Fonemas segmentais (vogais, consoantes) definem **QUE** som √© produzido
- Features suprassegmentais definem **COMO** o som √© articulado no tempo/amplitude
- Analogia: modificadores s√£o "adjetivos" dos fonemas

**Exemplos de Suprassegmentais no IPA:**

1. **Stress (Acento T√¥nico):**
   - `'Àà'` (U+02C8) = stress prim√°rio (exemplo: caÀàsa ‚Üí "C√Åsa")
   - `'Àå'` (U+02CC) = stress secund√°rio
   - **Efeito:** Aumenta dura√ß√£o, amplitude, pitch do fonema seguinte
   - **Status atual:** PanPhon retorna vetor vazio (esperado, n√£o √© fonema articulat√≥rio)

2. **Tone Markers (Tons):**
   - `‚Üó` (rising tone) - som sobe
   - `‚Üò` (falling tone) - som desce  
   - `‚Üí` (level tone) - som est√°vel
   - **Efeito:** Mud a pitch contour (crucial em l√≠nguas tonais: mandarim, tailand√™s)

3. **Length (Dura√ß√£o):**
   - `:` (U+02D0) = vogal longa (exemplo: `a:` vs `a`)
   - **Efeito:** Dobra dura√ß√£o do segmento

4. **Intonation (Entona√ß√£o):**
   - `?` (interroga√ß√£o) ‚Üí pitch rise no final
   - `!` (exclama√ß√£o) ‚Üí √™nfase + amplitude
   - **Efeito:** Muda sentido pragm√°tico da senten√ßa

**Por que isso importa para G2P:**
- **Estado atual:** Modelo trata `'Àà'` como token com zero features (PanPhon correto)
- **Limita√ß√£o:** N√£o modela **dura√ß√£o**, **pitch**, **amplitude** de fonemas adjacentes
- **Oportunidade:** Stress prediz onde o modelo deve "prestar mais aten√ß√£o"

### **Propostas de Melhorias Futuras:**

- [ ] **SUP-1: Embeddings de Stress como Contexto** üî¨ PESQUISA
  - **Ideia:** Criar embedding separado para stress markers (`'Àà'`, `'Àå'`)
  - **Implementa√ß√£o:** Concatenar com fonema seguinte (ex: `[Àà, a]` ‚Üí `[stress_emb, phoneme_emb]`)
  - **Hip√≥tese:** LSTM aprender√° que stress ‚Üí maior aten√ß√£o no fonema
  - **Baseline:** Comparar com/sem stress embeddings (ablation study)

- [ ] **SUP-2: Duration Features como Canal Adicional** üî¨
  - **Ideia:** Adicionar feature bin√°ria: `is_stressed` (+1 se seguido de `'Àà'`, 0 caso contr√°rio)
  - **Implementa√ß√£o:** Expandir feature matrix de 24D ‚Üí 25D (+ stress bit)
  - **Benef√≠cio:** Features fon√©ticas + pros√≥dicas integradas

- [ ] **SUP-3: Modelo de Aten√ß√£o Dependente de Pros√≥dia** üéì AVAN√áADO
  - **Ideia:** Attention weights modulados por stress (fonemas t√¥nicos recebem mais aten√ß√£o)
  - **Arquitetura:** Modificar Bahdanau attention para incluir stress bias
  - **Refer√™ncia:** Similar a positional encoding em Transformers

- [ ] **SUP-4: Dataset com Anota√ß√µes de Dura√ß√£o** üìä
  - **Problema:** pt-br.tsv tem stress markers mas n√£o dura√ß√£o real
  - **Solu√ß√£o:** Anotar corpus com dura√ß√µes fon√©ticas (usando alinhamento forced)
  - **Ferramentas:** Montreal Forced Aligner (MFA)
  - **Output:** TSV com: `word \t phonemes \t durations` (ex: `casa \t k a s a \t 0.08 0.12 0.06 0.10`)

### **Documenta√ß√£o Necess√°ria:**

- [ ] **DOC-3: Criar docs/SUPRASEGMENTALS.md**
  - Teoria completa de features suprassegmentais
  - Estado da arte em modelagem pros√≥dica para G2P
  - Roadmap de implementa√ß√£o (SUP-1 ‚Üí SUP-4)
  - Refer√™ncias: IPA Handbook, ToBI (Tones and Break Indices)

### **Melhoria Futura: PanPhon como Depend√™ncia Opcional**
- [ ] **Desacoplar panphon/pandas do runtime** üéØ OTIMIZA√á√ÉO
  - **Problema**: panphon (~5MB) + pandas (~30MB) s√£o pesados para produ√ß√£o
  - **Solu√ß√£o**: Mover para `requirements-dev.txt` (dev-only)
  - **Estrat√©gia**:
    1. Distribuir cache pr√©-gerado: `cache/panphon_feature_table.pkl` (1.5MB)
    2. Modelos treinados j√° t√™m matriz no `state_dict` ‚Üí zero depend√™ncia!
    3. panphon s√≥ necess√°rio para:
       - Criar cache inicial (uma vez na vida)
       - Atualizar features (rar√≠ssimo)
    4. Usu√°rio final s√≥ precisa: `torch`, `editdistance`
  - **Implementa√ß√£o**:
    - Script `scripts/generate_panphon_cache.py` (dev)
    - CI/CD gera cache automaticamente
    - Produ√ß√£o: importa cache ou state_dict (sem panphon)
  - **Impacto**: Instala√ß√£o ~35MB menor, deploy mais r√°pido

### **Dataset de Neologismos e Nomes (Avalia√ß√£o de Robustez)**
- [ ] **Criar dataset de teste OOV (Out-of-Vocabulary)** üîÑ PLANEJANDO
  - **Objetivo:** Avaliar capacidade de generaliza√ß√£o em palavras n√£o vistas
  - **Composi√ß√£o (~1000 palavras):**
    - **Neologismos:** 300 palavras (ex: "blogueiro", "text√£o", "clickbait", "selfie")
    - **Nomes pr√≥prios brasileiros:** 200 (ex: "Yasmin", "Kau√£", "Joaquim", "√çtalo")
    - **Nomes estrangeiros:** 200 (ex: "Shakespeare", "Beethoven", "Nietzsche")
    - **Compostos complexos:** 100 (ex: "anti-inflamat√≥rio", "p√≥s-modernidade")
    - **Palavras raras/arcaicas:** 100 (ex: "obl√≠vio", "escrut√≠nio", "perempt√≥rio")
    - **Palavras inventadas (pseudopalavras):** 100 (ex: "prasidente", "telef√¥nio", "computadeira")
  - **Fon√©tica manual:** Anotar IPA esperado baseado em regras PT-BR
  - **Metodologia:**
    - Criar arquivo `data/test_oov.txt` (word\tphonemes)
    - Infer√™ncia em modelos treinados (sem retreino)
    - Comparar PER/WER com test set padr√£o
    - Analisar padr√µes de erro em OOV vs vocabulary
  - **Arquivos:** `data/test_oov.txt`, `scripts/evaluate_oov.py`
  - **An√°lise esperada:**
    - Modelo generaliza bem? Ou memoriza?
    - Nomes estrangeiros: erros sistem√°ticos?
    - Pseudopalavras: segue regras fonol√≥gicas PT-BR?

---

## ÔøΩ INVESTIGA√á√ÉO LSTM/ATEN√á√ÉO EM PALAVRAS LONGAS/COMPOSTAS

### **Comportamento Observado**
- **Caso:** "pol√≠tico-administrativas" (27 fonemas na refer√™ncia)
  - Predi√ß√£o gera 50 fonemas ‚Äî trigram "t …æ i" repetido ~10√ó consecutivamente
  - LSTM ficou preso em loop de aten√ß√£o (decoder reutiliza mesmas posi√ß√µes do encoder)
  - √â o **√∫nico caso real de alucina√ß√£o** entre ~27.374 palavras avaliadas

### **Hip√≥teses**
1. **Comprimento excessivo:** Palavras compostas com h√≠fen podem ultrapassar o contexto efetivo do LSTM
2. **Aten√ß√£o Bahdanau:** Com sequ√™ncias muito longas, alignment scores podem "colapsar" para poucas posi√ß√µes
3. **Teacher forcing na training:** Modelo treinado com teacher forcing pode n√£o ter aprendido self-recovery
4. **EOS score baixo:** A probabilidade do token EOS pode ficar suprimida quando o LSTM est√° em loop

### **Investiga√ß√µes Futuras**
- [ ] Visualizar attention weights de "pol√≠tico-administrativas" (heatmap)
- [ ] Testar com beam search (k=3,5) para ver se paths alternativos evitam o loop
- [ ] Avaliar impacto de scheduled sampling (gradual teacher forcing ‚Üí free-running)
- [ ] Testar max_length din√¢mico (1.5√ó input length como limite)
- [ ] Coletar mais exemplos de palavras compostas longas para avaliar padr√£o

### **Contexto**
- Taxa de alucina√ß√£o: ~0.004% (1 em ~27.374 palavras) ‚Äî muito baixa
- Modelos LSTM seq2seq s√£o suscet√≠veis a loops em sequ√™ncias longas (literatura)
- Transformers e suas variantes tendem a ser mais robustos neste cen√°rio
- Documentado para poss√≠vel explora√ß√£o em trabalho futuro (encoder bidirectional + aten√ß√£o)

---

## ÔøΩüìä AN√ÅLISE CR√çTICA DAS M√âTRICAS FON√âTICAS

### **Limita√ß√µes da Classifica√ß√£o A/B/C/D**
- [x] **Documentado (2026-02-18)** - An√°lise de casos problem√°ticos

**Contexto:** M√©tricas fon√©ticas (PanPhon) medem proximidade articulat√≥ria, n√£o preserva√ß√£o sem√¢ntica.

**Casos Analisados:**

1. **"z ‚Üî s" √© Classe B (1 feature)**
   - **Fon√©tica:** Diferem apenas em vozeamento (z=[+voiced], s=[-voiced])
   - **Lingu√≠stica:** Confus√£o comum em PT-BR (casa [Ààkaza] vs ca√ßa [Ààkasa])
   - **Perceptual:** Para TTS, erro impercept√≠vel em muitos contextos
   - **Conclus√£o:** Classifica√ß√£o adequada (erro leve)

2. **"pato ‚Üí peto" (a ‚Üî e, 2 features)**
   - **Fon√©tica:** a=[+low, -high], e=[-low, +high] ‚Üí Classe B/C
   - **Problema:** Fonemas pr√≥ximos, mas **sem√¢ntica totalmente diferente**
   - **Para TTS:** Gera palavra intelig√≠vel mas incorreta
   - **Para transcri√ß√£o:** Erro inaceit√°vel (muda significado)
   - **Limita√ß√£o:** M√©trica n√£o considera contexto lexical

3. **"p√£o ‚Üí pau" (√£ ‚Üî u, ~4 features)**
   - **Fon√©tica:** √£=[+nasal, +low, -back], u=[-nasal, +high, +back] ‚Üí Classe C/D
   - **Lingu√≠stica:** Erro cl√°ssico de estrangeiros (nasalidade dif√≠cil)
   - **Gravidade:** Alta (muda significado completamente)
   - **Conclus√£o:** Classifica√ß√£o adequada (erro grave)

**Implica√ß√µes:**
- ‚úÖ **Para TTS:** Classe B = erros impercept√≠veis; Classe D = inteligibilidade comprometida
- ‚ö†Ô∏è **Para transcri√ß√£o:** Mesmo Classe B pode causar confus√£o lexical
- ‚ö†Ô∏è **N√£o considera:** Posi√ß√£o na palavra (t√¥nica vs √°tona), frequ√™ncia lexical, ambiguidade

**Poss√≠veis Melhorias Futuras:**
- [ ] Pondera√ß√£o por posi√ß√£o: erro em t√¥nica = peso maior
- [ ] Dist√¢ncia + edit distance: combinar fon√©tica + sequencial
- [ ] M√©trica sem√¢ntica: embeddings de palavras (mas foge do escopo G2P)
- [ ] An√°lise por categoria: vogais vs consoantes, oclusivas vs fricativas

**Decis√£o:** Manter m√©tricas fon√©ticas como baseline t√©cnico. Classifica√ß√£o A/B/C/D √© adequada para an√°lise articulat√≥ria, mas n√£o substitui avalia√ß√£o com corpus de fala real (futuro).

---

## üöÄ COMANDOS R√ÅPIDOS (Rastreabilidade)

### **Gest√£o de Experimentos**
```bash
# Listar todos os experimentos com status
python src/manage_experiments.py --list

# Estat√≠sticas gerais (storage, distribui√ß√£o)
python src/manage_experiments.py --stats

# Detalhes de experimento espec√≠fico
python src/manage_experiments.py --show N

# Remover experimento √≥rf√£o/incompleto
python src/manage_experiments.py --prune N

# Limpar todos incompletos (preserva rodando)
python src/manage_experiments.py --prune-incomplete

# Simula√ß√£o sem deletar
python src/manage_experiments.py --prune-incomplete --dry-run

# Orquestra√ß√£o incremental do pipeline (inference/analyze/plots/report)
python src/manage_experiments.py --process-all --dry-run
python src/manage_experiments.py --process-all

# Force fraco (reexecuta leves, mant√©m inference incremental)
python src/manage_experiments.py --process-all --force --dry-run

# Force forte (inclui inference)
python src/manage_experiments.py --process-all --force --force-inference --dry-run
```

### **Treinamento**
```bash
# Exp1 (rodando)
python src/train.py --config config_exp1_baseline_60split.json

# Pr√≥ximos na fila
python src/train.py --config config_exp2_extended_512hidden.json
python src/train.py --config config_exp5_intermediate_60split.json
python src/train.py --config config_exp3_panphon_trainable.json
python src/train.py --config config_exp4_panphon_fixed_24d.json
```

### **Avalia√ß√£o**
```bash
# Listar modelos dispon√≠veis
python src/inference.py --list

# Avaliar modelo espec√≠fico
python src/inference.py --index N

# An√°lise de erros (auto-executado pelo report)
python src/analyze_errors.py --model exp1_baseline_60split__20260218_164935

# Gerar relat√≥rio HTML completo
python src/reporting/report_generator.py

# Gerar apresenta√ß√£o PowerPoint (PLANEJADO - ap√≥s implementa√ß√£o)
python src/reporting/presentation_generator.py                    # Completa
python src/reporting/presentation_generator.py --exp 7            # Apenas Exp7
python src/reporting/presentation_generator.py --output custom.pptx
```

### **Dataset Stats**
```bash
# Recomputar estat√≠sticas (se dataset mudar)
python src/compute_dataset_stats.py

# Ver cache atual
cat data/dataset_stats.json | jq .overall.representativeness
```

### **Verifica√ß√£o de Integridade**
```bash
# Ver todos os artefatos de um experimento
ls -lh models/exp1_baseline_60split__20260218_164935*
ls -lh results/exp1_baseline_60split__20260218_164935*
ls -lh results/*exp1_baseline_60split__20260218_164935*

# Verificar progresso de treino em tempo real
tail -f logs/train_*.log  # Se existir
python src/manage_experiments.py --show 1  # Metadata atualiza a cada checkpoint
```

---

## üìã RASTREABILIDADE ‚Äî Arquivos de Projeto

### **Configura√ß√µes**
- `config_exp0_baseline_70split.json` ‚Äî Baseline 70/10/20, 4.3M params
- `config_exp1_baseline_60split.json` ‚Äî Baseline 60/10/30, 4.3M params
- `config_exp2_extended_512hidden.json` ‚Äî Extended 60/10/30, 17.2M params
- `config_exp5_intermediate_60split.json` ‚Äî Intermediate 60/10/30, 9.7M params (**NOVO**)
- `config_exp3_panphon_trainable.json` ‚Äî PanPhon trainable
- `config_exp4_panphon_fixed_24d.json` ‚Äî PanPhon fixed

### **Modelos Treinados** (em `models/`)
- ‚úÖ `exp0_baseline_70split__20260218_044620.pt` (16.9 MB) + metadata
- üîÑ `exp1_baseline_60split__20260218_164935.pt` (16.9 MB) + metadata (rodando)
- ‚è∏ exp2, exp3, exp4, exp5 (pendentes)

### **Resultados** (em `results/`)
- ‚úÖ `exp0_baseline_70split__20260218_044620_history.csv` (converg√™ncia)
- ‚úÖ `evaluation_exp0_baseline_70split__20260218_044620.txt` (PER/WER)
- ‚úÖ `error_analysis_exp0_baseline_70split__20260218_044620.txt` (m√©tricas graduadas)
- ‚úÖ `predictions_exp0_baseline_70split__20260218_044620.tsv` (predi√ß√µes completas)
- ‚úÖ `exp0_baseline_70split__20260218_044620_convergence.png` (gr√°fico)
- ‚úÖ `exp0_baseline_70split__20260218_044620_analysis.png` (gr√°fico)
- üîÑ exp1 em progresso (s√≥ history.csv at√© agora)

### **Documenta√ß√£o**
- `TODO.md` ‚Äî Este arquivo (status global)
- `docs/performance.json` ‚Äî Benchmarks SOTA integrados
- `data/dataset_stats.json` ‚Äî Cache de estat√≠sticas

### **Ferramentas**
- `src/manage_experiments.py` ‚Äî Gerenciador de experimentos
- `src/compute_dataset_stats.py` ‚Äî Estat√≠sticas + cache
- `src/reporting/report_generator.py` ‚Äî HTML reports
- `src/analyze_errors.py` ‚Äî An√°lise de erros PanPhon
- `src/inference.py` ‚Äî Avalia√ß√£o de modelos
- `src/train.py` ‚Äî Treinamento
- üü° `src/reporting/presentation_generator.py` ‚Äî **Planejado**: Apresenta√ß√µes PowerPoint (.pptx) cient√≠ficas

---

## Prioridades (curto prazo)

- [x] **PAD vs EOS**: ‚úÖ Diagn√≥stico completo ‚Äî implementa√ß√£o correta ([docs/PAD_EOS_ANALYSIS.md](docs/PAD_EOS_ANALYSIS.md))
- [x] **PanPhon embedding real**: ‚úÖ Implementado (`phoneme_embeddings.py`, `g2p.py`, `train.py`, `inference.py`)
- [x] **M√©tricas graduadas**: ‚úÖ Completo para Exp2 e Exp3 (2026-02-17) ‚Äî [docs/EXPERIMENTS_RESULTS.md](docs/EXPERIMENTS_RESULTS.md)
- [x] **Relat√≥rios HTML**: ‚úÖ Sistema completo
  - Tabelas de treino/teste (dados pr√©-renderizados)
  - M√©tricas cl√°ssicas + graduadas (PanPhon)
  - Benchmark com SOTA: LatPhon, DeepPhonemizer, ByT5, Phonetisaurus
  - Parser robusto de evaluation files (regex)
- [x] **Literatura SOTA integrada**: ‚úÖ performance.json + model_report.html
  - Compara√ß√£o com LatPhon (PT-BR SOTA 2025)
  - Compara√ß√£o com DeepPhonemizer (IT/EN)
  - An√°lise de robustez (57√ó larger test set que LatPhon)
- [x] **Padroniza√ß√£o CLI**: ‚úÖ inference.py, analyze_errors.py, report_generator.py (2026-02-18)
  - `--list`, `--index`, `--model` consistentes
  - Orientados a config/metadata (conservative approach)

---

## üöÄ ROADMAP Exp6+ ‚Äî Implementa√ß√£o Iniciada! (2026-02-20)

### **Status NOVO**: ‚úÖ INTEGRADO E VALIDADO (smoke tests passaram)

**Documenta√ß√£o Completa de Exp6**:
1. ‚úÖ **RFC Document**: [docs/RFC_EXP6_PHONETIC_DISTANCE.md](docs/RFC_EXP6_PHONETIC_DISTANCE.md)
   - An√°lise cr√≠tica de 3 propostas (Linear 1D, Distance-Aware Loss, Refactoring)
   - Recomenda√ß√£o: Distance-Aware Loss (Exp6) √© vi√°vel e teoricamente s√≥lido

2. ‚úÖ **Funda√ß√µes Te√≥ricas Completas**: [docs/THEORETICAL_FOUNDATIONS.md](docs/THEORETICAL_FOUNDATIONS.md)
   - Se√ß√µes 1-9: Fundamenta√ß√£o de G2P, LSTM, Aten√ß√£o, Embeddings, M√©tricas, Design Exp, Exp6, Contribui√ß√µes, Refer√™ncias
   - 50+ refer√™ncias acad√™micas com URLs
   - Pronto para integrar direto no paper/tese

3. ‚úÖ **Implementa√ß√£o Exp6 (C√≥digo)**:
   - `src/losses.py`: SequenceCrossEntropyLoss (wrapper) + PhonicDistanceAwareLoss + SoftTargetCrossEntropyLoss + factory
   - `config_exp6_distance_aware_loss.json`: Config completa com hiperpar√¢metros
   - `docs/INTEGRATION_EXP6.md`: Guia de integra√ß√£o (atualizado 2026-02-20)

4. ‚úÖ **Integra√ß√£o em train.py** (2026-02-20):
   - Interface unificada: todas as losses aceitam `(batch, seq, vocab)` ‚Äî sem `isinstance` no training loop
   - Factory `get_loss_function()` retorna `SequenceCrossEntropyLoss` para CE (wrapper fino)
   - 100% backward compatible: Exp0-5 funcionam identicamente (validado por smoke test)
   - Smoke tests: Exp1 (CE, 1 epoch ‚úì) + Exp6 (distance_aware, 1 epoch ‚úì)

**PR√ìXIMO PASSO**: Treinar Exp6 completo (~24h GPU).

---

### **An√°lise das 3 Propostas**

#### **1. Linear 1D Projection** ‚ùå SKIP
- Risco Alto: Perda severa de informa√ß√£o (24D ‚Üí 1D)
- Sem evid√™ncia cient√≠fica de benef√≠cio
- RFC Se√ß√£o 1 explica detalhadamente

#### **2. Phonetic Distance-Aware Loss** ‚úÖ IMPLEMENT (Exp6 - INTEGRADO!)
- Status: **INTEGRADO E VALIDADO** (refatorado com interface unificada)
- Teoria s√≥lida: Structured prediction + metric learning
- train.py limpo: `loss = criterion(logits, phonemes)` ‚Äî uma linha, sem branching

**SUB-TAREFAS**:
- [x] **EXP6-1: Implementar Loss Function** ‚úÖ COMPLETO
  - Arquivo: `src/losses.py` com 3 classes + factory
  - SequenceCrossEntropyLoss: wrapper para interface unificada (B,T,V)
  - PhonicDistanceAwareLoss + SoftTargetCrossEntropyLoss

- [x] **EXP6-3: Config File** ‚úÖ COMPLETO
  - `config_exp6_distance_aware_loss.json` com todos os hiperpar√¢metros

- [x] **EXP6 Documentation** ‚úÖ COMPLETO + ATUALIZADO
  - RFC_EXP6_PHONETIC_DISTANCE.md (an√°lise completa)
  - INTEGRATION_EXP6.md (atualizado com refatora√ß√£o + resultados smoke tests)
  - THEORETICAL_FOUNDATIONS.md (contexto te√≥rico)

- [x] **EXP6-2: Integrar em train.py** ‚úÖ COMPLETO (2026-02-20)
  - Interface unificada via SequenceCrossEntropyLoss + factory
  - Sem isinstance/if-else no training loop
  - Metadata inclui loss_type e loss_config
  - Smoke tests passaram (Exp1 backward compat + Exp6)

- [ ] **EXP6-4: Executar Training** ‚è≥ PRONTO PARA RODAR
  - Comando: `python src/train.py --config config_exp6_distance_aware_loss.json`
  - Estimado: 18-24h GPU
  - N√£o √© necess√°rio re-treinar Exp0-5

- [ ] **EXP6-5: An√°lise Comparativa** ‚è≥ AP√ìS EXP6-4
  - Inference + analyze_errors + HTML report
  - Comparar vs Exp1: PER/WER/convergence
  - Documentar achados em EXPERIMENTS_RESULTS.md
  - Tempo: 2-3 horas

#### **3. g2p.py Refactoring** üü° DEFER
- Vi√°vel mas **baixa prioridade n√£o-cr√≠tica**
- Timeline: Ap√≥s Exp6-7 se mostrarem valor
- RFC Se√ß√£o 3 detalha proposta

---

### **Cronograma Exp6**

```
AGORA (2026-02-20, Exp5 rodando):
  ‚úÖ RFC document finalizado
  ‚úÖ THEORETICAL_FOUNDATIONS.md completo (9 se√ß√µes!)
  ‚úÖ src/losses.py implementado (2 loss classes + factory)
  ‚úÖ config_exp6_distance_aware_loss.json pronto
  ‚úÖ INTEGRATION_EXP6.md com guia passo-a-passo

TER√áA (2026-02-21, se Exp5 terminar segunda noite):
  ‚è≥ Aplicar 5 mudan√ßas em train.py (~5 minutos)
  ‚è≥ Valida√ß√£o: teste smoke de 1 √©poca
  ‚è≥ Iniciar Exp6 training (~24h GPU)

QUARTA (2026-02-22):
  ‚è≥ Exp6 training completa (se ~6pm ter√ßa + 18h)
  ‚è≥ Executar inference + analyze_errors
  ‚è≥ Gerar HTML report com compara√ß√£o Exp1 vs Exp6

QUINTA (2026-02-23):
  ‚è≥ An√°lise e documenta√ß√£o de resultados
  ‚è≥ Decis√£o: Exp7 (Triplet Loss)? Ou focar em paper?
  ‚è≥ Redactar se√ß√µes te√≥ricas para tese/paper
```

---

### **Documenta√ß√£o de Teoria COMPLETADA**

**Para o seu artigo, tudo que voc√™ pediu est√° em**: [docs/THEORETICAL_FOUNDATIONS.md](docs/THEORETICAL_FOUNDATIONS.md)

Estrutura:
1. **G2P: Fundamenta√ß√£o** - Problema cient√≠fico, solu√ß√µes cl√°ssicas vs deep learning
2. **Arquitetura Neural** - BiLSTM, LSTM equations, compara√ß√£o com GRU
3. **Mecanismo de Aten√ß√£o** - Bahdanau, scaled dot-product, impl√≠ca√ß√µes
4. **Embeddings Fon√©ticos** - Learned vs PanPhon, 24D features articulat√≥rias
5. **M√©tricas de Avalia√ß√£o** - Cl√°ssicas (PER/WER) + nossas graduadas (A/B/C/D)
6. **Design do Experimento** - Dataset PT-BR, split 60/10/30, hyperparameters, validation
7. **Exp6: Loss Distance-Aware** - Teoria completa, equa√ß√µes, implementa√ß√£o t√©cnica
8. **Contribui√ß√µes Pr√≥prias** - 4 descobertas experimentais originais + m√©trica inovadora
9. **Refer√™ncias** - 27 papers com URLs, categorizados por t√≥pico

**Todos os 9 t√≥picos t√™m refer√™ncias acad√™micas espec√≠ficas**, deixando claro onde sua teor vem e qual √© sua contribui√ß√£o original.

---

### **Caminho Feliz Atualizado** üü¢

```
Exp5 RODANDO (√©poca 13)
  ‚îú‚îÄ (FEITO) Criar RFC + Theoretical Foundations + implementa√ß√£o Exp6
  ‚îî‚îÄ ETA: ~8h mais, esperado completar segunda noite (21:00 ter√ßa)

Assim que Exp5 COMPLETAR:
  ‚îú‚îÄ Aplicar 5 mudan√ßas em train.py (5 min)
  ‚îú‚îÄ Teste smoke de valida√ß√£o (5 min)
  ‚îú‚îÄ Iniciar Exp6 (18-24h GPU paralelo com trabalho)
  ‚îî‚îÄ Continuar escrevendo artigo enquanto GPU treina

Exp6 COMPLETAR (quarta 2026-02-22):
  ‚îú‚îÄ An√°lise autom√°tica (analyze_errors, report HTML)
  ‚îú‚îÄ Compara√ß√£o Exp1 vs Exp6 (speedup converg√™ncia? PER melhor?)
  ‚îî‚îÄ Decis√£o: Exp7? Paper? ou ambos?

Paper/Tese ESCRITA:
  ‚îú‚îÄ Se√ß√µes 1-7: Copy-paste do THEORETICAL_FOUNDATIONS.md
  ‚îú‚îÄ Se√ß√£o 8: Resultados Exp0-6 com tabelas/gr√°ficos
  ‚îú‚îÄ Se√ß√£o 9: Refer√™ncias BibTeX autom√°tico
  ‚îî‚îÄ Ap√™ndice: Detalhes implementa√ß√£o (src/losses.py, train.py mods)
```

**Status Global Exp6**: ‚úÖ **C√ìDIGO COMPLETO, DOCUMENTA√á√ÉO TEOR√âTICA COMPLETA, PRONTO PARA EXECUTAR**

---

---

## üìö √çNDICE DOCUMENTA√á√ÉO - Centralizado

**Estrutura de documenta√ß√£o** (source of truth):

| Arquivo | Conte√∫do |
|---------|---------|
| [README.md](README.md) | Quick start, resultados principais, capacidades |
| [STATUS.md](STATUS.md) | SOTA atual, milestones, timeline |
| [TODO.md](TODO.md) | Roadmap, tasks pendentes, backlog |
| [docs/04_EXPERIMENTS.md](docs/04_EXPERIMENTS.md) | Resultados Exp0-10, Phase 5 (decomposed) |
| [docs/05_THEORY.md](docs/05_THEORY.md) | Embedding types, loss functions, funda√ß√µes |
| [docs/02_ARCHITECTURE.md](docs/02_ARCHITECTURE.md) | BiLSTM, Attention, otimiza√ß√µes t√©cnicas |
| [src/](src/) | C√≥digo Python produ√ß√£o |
| [models/](models/) | Checkpoints treinados + metadados |

**Regra**: N√£o criar novos `.md` na raiz. Integrar em README/STATUS/TODO ou docs/.

---

## Backlog (m√©dio prazo)

- [ ] **TRAIN-CSV: Expandir history CSV com m√©tricas de performance** üîß
  - **Problema**: CSV atual s√≥ grava `epoch,train_loss,val_loss` (3 colunas)
  - **Dados perdidos**: `epoch_time_s`, `train_time_s`, `eval_time_s`, `samples_per_sec`, `wall_clock`, `is_best`
  - **Esses dados J√Å s√£o calculados** no loop (linhas 248-263 de train.py) mas s√≥ v√£o pro logger
  - **Header proposto**: `epoch,train_loss,val_loss,epoch_time_s,train_time_s,eval_time_s,samples_per_sec,wall_clock,is_best`
  - **Valor**:
    - Throughput m√©dio e vari√¢ncia (detectar throttling t√©rmico da GPU)
    - ETA preciso via wall_clock timestamps
    - Best model tracking (qual epoch salvou)
    - An√°lise p√≥s-treino sem depender de logs do terminal
  - **Impacto**: Altera√ß√£o de ~3 linhas no `csv_writer.writerow()` em train.py (linha 252)
  - **Prioridade**: Baixa urg√™ncia (n√£o bloqueia nada), mas alto valor para an√°lise
  - **NOTA**: N√ÉO alterar train.py enquanto treino estiver rodando. Aplicar antes do Exp1.

- [ ] **PLANO COMPLETO: Consolida√ß√£o Minimalista de An√°lise** üìã
  - **Documento**: Ver [PLANO_ANALISE_CONSOLIDADA.md](PLANO_ANALISE_CONSOLIDADA.md) para detalhes completos
  - **Objetivo**: 1 √∫nico script de an√°lise + CSV minimalista + outputs estruturados
  
  **Fase 1: Upgrade CSV** (‚ö° R√ÅPIDO, antes do Exp1)
  - [ ] **CSV M√≠nimo Expandido** ‚Äî train.py linha 225 + 252
    - Adicionar 2 colunas: `epoch_start_ts`, `epoch_end_ts` (timestamps Unix)
    - Remover: NADA que seja redundante (dura√ß√µes, throughput calcul√°veis)
    - Novo header: `epoch,train_loss,val_loss,epoch_start_ts,epoch_end_ts`
    - Mudan√ßa: ~5 linhas (2x `time.time()` call + 2 colunas no writerow)
    - Risco: Baixo (compat√≠vel forward, Exp0 continua rodando)
    - Tempo: 5-10 min
    - Estado: **PRONTO PARA IMPLEMENTAR**
  
  **Fase 2: Novo Script Unificado** (3-4h ap√≥s Exp0 terminar)
  - [ ] **Criar `src/analysis.py`** (unifica 3 scripts antigos)
    - Baseado em: melhores partes de `analyze.py` + `analyze_training.py`
    - Modos:
      - `--monitor`: Status treino em andamento (via metadata)
      - `--default`: Gr√°ficos converg√™ncia (train/val loss)
      - `--test`: PER/WER/confus√µes (evaluation_*.txt)
      - `--compare`: M√∫ltiplos runs lado a lado
      - `--stats`: Apenas JSON estruturado (sem PNG)
    - Outputs:
      - `{exp}_convergence.png`: Curva loss + best epoch
      - `{exp}_analysis.png`: Gap + throughput
      - `{exp}_results.json`: M√©tricas estruturadas (**NEW**)
    - Funcionalidades de c√°lculo:
      - `duration = end_ts - start_ts` (por epoch)
      - `samples_per_sec = train_size / train_duration`
      - `convergence_epoch = quando atingiu 95% melhoria`
      - `overfitting = gap analysis (val - train)`
      - `plateau = std √∫ltimas 5 √©pocas`
    - Tempo estimado: 3-4h
  
  - [ ] **Testar em Exp0**
    - `python src/analysis.py` ‚Üí PNG gr√°ficos
    - `python src/analysis.py --test` ‚Üí PER/WER
    - `python src/analysis.py --stats --json` ‚Üí JSON results
    - Verificar: outputs corretos, sem erros
    - Tempo: 30-45 min
  
  **Fase 3: Limpeza** (30 min ap√≥s testes)
  - [ ] **Deletar scripts antigos** (redundantes/quebrados)
    - `rm src/analyze.py` (366 lin, 75% duplicado com analyze_training.py)
    - `rm src/analyze_training.py` (320 lin, id√™ntico com analyze.py)
    - `rm src/compare_results.py` (106 lin, **QUEBRADO**, assume test_loss falsamente)
    - Manter: `analyze_errors.py` (separado, an√°lise de erros), `report_generator.py` (HTML)
  
  - [ ] **Atualizar docs/README.md**
    - Se√ß√£o "An√°lise de Treino" com novos comandos
    - Remover men√ß√£o a scripts antigos
  
  **Fase 4: Valida√ß√£o** (ap√≥s Exp3/Exp4)
  - [ ] **Usar `--compare` para benchmarking**
    - Comparar Exp0 vs Exp1 vs Exp2 vs Exp3 vs Exp4
    - Gerar JSON centralizado com todos os resultados
  
  **Ganhos:**
  ‚úÖ Menos c√≥digo: -792 linhas (3 scripts)
  ‚úÖ Sem redund√¢ncia + sem bugs
  ‚úÖ CSV minimalista (apenas timestamps raw)
  ‚úÖ Outputs estruturados (PNG + JSON)
  ‚úÖ Escal√°vel para novos modos

## üé® PHASE 3 ‚Äî Reestrutura√ß√£o Documentacional ‚úÖ EXECUTADO

**Status**: ‚úÖ COMPLETO (2026-02-20 15:00 UTC)  
**Objetivo**: Transformar docs/ de 21 arquivos dispersos ‚Üí 6 cap√≠tulos estruturados como artigo cient√≠fico

**Resultado Final**:
- üî¥ 26 itens docs/ ‚Üí üü¢ 6 cap√≠tulos estruturados (73% redu√ß√£o)
- üî¥ ~2000+ linhas espalhadas ‚Üí üü¢ ~2000 linhas organizadas (zero duplica√ß√£o)
- üî¥ Leitura n√£o-linear ‚Üí üü¢ Leitura linear natural (artigo cient√≠fico)
- ‚úÖ Conhecimento integral preservado

### ‚úÖ Fase 3.1 ‚Äî Cap√≠tulos Criados (COMPLETO)
- [x] Criar `docs/01_OVERVIEW.md` (intro + roadmap de leitura)
- [x] Expandir `docs/02_ARCHITECTURE.md` (+ absorver PAD_EOS_ANALYSIS)
- [x] Criar `docs/03_METRICS.md` (consolidar METRICS_GLOSSARY + GRADUATED_METRICS)
- [x] Criar `docs/04_EXPERIMENTS.md` (Exp0-9: design, resultados, an√°lise)
- [x] Criar `docs/05_THEORY.md` (funda√ß√µes G2P, loss functions, features)
- [x] Criar `docs/06_REFERENCES.md` (LITERATURA + REFERENCIAS.bib convertido)

### ‚úÖ Fase 3.2 ‚Äî Consolida√ß√£o de Conte√∫do (COMPLETO)
- [x] Revisar 02_ARCHITECTURE contra original PAD_EOS (zero duplica√ß√£o verificada)
- [x] Revisar 03_METRICS contra METRICS_GLOSSARY + GRADUATED_METRICS (consolidado)
- [x] Revisar 04_EXPERIMENTS contra EXPERIMENTS_RESULTS + RFC_EXP6 + INTEGRATION (tudo absorvido)
- [x] Revisar 05_THEORY contra THEORETICAL_FOUNDATIONS + LITERATURE (essencial integrado)
- [x] Revisar 06_REFERENCES e padronizar REFERENCIAS.bib (duplicatas consolidadas)
- [x] Adicionar links cruzados (01 ‚Üí 02 ‚Üí 03 ‚Üí 04 ‚Üí 05 ‚Üí 06)
- [x] Adicionar √≠ndice ao 01_OVERVIEW.md

### ‚úÖ Fase 3.3 ‚Äî Limpeza de Obsoletos (COMPLETO)

**Deletados 13 arquivos** (conte√∫do absorvido):
- [x] `docs/ARCHITECTURE.md` ‚Üí expans√£o em 02_ARCHITECTURE
- [x] `docs/PAD_EOS_ANALYSIS.md` ‚Üí se√ß√£o 02_ARCHITECTURE "Tratamento Sequ√™ncias"
- [x] `docs/METRICS_GLOSSARY.md` ‚Üí consolidado em 03_METRICS.md
- [x] `docs/GRADUATED_METRICS_ANALYSIS.md` ‚Üí 03_METRICS + 04_EXPERIMENTS
- [x] `docs/EXPERIMENTS_RESULTS.md` ‚Üí 04_EXPERIMENTS.md (Se√ß√µes 2 + 5)
- [x] `docs/RFC_EXP6_PHONETIC_DISTANCE.md` ‚Üí 04_EXPERIMENTS.md (Se√ß√£o 3.1)
- [x] `docs/INTEGRATION_EXP6.md` ‚Üí 04_EXPERIMENTS.md (Se√ß√£o 3.2-3.3)
- [x] `docs/IMPLEMENTATION_SUMMARY_2026_02_20.md` ‚Üí 04_EXPERIMENTS.md
- [x] `docs/EVALUATION_GUIDE.md` ‚Üí 03_METRICS.md (m√©todo avalia√ß√£o)
- [x] `docs/THEORETICAL_FOUNDATIONS.md` ‚Üí 05_THEORY.md (obsoleto)
- [x] `docs/LITERATURE.md` ‚Üí 06_REFERENCES.md (consolidado)
- [x] `docs/RESULTS.md` ‚Üí ALREADY DELETED (Phase 2)
- [x] `docs/STATUS.md` ‚Üí ALREADY DELETED (Phase 2)

**Documentos deletados (Fase 4 cleanup)**:
- ‚ùå `docs/AUDITORIA_CODIGO_DOCS.md` ‚Äî deletado (auditoria completa)
- ‚ùå `docs/DATASET_CACHE.md` ‚Äî deletado (consolidado em 02_ARCHITECTURE.md)
- ‚ùå `docs/REPORTING.md` ‚Äî deletado (consolidado em 02_ARCHITECTURE.md + 03_METRICS.md)

### ‚úÖ Fase 3.4 ‚Äî Atualiza√ß√£o de Refer√™ncias (COMPLETO)
- [x] README.md: atualizar links (‚Üí novos 6 cap√≠tulos)
- [x] README.md: indicar leitura recomendada (01‚Üí02‚Üí03‚Üí04‚Üí05‚Üí06)
- [x] TODO.md: atualizar refs a docs/ obsoletos
- [x] performance.json: confirmado em ROOT (h√≠brido doc+config)
- [x] REFERENCIAS.bib: padronizado (consolidado CMUdict duplicate)

### ‚úÖ Fase 3.5 ‚Äî Valida√ß√£o (COMPLETO)
- [x] Verificar todos links internos (docs/ ‚Üí cap√≠tulos)
- [x] Verificar leitura linear: 01 ‚Üí 02 ‚Üí 03 ‚Üí 04 ‚Üí 05 ‚Üí 06 ‚úì
- [x] Validar Markdown syntax (tabelas, c√≥digo, links)
- [x] Confirmar zero duplica√ß√£o: grep em docs/ por termos-chave
- [x] Final listing: 6 cap√≠tulos + 3 opcionais

**Estat√≠sticas**:
```
ANTES (Fase 3 in√≠cio):    21 arquivos Markdown
DEPOIS (Fase 3 fim):       6 cap√≠tulos + 3 opcionais = 9 arquivos
Redu√ß√£o:                  -57% (21 ‚Üí 9 files)
Linhas de conhecimento:   ~2000 ‚Üí 2000 (zero perda, apenas reorganizada)
Duplica√ß√£o:               Eliminada completamente
```

### ‚úÖ Conclus√£o Phase 3
- ‚úÖ COMPLETO 2026-02-20 15:00 UTC
- ‚úÖ Estrutura de artigo cient√≠fico implementada
- ‚úÖ Todos os links funcionais validados
- ‚úÖ Pronto para Exp7-9 e publica√ß√£o

---

## Referencias rapidas

- Status atual: [TODO.md](TODO.md)
- Resultados completos: [docs/EXPERIMENTS_RESULTS.md](docs/EXPERIMENTS_RESULTS.md)
- Benchmarks manuais: [docs/performance.json](docs/performance.json)
