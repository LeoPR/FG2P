# STATUS ‚Äî FG2P Project Overview

**Data**: 2026-02-28
**Status**: Phase 6C COMPLETA ‚úÖ | Docs reorganizados | Phase 7 iniciada (Exp107 planejado)
**SOTA WER**: **Exp9** (PER 0.58%, WER **4.96%**, Acc 95.04%, 9.7M params)
**SOTA PER**: **Exp104b** (PER **0.49%**, WER 5.43%, Acc 94.57%, 9.7M params)
**Finding Phase 6B**: Override de dist√¢ncias AP√ìS normaliza√ß√£o ‚Üí PER 0.49% NOVO SOTA (Exp104b)
**Finding Phase 6C**: 50% dados ‚Üí +0.05% PER (robusto); sem h√≠fen ‚Üí +0.04% PER, 2.58√ó speed
**Pr√≥ximo**: Exp107 (95% treino) ‚Äî compara√ß√£o com LatPhon 2025 (PER 0.89%, N=500)

---

## üéØ Miss√£o

Desenvolver modelo G2P (Grapheme-to-Phoneme) SOTA para Portugu√™s Brasileiro usando arquitetura BiLSTM Encoder-Decoder + Attention, com foco em:
1. Minimizar PER (Phoneme Error Rate)
2. M√©tricas linguisticamente graduadas (PanPhon features)
3. Reproducibilidade cient√≠fica total
4. ROI computacional (performance vs params)

---

## üèÜ Achievements

### **SOTA Alcan√ßado** ‚úÖ
- **PER: 0.49%** (Exp104b) ‚Äî SOTA PER final | Supera LatPhon 2025 (0.89%) em -45%
- **WER: 4.96%** (Exp9) ‚Äî SOTA WER | Test set 28.782 palavras (57√ó maior que LatPhon)
- **Speed: 30.2 w/s** (Exp106) ‚Äî 2.58√ó mais r√°pido sem perda fonol√≥gica significativa
- **Robusto**: 50% dados ‚Üí PER 0.54% (+0.05%) ‚Äî modelo n√£o memoriza, generaliza
- **Generaliza√ß√£o OOV PT-BR**: 5/5 palavras reais fora do vocabul√°rio corretas (100%)

### **Descobertas Cient√≠ficas** üî¨

#### 1. Split Ratio Impact (Phase 1)
- **60/10/30 > 70/10/20**: -41% PER improvement
- **Conclus√£o**: Mais dados de teste ‚Üí valida√ß√£o estat√≠stica superior

#### 2. Capacity Ceiling (Phase 1-2)
```
4.3M params:  0.66% PER [baseline]
9.7M params:  0.58% PER [SWEET SPOT ‚úì]
17.2M params: 0.60% PER [diminishing returns]
```
- **Satura√ß√£o em ~0.58% PER** com arquitetura LSTM atual

#### 3. Distance-Aware Loss (Phase 3-4)
- ‚úÖ **Funciona em baseline/intermediate** (4.3M-9.7M params)
- ‚ùå **Falha em high-capacity** (17.2M params)
- **Œª optimal = 0.2** (lambda sweep Exp7: 0.05 < 0.20 < 0.50)
- **Mecanismo**: Regulariza√ß√£o impl√≠cita ‚Üí contraprodutivo em modelos grandes

#### 4. PanPhon Features (Phase 2-3)
- **Neutral vs learned embeddings** em PT-BR (Exp3 ‚âà Exp1)
- **Fixed features prejudicam** (Exp4 pior que Exp3)
- **Conclus√£o**: PT-BR ortografia regular ‚Üí learned embeddings suficientes

#### 5. Error Pattern (consistente todos experimentos)
- **65-70% erros**: Confus√µes vogais m√©dias (…õ‚Üîe, …î‚Üîo)
- **Linguisticamente justificado**: Sem contexto sem√¢ntico, ambiguidade inerente
- **Implica√ß√£o**: 0.58% PER pode ser limite "natural" sem context awareness

---

## üìä Experimentos Completos (20 modelos)

| Exp | PER | WER | Acc | Params | Key Feature | Status |
|-----|-----|-----|-----|--------|-------------|--------|
| **Exp104b** | **0.49%** | 5.43% | 94.57% | 9.7M | DA Loss + sep + override p√≥s-norm | ‚úÖ **SOTA PER** |
| Exp105 | 0.54% | 5.87% | 94.13% | 9.7M | DA Loss + sep, 50% treino | ‚úÖ Abla√ß√£o dados |
| **Exp102** | 0.52% | 5.79% | 94.21% | 9.7M | Intermediate + sep + CE | ‚úÖ Sep baseline |
| Exp103 | 0.53% | 5.73% | 94.27% | 9.7M | Intermediate + sep + DA Œª=0.2 | ‚úÖ Phase 6A |
| **Exp9** | 0.58% | **4.96%** | **95.04%** | 9.7M | Intermediate + DA Œª=0.2 | ‚úÖ **SOTA WER** |
| Exp106 | 0.58% | 6.12% | 93.88% | 9.7M | DA Loss + sep, 50% treino, sem - | ‚úÖ **30.2 w/s ‚ö°** |
| Exp101 | 0.53% | 5.99% | 94.01% | 4.3M | Baseline + sep | ‚úÖ Sep. diagn√≥stico |
| Exp2 | 0.60% | 4.98% | 95.02% | 17.2M | Extended capacity | ‚úÖ High-cap baseline |
| Exp10 | 0.61% | 5.25% | 94.75% | 17.2M | Extended + DA Œª=0.2 | ‚úÖ Negative ROI |
| Exp6 | 0.63% | 5.35% | 94.65% | 4.3M | Baseline + DA Œª=0.1 | ‚úÖ Budget option |
| Exp5 | 0.63% | 5.38% | 94.62% | 9.7M | Intermediate | ‚úÖ Capacity test |
| Exp8 | 0.65% | 5.62% | 94.38% | 4.3M | PanPhon + DA Œª=0.2 | ‚úÖ Features test |
| Exp1 | 0.66% | 5.65% | 94.35% | 4.3M | Baseline 60/10/30 | ‚úÖ Reference |
| Exp3 | 0.66% | 5.45% | 94.55% | 4.3M | PanPhon trainable | ‚úÖ Linguistic features |
| Exp7 | 0.68-0.73% | varies | varies | 4.3M | Lambda sweep | ‚úÖ Hyperopt |
| Exp4 | 0.71% | 6.02% | 93.98% | 4.3M | PanPhon fixed | ‚úÖ Ablation |
| Exp11 | 0.97% | 7.53% | 92.47% | 4.3M | Baseline + decomposed NFD | ‚úÖ NFD incompat√≠vel |
| Exp0 | 1.12% | 9.37% | 90.63% | 4.3M | Baseline 70/10/20 | ‚úÖ Initial baseline |

**Progresso total**: -54% PER (Exp0 1.12% ‚Üí Exp102 0.52%) | SOTA WER: Exp9 (4.96%) | 17 modelos treinados

---

## üöÄ Phase 6A CONCLU√çDA ‚Äî Sep + DA Loss Combination

### Experimentos Planejados

#### **Exp11**: Baseline + Decomposed NFD
- **Config**: `config_exp11_baseline_decomposed.json`
- **Hip√≥tese**: NFD Unicode (√°‚Üía+¬¥) facilita aprendizado diacritics
- **Compara com**: Exp1 (0.66% PER)
- **Target**: 0.60-0.64% PER
- **Status**: Re-iniciado com `keep_syllable_separators=true`

#### **Exp101**: Baseline + Separadores (controle direto)
- **Config**: `config_exp101_baseline_60split_separators.json`
- **Hip√≥tese**: Separadores mudam PER/WER mesmo com encoding raw
- **Compara com**: Exp1 (baseline raw sem separadores)

#### **Exp12**: PanPhon + Decomposed
- **Config**: `config_exp12_panphon_decomposed.json`
- **Hip√≥tese**: Sinergia features lingu√≠sticas + diacritics expl√≠citos
- **Compara com**: Exp3 (0.66%) e Exp11
- **Target**: 0.58-0.62% PER
- **Critical**: Se ‚â• Exp9 ‚Üí 4.3M params rivalizam 9.7M = OPTIMAL ROI

#### **Exp13**: SOTA + Decomposed (FRONTIER PUSH)
- **Config**: `config_exp13_intermediate_distance_aware_decomposed.json`
- **Hip√≥tese**: NFD + SOTA architecture ‚Üí **NEW ABSOLUTE SOTA**
- **Compara com**: Exp9 (0.58% PER)
- **Target**: **< 0.55% PER** (breakthrough PT-BR G2P)

**Estrat√©gia**: Design fatorial 2√ó2 [raw/decomposed] √ó [learned/PanPhon]

---

## ‚úÖ Hotfixes Recentes

- **BUG 1 (cache collision)**: resolvido com nomes sens√≠veis a `encoding + separadores + split + seed`
- **BUG 2 (separadores de s√≠laba)**: flag opcional `keep_syllable_separators`
	- Default: `false` (compat√≠vel com Exp0-10)
	- Exp11+ ativado para testes com separadores
- **Observa√ß√£o**: revalidar impacto direto via Exp101 (baseline raw + separadores)
- **Relat√≥rio HTML**: ordena√ß√£o generalizada por √≠ndice de experimento (evita ordem lexicogr√°fica `exp1, exp11, exp2`) e sort robusto para colunas num√©ricas (PER/WER/Accuracy e m√©tricas graduadas)

### Impacto nos experimentos j√° feitos (avalia√ß√£o retroativa)
- **Exp0‚ÄìExp10**: **sem impacto em m√©tricas hist√≥ricas** (PER/WER/Acc mantidos).
- Motivo: todos foram treinados antes da flag de separadores e permanecem v√°lidos como baseline hist√≥rico.
- **Cache**: mudan√ßa afeta apenas arquivos de inspe√ß√£o em `data/` (evita sobrescrita), n√£o altera checkpoints j√° salvos em `models/`.
- **Comparabilidade**:
	- Exp11 run antigo (`20260222_161238`): decomposed sem separadores.
	- Exp11 run atual (`20260222_201314`): decomposed com separadores.
	- Esses dois runs devem ser tratados como condi√ß√µes experimentais diferentes.

---

## üìà M√©tricas vs Literatura

| Sistema | Idioma | Test Size | PER | Params | Notas |
|---------|--------|-----------|-----|--------|-------|
| **FG2P Exp104b** | PT-BR | **28.8k** | **0.49%** | 9.7M | ‚úÖ **SOTA PER** |
| **FG2P Exp9** | PT-BR | **28.8k** | 0.58% | 9.7M | ‚úÖ **SOTA WER 4.96%** |
| LatPhon 2025 | PT-BR | 500 | 0.89% | ~7M | N=500 ‚Äî menor comparabilidade |
| DeepPhonemizer | IT | ~77k | 0.40% | 229M | Romance: similar ao PT-BR |
| ByT5 Small | 100+ | varies | 8.90% | 299M | Multilingual zero-shot |

**Destaques**:
- ‚úÖ **Supera LatPhon SOTA em -45% PER** (0.49% vs 0.89%)
- ‚úÖ Test set **57√ó maior** que LatPhon (28.8k vs 500) ‚Äî mais robusto
- ‚úÖ Perto de DeepPhonemizer IT com **23√ó menos params**

---

## üöÄ Phase 7 ‚Äî Pr√≥ximos Experimentos

### Exp107 ‚Äî MaxData 95% treino [PENDENTE]
- **Config**: `conf/config_exp107_maxdata_95train.json`
- **Split**: train=95% (~91.140 palavras), val=4%, test=1% (~960 palavras)
- **Hip√≥tese**: Mais dados ‚Üí PER < 0.49% (SOTA atual)
- **Objetivo estrat√©gico**: Compara√ß√£o metodol√≥gica com LatPhon 2025 (test N=500)
- **Executar**: `python src/train.py --config conf/config_exp107_maxdata_95train.json`
- **Ap√≥s treino**: Atualizar tabela SOTA + slides + ARTICLE.md ¬ß5

---

## üìã Log de Decis√µes de Documenta√ß√£o (2026-02-28)

Registro das decis√µes tomadas para n√£o perder o racioc√≠nio ao retomar o projeto.

### Reorganiza√ß√£o docs/ (Fase 1)
- **Feito**: 12 arquivos movidos para subpastas `article/`, `presentation/`, `report/`, `data/`
- **Motivo**: 8 arquivos no mesmo n√≠vel era dif√≠cil de navegar
- **Resultado**: `docs/INDEX.md` como hub de entrada

### Slides ‚Äî Decis√µes Tomadas (2026-02-28)
| Elemento | Decis√£o | Raz√£o |
|----------|---------|-------|
| **Exp103 nos slides** | Removido de tabelas de ranking; aparece s√≥ como nota de rodap√© | N√£o vence em nenhuma m√©trica ‚Äî hist√≥rico apenas |
| **Slide "Dist√¢ncias"** | Exp103 ‚Üí "Sem override (baseline)" | Anonimiza mas preserva a narrativa do bug |
| **"Ranking Final"** | Convertido de lista de bullets para tabela (PER/WER/Speed/Caso) | Mais informa√ß√£o em menos espa√ßo |
| **ASCII chart** | Mantido intacto | Chart est√° limpo e conta a hist√≥ria bem |
| **Nota abaixo do chart** | Adicionada 1 linha com Phase 6C + Fase 7 hint | Contexto sem poluir o visual |

### O que N√ÉO foi tocado (e por qu√™)
- `src/reporting/presentation_generator.py` ‚Äî slides hardcoded (attention, CE, DA example) n√£o mudam sem risco
- Modelos existentes ‚Äî nunca modificar arquivos .pt
- Configs existentes (Exp0‚ÄìExp106) ‚Äî configs s√£o imut√°veis ap√≥s treino

### Backups dispon√≠veis
- `docs/presentation/PRESENTATION.md.bak_20260228` ‚Äî estado dos slides antes das edi√ß√µes de 2026-02-28
- **Para restaurar**: `cp docs/presentation/PRESENTATION.md.bak_20260228 docs/presentation/PRESENTATION.md`
- **Para apagar o backup** (quando confirmar que est√° tudo OK): `rm docs/presentation/PRESENTATION.md.bak_20260228`

---

## üõ†Ô∏è Infraestrutura & Tools

### Core Pipeline
- ‚úÖ **train.py**: Training loop com early stopping, checkpointing
- ‚úÖ **inference.py**: Batch evaluation + metrics + error analysis
- ‚úÖ **analysis.py**: Training history plots + convergence analysis
- ‚úÖ **report_generator.py**: HTML reports com m√©tricas graduadas
- ‚úÖ **manage_experiments.py**: Experiment tracking + cleanup

### Data & Registry
- ‚úÖ **G2PCorpus**: Stratified splits, caching, statistical validation
- ‚úÖ **FileRegistry**: Timestamped artifacts, metadata tracking
- ‚úÖ **dataset_stats.json**: Reproducible cache (phoneme coverage, chi-square)

### Quality Assurance
- ‚úÖ Reproducibilidade total (seed=42, deterministic)
- ‚úÖ Configs JSON versionados com todos hyperparameters
- ‚úÖ Metadata JSON por modelo (architecture, training, metrics)
- ‚úÖ Git-tracked configs + .gitignore models/results

---

## üìÅ Repository Structure

```
FG2P/
‚îú‚îÄ‚îÄ src/                          # Source code
‚îÇ   ‚îú‚îÄ‚îÄ train.py                  # Training pipeline
‚îÇ   ‚îú‚îÄ‚îÄ inference.py              # Evaluation + metrics
‚îÇ   ‚îú‚îÄ‚îÄ g2p.py                    # Model architecture + corpus
‚îÇ   ‚îú‚îÄ‚îÄ analysis.py               # Training analysis
‚îÇ   ‚îî‚îÄ‚îÄ utils.py                  # Logging, paths, helpers
‚îú‚îÄ‚îÄ config_*.json                 # Experiment configs (reproducible)
‚îú‚îÄ‚îÄ models/                       # Model checkpoints .pt + metadata
‚îú‚îÄ‚îÄ results/                      # Evaluations, predictions, analysis
‚îú‚îÄ‚îÄ data/                         # Cached dataset splits
‚îú‚îÄ‚îÄ dicts/                        # Source dictionary pt-br.tsv
‚îú‚îÄ‚îÄ docs/                         # Documentation (scientific paper structure)
‚îÇ   ‚îú‚îÄ‚îÄ 01_LITERATURA.md
‚îÇ   ‚îú‚îÄ‚îÄ 02_ARQUITETURA.md
‚îÇ   ‚îú‚îÄ‚îÄ 03_IMPLEMENTACAO.md
‚îÇ   ‚îú‚îÄ‚îÄ 04_EXPERIMENTOS.md
‚îÇ   ‚îú‚îÄ‚îÄ 05_BENCHMARKS.md
‚îÇ   ‚îî‚îÄ‚îÄ 06_ANALISE_LINGUISTICA.md
‚îú‚îÄ‚îÄ TODO.md                       # Roadmap + status (source of truth)
‚îú‚îÄ‚îÄ RESUMO_EXPERIMENTOS.md        # Consolidated experiment summary
‚îú‚îÄ‚îÄ EXPERIMENTOS_DECOMPOSED.md    # Phase 5 strategy
‚îî‚îÄ‚îÄ README.md                     # Quick start

```

---

## üéØ Pr√≥ximos Milestones

### Curto Prazo (1-2 semanas)
1. ‚úÖ **Exp11-13 training** (decomposed encoding tests)
2. üìä **Comparative analysis** Exp11-13 vs baselines
3. üéØ **Decision**: Adoptar decomposed como default SE beneficial

### M√©dio Prazo (2-4 semanas)
4. üìù **Paper draft** (estrutura j√° em docs/)
5. üé® **PowerPoint generator** para apresenta√ß√µes cient√≠ficas
6. üî¨ **M√©tricas graduadas avan√ßadas** (eros√£o cumulativa)

### Longo Prazo (backlog)
7. ü§ñ **Transformer architecture** (compare vs LSTM)
8. üåê **Multi-task learning** (tonicidade, syllabification)
9. üì¶ **Production API** (Flask/FastAPI deployment)

---

## üìö Documenta√ß√£o

### Principal
- **[README.md](README.md)**: Quick start + resultados destacados
- **[TODO.md](TODO.md)**: Roadmap completo + tracking
- **[RESUMO_EXPERIMENTOS.md](RESUMO_EXPERIMENTOS.md)**: An√°lise consolidada Exp0-10

### Cient√≠fica (paper structure)
- **[docs/](docs/)**: 6 documentos (Literatura ‚Üí An√°lise lingu√≠stica)
- **[EXPERIMENTOS_DECOMPOSED.md](EXPERIMENTOS_DECOMPOSED.md)**: Phase 5 strategy

### Configuration
- **[config_*.json](./config_exp*.json)**: 13 experiment configs (reproducible)
- **[CONFIG_README.md](CONFIG_README.md)**: Config file format specification

---

## üë• Team & Contact

**Desenvolvedor Principal**: [Nome]  
**Orienta√ß√£o**: [Orientador]  
**Institui√ß√£o**: [Universidade]  
**Curso**: [Programa]

---

**√öltima atualiza√ß√£o**: 2026-02-22 16:40  
**Gerado automaticamente** a partir do estado atual do projeto.
